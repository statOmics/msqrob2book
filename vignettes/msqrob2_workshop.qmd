---
title: "msqrob2TMT: modelling sources of variability in TMT-based proteomics experiments, a use case"
author:
    - name: Christophe Vanderaa
    - name: Stijn Vandenbulcke
    - name: Lieven Clement
output: rmarkdown::html_vignette
date: "`r BiocStyle::doc_date()`"
package: "`r BiocStyle::pkg_ver('msqrob2')`"
vignette: >
    %\VignetteIndexEntry{msqrob2TMT use case}
    %\VignetteEngine{knitr::rmarkdown}
    %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
    warning=FALSE,
    message=FALSE
)
```

# Introduction

## Mass spectrometry-based proteomics

Mass spectrometry (MS)-based proteomics aims at characterising the
proteome content from biological samples. In a nutshell, the workflow 
starts with sample preparation where the samples are collected, and
the protein content is extracted and digested into peptides. For
TMT experiments, each sample is labelled and multiple samples
are pooled together. Next, during the liquid chromatographt (LC) and
ionisation, the peptides are passed through a chromatographic column 
and separated based on their physicochemical properties. Eluting 
peptides are ionised by an electrospray. A first round of MS records the ion’s
m/z distribution for the intact ions. This provides an overview of the
ions that elute from the column and allows for further separation of
the ions in the m/z space. The second round of MS records the
fragmented ions for a selection of ions. This provides the ion’s mass
fingerprint that will later enable computational identification of the
peptide sequence. The recorded spectral data is then processing using
search engines leading to peptide-to-spectrum matches (PSM). Analyzing
the spectral peaks generated by the TMT labels (coloured bars in the
bottom of the figure) enables to quantify the corresponding peptide in
its corresponding sample before pooling.

```{r, echo = FALSE, out.width = "80%", fig.cap = "Overview of an MS-based proteomics workflow."}
knitr::include_graphics("figs/ms_workflow.png")
```

## In this vignette

We will start from the quantified PSM data and infer protein-level
differences between samples. To achieve this goal, we will apply the
msqrob2TMT workflow, a data processing and modelling workflow
dedicated to the analysis of TMT-based proteomics datasets. We will
demonstrated the workflow using the study published by [Plubell et al.
2017](https://doi.org/10.1074/mcp.m116.065524), illustrating the
statistical concepts using a real-life use case.

You can read more about `msqrob2TMT` in:

> Vandenbulcke S, Vanderaa C, Crook O, Martens L, Clement L.
msqrob2TMT: robust linear mixed models for inferring differential
abundant proteins in labelled experiments with arbitrarily complex
design. bioRxiv. Published online March 29, 2024:2024.03.29.587218.
doi:10.1101/2024.03.29.587218

Since this vignette is about a real-life study, we cannot objectively
assess the results. For an msqrob2TMT analysis with ground tuth
information, we refer to our [spike-in
vignette](https://github.com/statOmics/msqrob2tmt_paper/tree/main/vignettes).

Before delving further into the use case, let us prepare our
computational environment.

# Load packages

First, we load the `msqrob2` package.

```{r}
library("msqrob2")
```

We also load 4 additional packages for data manipulation and
visualisation.

```{r}
library("dplyr")
library("ggplot2")
library("ggrepel")
library("patchwork")
```

`msqrob2` relies on parallelisation to improve computational speed.
To ensure this vignette can be run regardless of hardware, we will
disable parallelisation. Parallelisation is controlled using the
`BiocParallel` package.

```{r}
library("BiocParallel")
register(SerialParam())
```

# Load data

## Experimental context

The data used in this vignette has been published by [Plubell et al.
2017](https://doi.org/10.1074/mcp.m116.065524) (PXD005953). The
objective of the experiment was to explore the impact of low-fat and
high-fat diets on the proteomic content of adipose tissue in mice. It
also assesses whether the duration of the diet may impact the results.
The authors assigned twenty mice into four groups (5 mice per group)
based on their diet, either low-fat (LF) or high-fat (HF), and the
duration of the diet, which was classified as short (8 weeks) or long
(18 weeks). Samples from the epididymal adipose tissue were extracted
from each mice. The samples were then randomly distributed across
three TMT 10-plex mixtures for analysis. In each mixture, two
reference labels were used, each containing pooled samples that
included a range of peptides from all the samples. Not all labels
were used, leading to an unbalanced design. Each TMT 10-plex mixture
was fractionated into nine parts and subjected to synchronous
precursor selection, resulting in a total of 27 MS runs.

## Getting the data

The data were reanalyzed by [Huang et al.
2020](http://dx.doi.org/10.1074/mcp.RA120.002105) and have been
deposited in the `MSV000084264` MASSiVE repository, but we will
retrieve the timestamped data from our
[Zenodo repository](https://zenodo.org/records/14767905). To
facilitate management of the files, we here download them using the
`BiocFileCache` package. We need 2 files: the Skyline identification
and quantification table generated by the authors and the sample
annotation files. `BiocFileCache` ensures that the files are
downloaded once, hence the chunk below will take some time only the
first time you run it.

```{r}
library("BiocFileCache")
bfc <- BiocFileCache()
psmFile <- bfcrpath(bfc, "https://zenodo.org/records/14767905/files/mouse_psms.txt?download=1")
annotFile <- bfcrpath(bfc, "https://zenodo.org/records/14767905/files/mouse_annotations.csv?download=1")
```

Now the files are downloaded, we can load the psm table. Each row in
the psm data table contains information for one PSM (the table below
shows the first 6 rows). Note that columns that start with
`"Abundance."` contain the quantitative values for each TMT label.

```{r}
psms <- read.delim(psmFile)
```
```{r, echo=FALSE}
knitr::kable(head(psms))
```

We also load the annotation table. Each row in the annotation table
contains information for one sample (the table below shows the first 6
rows).

```{r}
coldata <- read.csv(annotFile)
```
```{r, echo=FALSE}
knitr::kable(head(coldata))
```

We perform a little cleanup of the sample annotations to generate the
information needed for later data modelling, namely we extract the
diet type and the duration of the diet from the condition variable.

```{r}
coldata$Duration <- gsub("_.*", "", coldata$Condition)
coldata$Diet <- gsub(".*_", "", coldata$Condition)
```

We will also subset the data set to reduce computational costs. If you
want to run the vignette on the full data set, you can skip this
chunk. We here randomly sample 500 proteins from the experiment.

```{r}
proteinIds <- unique(psms$Protein.Accessions)
set.seed(1234)
psms <- psms[psms$Protein.Accessions %in% sample(proteinIds, 500), ]
```

## The `QFeatures` data class

Finally, we combine the data into a `QFeatures` object. The
`QFeatures` package provides infrastructure to manage and analyse
quantitative features from mass spectrometry experiments. It is based
on the `SummarizedExperiment` and `MultiAssayExperiment` classes. It
leverages the hierarchical structure of proteomics experiments: data
proteins are composed of peptides, themselves produced by spectra.
Throughout the aggregation and processing of these data, the relations
between assays are tracked and recorded, thus allowing users to easily
navigate across spectra, peptide and protein quantitative data.

```{r, echo = FALSE, out.width = "80%", fig.cap = "Illustration of the `QFeatures` data class."}
knitr::include_graphics("figs/QFeatures.png")
```

The `readQFeatures()` allows for seamless conversion of tabular data
into a `QFeatures` object. In order to link the annotation table with
the PSM data (from the Skyline PSM table), the annotation table must
contain a `runCol` column with run names to be matched with the run
names in the PSM table (for Skyline, it is stored in the
`Spectrum.File` column). We also add a `quantCols` column in the
annotation table. It will allow to link each sample to the
quantification column in the PSM table. See `?readQFeatures()` for
more details.

```{r}
coldata$runCol <- coldata$Run
coldata$quantCols <- paste0("Abundance..", coldata$Channel)
mouse <- readQFeatures(psms, colData = coldata,
                       quantCols = unique(coldata$quantCols),
                       runCol = "Spectrum.File", name = "psms")
names(mouse) <- sub("^.*(Mouse.*ACN).*raw", "\\1", names(mouse))
mouse
```

We now have a `QFeatures` object with 27 sets, each containing data
associated with an MS run. The sample annotation can be retrieved 
using `colData()`.

```{r, eval=FALSE}
head(colData(mouse))
```
```{r, echo=FALSE}
tmp <- head(colData(mouse))
rownames(tmp) <- NULL
tmp
```

We can also retrieve the quantitative values for each set using 
`assays()`.

```{r}
assay(mouse[[1]])[1:5, 1:5]
```

Finally, the remaining PSM annotations are available for each set in
the corresponding `rowData`.

```{r}
head(rowData(mouse[[1]]))
```


# Data preprocessing

`msqrob2` relies on the `QFeatures` data structure, meaning that we
can directly make use of `QFeatures`' data preprocessing
functionality (see also the `QFeatures`
[documentation](https://rformassspectrometry.github.io/QFeatures/articles/Processing.html)).

The very first data processing step for MS experiments is to replace
any zero PSM intensity by a missing value (see `?zeroIsNA()`). This is
because true zeros (the peptide is absent from the sample) cannot be
distinguished from technical zeros (the peptide was missed by the
instrument). However, Skyline already encodes zeros by `NA`s, so we
can skip this step.

## PSM filtering

We first filter features for which more than 70% of the intensities
are missing in a run. We keep the spectrum as soon as the reporter
ions are observed in at least 3 out of 10 TMT labels of the run
(same cut-off as applied in [Huang et al.
2020](http://dx.doi.org/10.1074/mcp.RA120.002105))/.

```{r}
mouse <- filterNA(mouse, names(mouse), pNA = 0.7) ## 2.
```

We next remove PSMs that could not be mapped to a protein or that map
to multiple proteins (the protein identifier contains multiple
identifiers separated by a `;`). We use `filterFeatures()` that will
keep the row that fulfill the condition below. Note that
`Protein.Accessions` is a column generated by Skyline that is
available in the `rowData`.

```{r}
mouse <- filterFeatures(
    mouse, ~ Protein.Accessions != "" & ## Remove failed protein inference
        !grepl(";", Protein.Accessions)) ## Remove protein groups
```

Peptide ions that were identified with multiple PSMs in a run are
collapsed to the PSM with the highest summed intensity over the
labels, a strategy that is also used by MSstats. We will again use
`filterFeatures()`, but the highest summed intensity PSM information 
is not available in the `rowData` so we need to create it manually.

We therefore

1. Make a new variable for ionID in the rowData.
2. We calculate the `rowSums` for each ion.
3. Make a new variable `psmRank` that ranks the PSMs for each ionID
   based on the summed intensity.
4. We store the new information back in the `rowData`.
5. For each ion that maps to multiple PSMs, only keep the PSM with the
   highest summed intensity, that is that ranks first.

```{r}
for (i in names(mouse)) {
    rowdata <- rowData(mouse[[i]])
    rowdata$ionID <- paste0(rowdata$Annotated.Sequence, rowdata$Charge) ## 1.
    rowdata$rowSums <- rowSums(assay(mouse[[i]]), na.rm = TRUE) ## 2.
    rowdata <- data.frame(rowdata) |>
        group_by(ionID) |>
        mutate(psmRank = rank(-rowSums)) ## 3.
    rowData(mouse[[i]]) <- DataFrame(rowdata) ## 4.
}
mouse <- filterFeatures(mouse, ~ psmRank == 1) ## 5.
```

Note that we now implicitly collapsed the PSM-level data into peptide
**ion** data, where each row represents a PSM, but also a unique ion 
within a run. So we will refer to the data as "PSM-level" or
"ion-level" interchangeably.

## Preprocessing workflow

We can now prepare the data for modelling. The workflow consists of
mains steps that ensure the data complies to `msqrob2`'s requirements:

1. Intensities are log-transformed.
2. Samples are normalised.
3. (optionally) PSMs intensities are summarised into protein abundance
   values for protein-level workflows.

```{r}
sNames <- names(mouse)
mouse <- logTransform( ## 1.
    mouse, sNames, name = paste0(sNames, "_log"), base = 2
)
mouse <- normalize( ## 2.
    mouse, paste0(sNames, "_log"), name = paste0(sNames, "_norm"),
    method = "center.median"
)
mouse <- aggregateFeatures( ## 3.
    mouse, i = paste0(sNames, "_norm"), name = paste0(sNames, "_proteins"),
    fcol = "Protein.Accessions", fun = MsCoreUtils::medianPolish,
    na.rm=TRUE
)
```

We remove the reference labels that were used by the MSstatsTMT
authors to obtain normalisation factors since msqrob2TMT workflows do
not require normalisation from reference label. The information
about which labels are normalisation labels is available from the
`colData`, in the `Condition` column.

```{r}
table(mouse$Condition)
```

We remove any sample that is marked as `Norm`. We also remove sample
that are annotated as `Long_M` since we could not find documentation
for this group.

```{r}
mouse <- subsetByColData(
    mouse, mouse$Condition != "Norm" & mouse$Condition != "Long_M"
)
```

We conclude the preprocessing by joining the assays of the different
runs in a single PSM set for PSM-level models. In order to correctly
match PSMs across rus, we provide the `fcol` argument, telling the
function to join PSM with the same `ionID` in one line.

```{r}
mouse <- joinAssays(mouse, paste0(sNames, "_norm"), fcol = "ionID", "ions_norm")
```

We do the same for joining the protein sets into a single set for
protein-level models. Note that we don't need to provide `fcol` since
the function will use the set's rownames (generated by
`aggregateFeatures()`).

```{r}
mouse <- joinAssays(mouse, paste0(sNames, "_proteins"), "proteins")
```

# Statistical modelling

The preprocessed data can now be modelled to answer biologically
relevant questions.

## Model definition

### Experimental design

As described above, samples (adipose tissue) originate from mice that
were either subject to a low-fat (`LF`) or high-fat (`HF`) diet.
Moreover, each of the diet was maintained for a short duration
(`Short`) or a long duration (`Long`). Note that each group contains 5
mice but the peptides from each sample have been fractionated in 9
fractions, leading to 45 units per group.

```{r, echo = FALSE, fig.cap="Overview of the experimental design. Taken from Plubell et al. 2017."}
knitr::include_graphics("figs/mouse_experiment.png")
```

So first, we need to identify the experimental factors of interest. In
this case, we are interested in the effects of diet type and the
effect of diet duration. The table below confirms we have a balanced
design for each condition.

```{r}
table(Diet = mouse$Diet, Duration = mouse$Duration)
```

### Sources of variation

Proteomics data contain several sources of variation that need to be
accounted for by the model:

1. **Treatment of interest**: we model the source of variation induced
   by the experimental treatment of interest as a **fixed effect**.
   Fixed effects are effect that are considered non-random, i.e. the
   treatment effect is assumed to be the same and reproducible across
   repeated experiments, but it is unknown and has to be estimated. We
   will include `Diet` as a fixed effect that models the fact that a
   change in diet type can induce changes in protein abundance.
   Similarly, we also include `Duration` as a fixed effect to model
   the change in protein abundance induces by the diet duration.
   Finally, we will also include an interaction between the two
   variables allowing that the changes in protein abundance induced by
   diet type can be different whether the mice were fed for a short or
   long duration.

2. **Biological replicate effect**: the experiment involves biological
   replication as the adipose tissue extracts were sampled from 20
   mice (5 mice per Diet x Duration combination). Replicate-specific
   effects occurs due to uncontrollable factors, such as social
   behavior, feeding behavior, physical activity, occasional
   injury,... Two mice will never provide exactly the sample material,
   even were they genetically identical and manipulated identically.
   These effects are typically modelled as random effects which are
   considered as a random sample from the population of all possible
   mice and are assumed to be i.i.d normally distributed with mean 0
   and constant variance, $u_{mouse} \sim
   N(0,\sigma^{2,\text{mouse}})$. The use of random effects thus
   models the correlation in the data, explicitly. We expect that
   intensities from the same mouse are more alike than intensities
   between mice.

```{r}
length(unique(mouse$BioReplicate))
```

3. **Labelling effects**: the 20 mouse adipose tissue samples have been
   labelled using 18-plex TMT. We can expect that samples measured
   within the same TMT label may be more similar than samples
   measured within different TMT labels. Since these effects may not
   be reproducible from one experiment to another, for instance
   because each TMT kit may potentially contain different impurity
   ratios, we can account for this correlation using a random effect
   for TMT label. However, we will not model the effects of labels.
   Normalisation already removes part of the label effect and
   including a random effect for label nested within run (see below)
   is sufficient, as confirmed from previous spike-in studies.

**TODO**: include label effect or not?

```{r}
length(unique(mouse$Channel))
```

4. **Mixture effects**: the 20 mouse samples were assigned to one out
   of 3 mixtures. Again, we expect protein intensities from the same
   mixture will be more alike than those of different mixtures. Hence,
   we will add a random effect for mixture.

```{r}
table(mouse$Mixture)
```

5. **Run effects**: protein intensities that are measured within the 
   same run will be more similar than protein intensities between
   runs. We will use a random effect for run to explicitly model this
   correlation in the data. Note that each sample has been acquired in
   9 fractions, each fraction being measured in a separate run.
   Accounting for the effects of run will also absorb the effects of
   fraction.

```{r}
length(unique(mouse$Run))
```

6. **Spectrum effects**: we will directly estimate the treatment effect
   at the protein-level from PSM-level data. This will again induce
   additional levels of correlation. The intensities for the different
   reporter ions in a TMT run within the same spectrum (PSM) will be
   more similar than the intensities between spectra. We therefore
   need to add a random effect term to account for the within PSM
   correlation structure. Note that a spectrum here contains the data
   from one peptide ion within a run. Hence, modelling a random effect
   for spectrum boils down to modelling a random effect for peptide
   ion nested within run.

7. **Labelling effects nested in run**: modelling the data at the
   PSM-level also implies that a label in a run contains multiple
   PSM intensities for each protein. Hence, intensities from different
   PSMs for a protein with the same label within a run will be more alike than
   intensities of different PSMs for the same protein with different
   labels and/or runs, and we will address this correlation with a random
   effect for label nested in run.

`msqrob2` workflows rely on linear mixed models, which are models that
can estimate and predict fixed and random effects, respectively.

Now we have identified the sources of variation, we can define a
model. `msqrob2` also allows to model using main effects for `Diet`
and `Duration`, and a `Diet:Duration` interaction, to account for
proteins for which the `Diet` effect changes according to `Duration`,
and vice versa, which can be written as `Diet + Duration +
Diet:Duration`, shortened into `Diet * Duration`. Adding the technical
sources of variation, the model becomes.

```{r}
model <- ~ 1 + Diet * Duration + ## (1) fixed effect for Diet and Duration with interaction
  (1 | BioReplicate) +  ## (2) random effect for biological replicate (mouse)      
  # (1 | Channel) + ## (3) random effect for label is negligible
  (1 | Mixture) + ## (4) random effect for mixture
  (1 | Run) + ## (5) random effect for MS run
  (1 | Run:ionID) + ## (6) random effect for spectrum, i.e. ionID nested in run
  (1 | Run:Channel)  ## (7) random effect for label nested in MS run
```

Note, that we do not suppress the intercept (the model start with `1
+`), because the first level of every factor is absorbed in the
intercept.

**TODO**: keep below?

Note also that we have commented out the random effect for label in
the model. In practice, normalisation already removes part of the
label effect and is sufficient. You can experiment this yourself by
removing the comment sign `#` in front of `(1 | Channel) +` across the
vignette, and see how the results may change.

Now we have defined the models, we can run the `msqrob2` statistical
workflow.

## Run the model

The statistical workflow starts with `msqrobAggregate()`. The function
takes the `QFeatures` object, extracts the quantitative values from
the `"ions_norm"` set generated after preprocessing, and fits
`model`. The variables defined in `model` are automatically
retrieved from the `colData` (i.e. `"Diet"`, `"Duration"`, `"Channel"`,
`"Run"`, `"Mixture"`, `"BioReplicate"`) and from the `rowData` (i.e.
`"ionID"`). Moreover, we tell the function how the PSM-level data is
grouped to protein data through the `fcol` argument, here we will
group PSMs by the `Protein.Accessions`. The function will generate a
new set, `proteins_msqrob`, with summarised protein values. This new
set will also contain the modelling output, stored in the `rowData` in
the `msqrob_psm` column. More specifically, the modelling
output is stored in the `rowData` for each protein as a `statModel`
object, one model per row (protein). We also enable M-estimation
(`robust = TRUE`) for improved robustness against outliers and ridge
penalisation (`ridge = TRUE`) to stabilise the parameter estimation.

```{r}
mouse <- msqrobAggregate(
    mouse, i = "ions_norm",
    formula = model,
    fcol = "Protein.Accessions",
    modelColumnName = "msqrob_psm",
    name = "proteins_msqrob",
    ridge = TRUE, robust = TRUE
)
```

Once the models are estimated, we can start answering biological
questions.

## Hypothesis testing

In this section, you will learn how to convert a biological question
into a statistical hypothesis.

#### Difference between low fat and high fat diet after short duration

A first question one can ask is: how are protein abundance affected by
diet when only considering a short diet duration? We need to convert
this question in a combination of the model parameters, also referred
to as a contrast. To aid defining contrasts, we will visualise the
experimental design using the `ExploreModelMatrix` package. Since we
are not interested in technical effects, we will only focus on the
variables of interest, here `Diet * Duration`.

```{r}
library("ExploreModelMatrix")
vd <- VisualizeDesign(
    sampleData =  colData(mouse),
    designFormula = ~ 0 + Diet * Duration,
    textSizeFitted = 4
)
vd$plotlist
```

Assessing the difference between low-fat and high-fat diets for short
duration boils down to assessing the difference between the `Short_LF` and
`Short_HF`. The mean for the short low-fat diet group is defined by
`(Intercept) + DietLF + DurationShort + DietLF:DurationShort`. The
mean for the short high-fat diet group is defined by `(Intercept) +
DurationShort`. The difference between the two results in the
contrast below:

```{r}
contrast <- "ridgeDietLF + ridgeDietLF:DurationShort"
```

Note that because we used ridge regression for modelling, we need to
prefix the parameter names with `ridge`. We can further specify the
null hypothesis, that is we are interest whether the differences 
between the two groups is different from zero.

```{r}
(hypothesis1 <- paste(contrast, "= 0"))
```

We next use `makeContrast()` to build a contrast matrix.

```{r}
(L <- makeContrast(
    hypothesis1,
    parameterNames = c("ridgeDietLF","ridgeDurationShort","ridgeDietLF:DurationShort")
))
```

We can now test our null hypothesis using `hypothesisTest()` which
takes the `QFeatures` object with the fitted model and the contrast
matrix we just built. Again, the results are stored in the set
containing the model, here `proteins_msqrob`

```{r}
mouse <- hypothesisTest(
    mouse, i = "proteins_msqrob", L, modelColumn = "msqrob_psm"
)
```

Let us retrieve the result table from the `rowData`. Note that the
model column is named after the column name of the contrast matrix `L`.

```{r}
inference <- rowData(mouse[["proteins_msqrob"]])[[colnames(L)]]
inference$Protein <- rownames(inference)
head(inference)
```

The table contains the hypothesis testing results for every protein.
Notice that some rows contain missing values. This is because data
modelling resulted in a `fitError` for some proteins. 

**TODO**: remove below and demonstrate msqrobRefit?

We refer to [another
vignette](https://github.com/statOmics/Msqrob2TMTPaper/blob/master/vignettes/spikein1.qmd)
that describes how to deal with `fitErrors`. We can use the table
above directly to build a volcano plot using `ggplot2` functionality.

```{r}
ggplot(inference) +
    aes(x = logFC, y = -log10(adjPval)) +
    geom_hline(yintercept = -log10(0.05)) +
    geom_text_repel(data = filter(inference, adjPval < 0.05),
                    aes(label = Protein)) +
    geom_point() +
    ggtitle("Statistical inference on differences between LF and HF (short duration)",
            paste("Hypothesis test:", gsub("ridgeCondition", "", colnames(L)), "= 0"))
```

In this example (remember this is a subset of the complete data set),
only a few proteins pass the significance threshold of 5%. Let us
visualise the protein with the largest fold change.

```{r}
(targetProtein <- rownames(inference)[which.max(inference$logFC)])
```

To obtain the required data, we perform a little data manipulation
pipeline:

1. We use the `QFeatures` subsetting functionality to retrieve all
   data related to `r targetProtein` and focusing on the `ions_norm`
   set that contains the preprocessed peptide ion data used for
   modelling.
2. We use `longForm()` to convert the object into a table suitable
   for plotting.
3. We remove missing values for plotting and focus only on the data
   with short diet duration.
4. We reorder the sample identifiers to improve visualisation.

```{r}
ionData <- mouse[targetProtein, , "ions_norm"] |> #1
    longForm(colvars = colnames(colData(mouse)), #2
               rowvars = c("Protein.Accessions", "ionID")) |>
    data.frame() |>
    filter(!is.na(value) & Duration == "Short") |> #3
    mutate(colname = factor(colname, levels = unique(colname[order(Condition)]))) #4
```

We can now plot the log normalised intensities. Since the protein is
modelled at the peptide ion level, multiple ion intensities are
recorded in each sample. Each ion is linked across samples using a
grey line. Samples are coloured according to the diet type. Finally,
we split the plot in facets, one for each mixture, to visualise the
heterogeneity induced by different pools of mice.

```{r}
ggplot(ionData) +
    aes(x = colname,
        y = value) +
    geom_line(aes(group = ionID), linewidth = 0.1) +
    geom_point(aes(colour = Condition)) +
    facet_grid(~ Mixture, scales = "free") +
    labs(x = "Sample", y = "log2 intensity") +
    ggtitle(targetProtein) +
    theme_minimal() +
    theme(axis.text.x = element_blank())
```

The statistical analysis revealed a significant increase (positive log
fold change) of the abundance for `r targetProtein` in the group fed
with a low-fat diet compared to the high-fat diet fed group (upon
early diet duration). This finding can be visually validated as there
is a systematic increase in peptide ion intensities between the
low-fat diet group (blue) compared to the high-fat diet group (red).

#### Difference between low fat and high fat diet after long duration

The second question one can ask is what proteins are affected by diet
when only considering, this time, a long diet duration. Following the
same approach as above, the contrast becomes.

```{r}
hypothesis2 <- "ridgeDietLF = 0"
```

We run the same statistical analysis pipeline as above.

```{r}
L <- makeContrast(
    hypothesis2,
    parameterNames = c("ridgeDietLF","ridgeDurationShort","ridgeDietLF:DurationShort")
)
mouse <- hypothesisTest(
    mouse, i = "proteins_msqrob", L, modelColumn = "msqrob_psm"
)
inference <- rowData(mouse[["proteins_msqrob"]])[[colnames(L)]]
inference$Protein <- rownames(inference)
```

And we plot the results.

```{r}
ggplot(inference) +
    aes(x = logFC, y = -log10(adjPval)) +
    geom_hline(yintercept = -log10(0.05)) +
    geom_text_repel(data = filter(inference, adjPval < 0.05),
                    aes(label = Protein)) +
    geom_point() +
    ggtitle("Statistical inference on differences between LF and HF (long duration)",
            paste("Hypothesis test:", gsub("ridgeCondition", "", colnames(L)), "= 0"))
```

Again, only a few proteins come out differentially abundant between
the two diets, but after a long diet duration. Surprisingly, there
is only a small overlap between differential protein after short
duration and after long duration. One hypothesis is that there is not
sufficient data to detect a reliable difference. A solution would be
to combine both short and long diet duration to retrieve an averaged
systematic effect between diets that combine all available data.
Another hypothesis is that diet duration may influence the effect of
diet on the protein abundances. We will explore the two hypothesis in
the following two sub-sections.

#### Average difference between low fat and high fat diet

One may want to identify the set of proteins that are systematically
differentially abundant between diets, irrespective of the duration.
To answer this question, we want to infer on the average difference
between group `LF` and group `HF`. The average low-fat diet is defined
by `((Intercept) + DietLF + DurationShort + DietLF:DurationShort +
(Intercept) + DietLF)/2`. The average high-fat diet group is defined
by `((Intercept) + DurationShort + (Intercept))/2`. The difference
between the two results in the hypothesis below:

```{r}
hypothesis3 <- "ridgeDietLF + (ridgeDietLF:DurationShort)/2 = 0"
```

We next run again the same statistical analysis pipeline as above.

```{r}
L <- makeContrast(
    hypothesis3,
    parameterNames = c("ridgeDietLF","ridgeDurationShort","ridgeDietLF:DurationShort")
)
mouse <- hypothesisTest(
    mouse, i = "proteins_msqrob", L, modelColumn = "msqrob_psm"
)
inference <- rowData(mouse[["proteins_msqrob"]])[[colnames(L)]]
inference$Protein <- rownames(inference)
```

And we plot the results.

```{r}
ggplot(inference) +
    aes(x = logFC, y = -log10(adjPval)) +
    geom_hline(yintercept = -log10(0.05)) +
    geom_text_repel(data = filter(inference, adjPval < 0.05),
                    aes(label = Protein)) +
    geom_point() +
    ggtitle("Statistical inference on average difference between LF and HF",
            paste("Hypothesis test:", gsub("ridgeCondition", "", colnames(L)), "= 0"))
```

We find much more significant proteins when combining all available
data to infer the differences between low-fat and high-fat diets,
irrespective of duration. We also retrieve a good overlap between this
set of significant proteins and the two previous sets, indicating
that more data helped improving the statistical power.

#### Interaction: does the diet effect change according to duration?

We will now explore whether the effect of diet on protein abundance
may be affected by duration, i.e. we want to infer on the difference
of differences. The difference between hypothesis 1 and 2 is `(DietLF
+ DietLF:DurationShort) - (DietLF)` and results in the hypothesis
below:

```{r}
hypothesis4 <- "ridgeDietLF:DurationShort = 0"
```

We can proceed with the same statistical pipeline.

```{r}
L <- makeContrast(
    hypothesis4,
    parameterNames = c("ridgeDietLF","ridgeDurationShort","ridgeDietLF:DurationShort")
)
mouse <- hypothesisTest(
    mouse, i = "proteins_msqrob", L, modelColumn = "msqrob_psm"
)
inference <- rowData(mouse[["proteins_msqrob"]])[[colnames(L)]]
inference$Protein <- rownames(inference)
```

And we plot the results.

```{r}
ggplot(inference) +
    aes(x = logFC, y = -log10(adjPval)) +
    geom_hline(yintercept = -log10(0.05)) +
    geom_text_repel(data = filter(inference, adjPval < 0.05),
                    aes(label = Protein)) +
    geom_point() +
    ggtitle("Statistical inference on the effect of duration on the differences between diets",
            paste("Hypothesis test:", gsub("ridgeCondition", "", colnames(L)), "= 0"))
```

There is only one protein for which duration impacts the effect of
diet. Let us visually explore this changes for the most significant
protein.

```{r}
(targetProtein <- rownames(inference)[which.min(inference$adjPval)])
```

We use again `Qfeatures`'s data manipulation pipeline.

```{r}
ionData <- mouse[targetProtein, , "ions_norm"] |> #1
    longForm(colvars = colnames(colData(mouse)), #2
               rowvars = c("Protein.Accessions", "ionID")) |>
    data.frame() |>
    filter(!is.na(value)) |> #3
    mutate(colname = factor(colname, levels = unique(colname[order(Condition)]))) #4
```

And explore the peptide ion data, this time also facetting for
duration in order to highlight changes in direction of the
difference between low-fat and high-fat diets.

```{r}
ggplot(ionData) +
    aes(x = Run, #colname,
        y = value) +
   # geom_line(aes(group = ionID), linewidth = 0.1) +
    #geom_point(aes(colour = Condition)) +
    # geom_boxplot(aes(colour = Condition)) +
    geom_point(aes(shape = rowname, colour = Diet)) +
    facet_wrap(Duration ~ Mixture, scales = "free_x", labeller = label_both) +
    #labs(x = "Sample", y = "log2 intensity") +
    labs(x = "Run", y = "log2 intensity") +
    ggtitle(targetProtein) +
    theme_minimal() +
    theme(axis.text.x = element_blank(),legend.position = "none")
```

The graph hints towards a slight increase in protein abundance in the
low-fat diet group compared to the high-fat diet group during a short
diet duration, but this increase disappears after a long diet
duration. However, the visual inspection of the results also shows
that the result rely on sparse and highly unbalanced data. The results
may hence require further experimental validation.

Note that we performed the statistical analysis for each hypothesis
separately. However, `msqrob2` can assess multiple hypothesis at once.

```{r}
L <- makeContrast(
    c(hypothesis1, hypothesis2, hypothesis3, hypothesis4),
    parameterNames = c("ridgeDietLF","ridgeDurationShort","ridgeDietLF:DurationShort")
)
mouse <- hypothesisTest(
    mouse, i = "proteins_msqrob", L,
    modelColumn = "msqrob_psm", overwrite = TRUE
)
```

Note that since we already generated results for the contrast, we
overwrite the results with the argument `overwrite = TRUE`.

We retrieve the inference tables from the `rowData` to generate the
volcano plot.

```{r}
inferenceTables <- rowData(mouse[["proteins_msqrob"]])[, colnames(L)]
```

We here use a `lapply()` loop to generate the plots. The code chunk is
elaborate, but follows the same structure as in the previous section.
This generates a list of volcano plots, one for each hypothesis.

```{r}
volcanoPlots <- lapply(colnames(inferenceTables), function(i) {
    inference <- inferenceTables[[i]]
    inference$Protein <- rownames(inference)
    ggplot(inference) +
        aes(x = logFC, y = -log10(adjPval)) +
        geom_hline(yintercept = -log10(0.05)) +
        geom_text_repel(data = filter(inference, adjPval < 0.05),
                        aes(label = Protein)) +
        geom_point() +
        ggtitle("Hypothesis test:",
                paste(gsub("ridge", "", i), "= 0"))
})
```

We combine all the plots in a single figure using the `patchwork`
packages.

```{r, fig.width=8, fig.height=8}
wrap_plots(volcanoPlots)
```

## Protein-level model

This section illustrate data modelling at the protein level instead of
the PSM level as shown in the previous sections.

Here, we work with a workflow where the peptide ion intensities are
summarised within each run. This has already been done in the
preprocessing. Note, that we no longer have multiple abundance values
for a protein in the same label of a run. Hence, we can omit the
nested effects for label and ionID in run.

```{r}
modelSum <- ~ Diet * Duration + ## fixed effect for Diet and Duration with interaction
        # (1 | Channel) + ## (1) random effect for channel is negligible
        (1 | Mixture) + ## (2) random effect for mixture
        (1 | Run) + ## (3) random effect for MS run
        (1 | BioReplicate)  ## (6) random effect for biorepeat (mouse)
```

For protein-level modelling, we use `msqrob()` instead of
`msqrobAggregate()`, but their function arguments closely overlap.

```{r}
mouse <- msqrob(
    mouse, i = "proteins",
    formula = modelSum,
    modelColumnName = "msqrob_rrilmm",
    ridge = TRUE, robust = TRUE
)
```

We perform hypothesis tests for the early, late, average and
interaction effects. Note, that the specification of contrasts for the
fixed effects remains the same.

```{r}
mouse <- hypothesisTest(
    mouse, i = "proteins", L, modelColumn = "msqrob_rrilmm"
)
```

The inference tables were all stored in the `rowData` as separate
columns, like previously.

```{r}
inferenceTablesSum <- rowData(mouse[["proteins"]])[, colnames(L)]
```

We here use again the `lapply()` loop that generates the list of
volcano plots, one for each hypothesis.

```{r}
volcanoPlotsSum <- lapply(names(inferenceTablesSum), function(i) {
    inference <- inferenceTablesSum[[i]]
    inference$Protein <- rownames(inference)
    ggplot(inference) +
        aes(x = logFC, y = -log10(adjPval)) +
        geom_hline(yintercept = -log10(0.05)) +
        geom_text_repel(data = filter(inference, adjPval < 0.05),
                        aes(label = Protein)) +
        geom_point() +
        ggtitle("Hypothesis test:",
                paste(gsub("tests_|ridge", "", i), "= 0"))
})
```

```{r, fig.width=8, fig.height=8}
wrap_plots(volcanoPlotsSum)
```

# Conclusion

In this vignette, we have demonstrated the application of msqrob2TMT
workflows on a real-life case study.

The preprocessing workflow relies on the the `QFeatures` package. The
package provides functionality to carry out many steps like data
filtering, missing values management, normalisation,
log-transformation, imputation, summarisation, etc. The functions also
provide different methods for each step, meaning that the
preprocessing pipeline can be easily adapted to the researcher's
needs based on their experiment and data set.

Once preprocessed, we use the `msqrob2` package to model all sources
of variability as identified from the experiment: effect of diet and
duration, effect of the MS acquisition run, effect of TMT mixture,
effect of spectrum, and effect of sample. Modelling these different
sources of variability allows to correctly infer changes in protein
abundances between groups of interest while using PSM-level data,
although we also illustrate how to model the data at the protein
level.

The experiment aims to understand the proteomic changes in mouse
adipose tissue that occur upon feeding the mice with low-fat or
high-fat diets, during a short or a long duration. We showed how to
model these data as two factor and how to translate biological
questions to statistical hypothesis and contrast matrices using our
msqrob2TMT workflow. To allow for the diet duration to influence the
impact of diet type, we included an interaction term. The unique
feature of `msqrob2` is that its flexible approach can include more
than 2 variables (with multiple interaction terms) as well as
including numerical variables, which may be essential in other
experimental contexts.

Modelling TMT-based data with biological replication leads to one of
the most complex designs. These have to be further complexified with
upcoming single-cell proteomics design where a new source of
variability arises as cells belonging to the same experimental unit
(subject or cell culture) are more similar than cells belonging to
different experimental units. However, the model simplifies for other
use cases. For instance, we saw how a protein-level model upon
aggregation simplifies the model. However, spectrum effects can no
longer be accounted for. This means that an appropriate summarisation
approach is needed to correctly account for these spectrum effects
when computing the summaries. Median polish (exemplified here) or
robust summary do account for this, at least partially depending on
the experimental design. Label-free experiments, which do not perform
chemical labelling of the samples, do not contain labelling effects
which therefore are omitted. Moreover, every sample is acquired as
part of a single run hence no run effect can be modelled. This
simplified model is easier to understand but bear in mind that the
unmodelled effects (eg. spectrum effects or run effect) may end up
increasing the residual variance, hence reduce statistical power.

Hence, we here demonstrated the power and flexibility of `msqrob2` and
the msqrob2TMT workflows to help researchers answer
biologically-relevant questions from their MS proteomics data.

# Citation

> Vandenbulcke S, Vanderaa C, Crook O, Martens L, Clement L.
msqrob2TMT: robust linear mixed models for inferring differential
abundant proteins in labelled experiments with arbitrarily complex
design. bioRxiv. Published online March 29, 2024:2024.03.29.587218.
doi:10.1101/2024.03.29.587218

# License

This vignette is distributed under a
[Artistic-2.0](https://opensource.org/license/artistic-2-0) license.

# Session info

```{r, echo=FALSE}
sessionInfo()
```
