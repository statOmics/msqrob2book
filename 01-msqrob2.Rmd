
# Statistical analysis with msqrob2 {#sec-concepts}

This chapter explains the important concepts when it comes to
statistical analysis of proteomics data using `msqrob2`. To illustrate
these concepts, we will use the spike-in study published by
@Huang2020-lu. We chose this dataset because 

1. Spike-in data contain ground truth information about which proteins 
are differentially abundant, enabling us to show the impact of 
different analysis strategies.
2. It has been acquired with a TMT-labelling strategy that require a
more complex experimental design. This provides an excellent example
to explain the different sources of variability in an MS experiment
and demonstrate the flexibility of `msqrob2` to model this
variability.


**TODO**: throughout the book, we must make sure we stick to one of 
the following terms for low-level modellig: peptide ion-, ion-,
precursor ion-, precursor- or psm-leve. I prefer "precursor" for its
simplicity and think we should replace "ionID" by "precursor_id"


## Why msqrob2?

Mass spectrometry (MS)-based proteomics experiments often imposes a
complex correlation structure among observations. Addressing this
correlation is key for correct statistical inference and reliable
biomarker discovery. msqrob2TMT is a set of mixed model-based
workflows tailored toward differential abundance analysis for labelled
MS-based proteomics data. The key features of `msqrob2TMT` workflows
are:

1. Modularity: all core functions rely on the `QFeatures` class, a
   standardised data structure, meaning that output of a function can
   be fed as input to any other function. Hence, different functions
   are assembled as modular blocks into a complete data analysis
   workflows that can be easily adapted to the peculiarities of any
   MS-based proteomics data set. Therefore, the approach extends well
   beyond the use case presented in this chapter
2. Flexibility: the `msqrob2` modelling approach relies on the
   `lme4::lmer()` model specification syntax, meaning that any linear
   model can be specified. For fixed effects, this includes modelling
   categorical and numerical variables, as well as their interaction.
   Moreover, `msqrob2` can model both sample-specific and
   feature-specific (e.g. peptide or protein) covariates, which
   unlocks the inference to experiments with arbitrarily complex
   designs as well as to correct explicitly for feature-specific
   properties.
3. Performance: thanks to the inclusion of robust ridge regression, we
   demonstrated improved performance of `msqrob2` workflows upon the
   competing software [@Goeminne2016-tr;@Sticker2020-rl;@Vandenbulcke2025-sj].

## Software

### Load packages

We load the `msqrob2` package, along with additional packages for
data manipulation and visualisation.

```{r}
library("msqrob2")
library("dplyr")
library("ggplot2")
library("patchwork")
```

### Parallelisation {#sec-parallel}

`msqrob2` can parallelisation computations during the model estimation
to improve speed. However, we will disable parallelisation to ensure
this vignette can be run regardless of hardware. Parallelisation is
controlled using the `BiocParallel` package.

```{r}
library("BiocParallel")
register(SerialParam())
```

If you want to use `msqrob2` with parallelisation enabled and using
4 cores, you can run the following:

```{r, eval = FALSE}
register(MulticoreParam(workers = 4))
```

Be mindful that, while parallelisation can improve speed, it will also
consume more RAM because part of the data will be copied multiple
times over your different workers. If you experience crashes because
you exceeded the amount of available RAM on your machine, you should
reduce the number of requested workers.

## Data

The data set used in this chapter is a spike-in experiment
(PXD0015258). It consists of controlled mixtures with known ground
truth. UPS1 peptides at concentrations of 500, 333, 250, and 62.5 fmol
were spiked into 50 g of SILAC HeLa peptides, each in duplicate. These
concentrations form a dilution series of 1, 0.667, 0.5, and 0.125
relative to the highest UPS1 peptide amount (500 fmol). A reference
sample was created by combining the diluted UPS1 peptide samples with
50g of SILAC HeLa peptides. All dilutions and the reference sample
were prepared in duplicate, resulting in a total of ten samples. These
samples were then treated with TMT10-plex reagents and combined before
LC-MS/MS analysis. This protocol was repeated five times, each with
three technical replicates, totaling 15 MS runs.

### Getting the data

The data have been deposited by the authors in the `MSV000084264`
MASSiVE repository, but we will retrieve the timestamped data from our
[Zenodo repository](https://zenodo.org/records/14767905). We need 2
files: the Skyline identification and quantification table generated
by the authors and the sample annotation files.

#### File caching{#sec-caching}

To facilitate management of the files, we download the required files
using the `BiocFileCache` package, which ensures that the files are
downloaded only once. The chunk below will take some time to complete
the first time you run it as it needs to download the (large) file
locally, but will fetch the local copy the following times.

```{r download_data}
library("BiocFileCache")
bfc <- BiocFileCache()
psmFile <- bfcrpath(bfc, "https://zenodo.org/records/14767905/files/spikein1_psms.txt?download=1")
annotFile <- bfcrpath(bfc, "https://zenodo.org/records/14767905/files/spikein1_annotations.csv?download=1")
```

Now the files are downloaded, we can load the two tables. 

#### The PSM table{#sec-psm_table}

An MS experiment generates spectra. Each MS2 spectra are used to infer 
the peptide identity thanks to a search engine. When
an observed spectrum is matched to a theoretical peptide spectrum, we
have a peptide-to-spectrum match (PSM). The identification software
compiles all the PSMs inside a table. Each row in the PSM data table
contains information for one PSM (the table below shows the first 6
rows). The columns contains various information about the PSM, such as
the peptide sequence and charge, the quantified value, the inferred
protein group, the measured and predicted retention time and precursor
mass, the score of the match, ... In the case of TMT data, the
quantification values are provides in multiple columns (start with
`"Abundance."`), one for each TMT label. Regardless of TMT or LFQ
experiments, quantitative values from samples in different runs are
stacked below each other. This is known as the "long format".

```{r}
psms <- read.delim(psmFile)
qcols <- grep("Abundance", colnames(psms), value = TRUE)
```
```{r, echo=FALSE}
knitr::kable(head(psms))
```

**TODO**: explain reading peptide and protein tables.

#### The sample annotation table{#sec-annotation_table}

The annotation table should be generated by the researcher and
provides information about Without an annotation table, no analysis
can be performed. Note that annotations are sometimes extracted from 
the column names, but reporting a detailed design of experiments in a
table is seen as better practice [@Gatto2023-kk]. 

The annotation table used in this tutorial has been generated by the
authors, and we perform an additional little cleanup for concise
output.

```{r}
coldata <- read.csv(annotFile)
## Lines below are optional
coldata <- coldata[, c("Run", "Channel", "Condition", "Mixture", "TechRepMixture")]
coldata$File.Name <- coldata$Run
coldata$Run <- sub("^.*(Mix.*).raw", "\\1", coldata$Run)
```
```{r, echo=FALSE}
knitr::kable(head(coldata))
```

#### Custom subseting

There is a peculiarity with the dataset: the spectra have been
identified with 2 nodes. In one node, the authors searched the
SwissProt database for proteins with static modifications related to
the metabolic labelling, in the other node they searched the Sigma_UPS
protein database without these static modifications. However, some
spectra were identified by both nodes leading to duplicate PSMs. We
here remove these duplicated PSMs that are identification artefacts.

```{r}
duplicatesQuants <- duplicated(psms[, qcols]) | duplicated(psms[, qcols], fromLast = TRUE)
psms <- psms[!duplicatesQuants, ]
```

We will also subset the data set to reduce computational costs. If you
want to run the analysis on the full data set, you can skip this code
chunk. The subsetting will keep all UPS proteins, known to be
differentially abundant by experimental design, and we will keep 500
background proteins known to be unchanged across condition.

```{r}
allProteins <- unique(psms$Protein.Accessions)
upsProteins <- grep("ups", allProteins, value = TRUE)
helaProteins <- grep("ups", allProteins, value = TRUE, invert = TRUE)
set.seed(1234)
keepProteins <- c(upsProteins, sample(helaProteins, 500))
psms <- psms[psms$Protein.Accessions %in% keepProteins, ]
```

### The QFeatures class{#sec-qfeatures}

`msqrob2` is built around the `QFeatures` class. We refer to the [R
for mass spectrometry
book](https://rformassspectrometry.github.io/book/sec-quant.html) for
a comprehensive description of the class. In a nutshell, the
`QFeatures` package provides infrastructure to manage and analyse
quantitative features from mass spectrometry experiments. It is based
on the `SummarizedExperiment` and `MultiAssayExperiment` classes. It
leverages the hierarchical structure of proteomics experiments: data
proteins are composed of peptides, themselves produced by spectra.
Each pieces of information in stored in an individual
`SummarizedExperiment` object, later referred to as a "set".
Throughout the aggregation and processing of these data, the relations
between sets are tracked and recorded, thus allowing users to easily
navigate across spectra, peptide and protein quantitative data.

```{r, echo = FALSE, out.width = "80%", fig.cap = "Illustration of the `QFeatures` data class."}
knitr::include_graphics("figs/QFeatures.png")
```

The `readQFeatures()` allows for seamless conversion of tabular data
into a `QFeatures` object. In order to link the annotation table with
the PSM data (from the Skyline evidence table), the annotation table
must contain a `runCol` column with run names to be matched with the
run names in the PSM table (for Skyline, it is stored in the
`Spectrum.File` column). We also add a `quantCols` column in the
annotation table. It will allow to link each sample to the
quantification column in the PSM table. See `?readQFeatures()` for
more details.

```{r}
coldata$runCol <- coldata$File.Name
coldata$quantCols <- paste0("Abundance..", coldata$Channel)
(spikein <- readQFeatures(
  psms, colData = coldata,
  quantCols = qcols,
  runCol = "Spectrum.File", name = "psms"
))
```

We now have a `QFeatures` object with 15 sets, each containing data
associated with an MS run. The name of each set is defined by the name
of the corresponding file name of the run, which rather unnecessarily
long. We simplify the set names, although this step is optional and
only meant to improve the clarity of the output.

```{r}
names(spikein) <- sub("^.*(Mix.*).raw", "\\1", names(spikein))
spikein
```

## Data preprocessing

Since we have a `QFeatures` object, we can directly make use of
`QFeatures`' data preprocessing functionality. Again, we refer to the
[R for mass spectrometry
book](https://rformassspectrometry.github.io/book/sec-quant.html) for
an in-depth tutorial about the data preprocessing of quantitatice MS
data. We demonstrate a typical data preprocessing workflow suitable
for `msqrob2` analysis, pinpointing some steps that are specific to
the data set at hand. Indeed, a major advantage of `QFeatures` is it
provides the power to build highly modular workflows, where each step
carried out by a dedicated function with a large choice of available
methods and parameters. This means that users can adapt the workflow
to their specific use case and their specific needs.

### Encoding missing values

The first preprocessing step is to correctly encode the missing
values. It is important that missing values are encoded using `NA`.
For instance, in MS experiments, non-observed values should not be
encoded with a zero. This is because true zeros (the proteomic feature
is absent from the sample) cannot be distinguished from technical
zeros (the feature was missed by the instrument or could not be
identified). We therefore replace any zero in the quantitative data
with an `NA`.

```{r}
spikein <- zeroIsNA(spikein, names(spikein))
```

Note that `msqrob2` can handle missing data without having to rely on
hard-to-verify imputation assumptions. However, `msqrob2` does not
block users from using imputation, which can be used performed with
`impute()` from the `QFeatures` package. Below, we show how one could 
perform KNN imputation (see `?impute` for more options), but note that
we will note evaluate the code in this tutorial to exclude imputation
from the current workflow.

```{r, eval = FALSE}
spikein <- impute(
    spikein, method = "knn",
    i = names(spikein), name = paste0(names(spikein), "_imput")
)
```

**TODO** mention the hurdle model here? 

### Sample filtering

We first remove the reference channels. These channels were used by
the MSstatsTMT authors to obtain normalisation factors [@Huang2020-lu]. However, this
approach ignores the uncertainty associated with the measurement with
these channels, potentially inflating the noise in the samples of
interest. Hence, `msqrob2` workflows do not use reference
channels. In practice, we found no impact of reference channel
normalisation on model performance [@Vandenbulcke2025-sj]. The
information is available from the `colData`, under the `Condition`
column. We remove any sample that is marked as `Norm`.

```{r}
spikein <- subsetByColData(spikein, spikein$Condition != "Norm")
```

### PSM filtering{#sec-filter}

Filter removes low-quality and unreliable PSMs that would otherwise
introduce noise and artefacts in the data. We use `filterFeatures()`
to perform the filtering. It uses information from the `rowData` and a
formula to generate a filter for each feature (row) in each set across
the object. If the filter returns `TRUE`, the corresponding row is
retained, otherwise it is removed. Defining a filter through a formula
offers a flexible approach, allowing for any customised filter. This
dataset requires an extensive PSM filtering which is an ideal use case
to demonstrate the customisation of a filtering workflow.

**TODO**: use some of the QFeaturesGUI functions?

#### Remove ambiguous identifications

The background proteins originate from HeLa cells, which also contain
UPS proteins. The background UPS proteins and the spiked-in UPS
proteins differ in metabolic labelling, so we should be able to
distinguish them. We used the PSM-level data searched with mascot, as
provided by the MSstatsTMT authors who used two mascot identification
nodes. In one node they searched the SwissProt database for proteins
with static modifications related to the metabolic labelling, in the
other node they searched the Sigma_UPS protein database without these
static modifications. Ideally, this should separate the spiked-in UPS
proteins and the UPS proteins from the HeLa cells, however, this is
not always the case. The SwissProt search is expected to return
peptide-spectrum matches (PSMs) for all proteins, including non-UPS
HeLa, UPS HeLa, and spike-in UPS proteins. Conversely, the Sigma_UPS
search is expected to return PSMs exclusively for spike-in UPS
proteins. However, a PSM that matches a UPS protein in the SwissProt
search but is not identified as such in the Sigma_UPS search could
either correctly originate from a HeLa protein or represent a
spiked-in UPS protein that was not recognised as such in the Sigma_UPS
search. Additionally, there are ambiguous PSMs that are not matched to
a UPS protein in the HeLa search but are matched to a UPS protein in
the SwissProt search. To address this, we exclude these ambiguous
proteins from the analysis.

To define amibiguous PSMs, we retrieve the PSM annotations from the
`rowData` and create a new colum indicating whether a PSM belongs to a
UPS protein or not, based on the protein SwissProt identifiers. For
this, we first need to:

1. Combine all the `rowData` information in a single table 
2. Define whether the PSM's protein group is a UPS protein
3. Define an ambiguous PSM as a PSM that is marked as UPS by the
   SwissProt identifier but not by the Sigma_UPS node (`Marked.as`
   column), and inversely. 
4. Inject this information back in the `rowData` of the different sets
5. Apply the filter


```{r}
## 1.
rowdata <- rbindRowData(spikein, names(spikein))
## 2.
rowdata$isUps <- "no"
isUpsProtein <- grepl("ups", rowdata$Protein.Accessions)
rowdata$isUps[isUpsProtein] <- "yes"
## 3.
rowdata$isUps[!isUpsProtein & grepl("UPS", rowdata$Marked.as)] <- "amb"
rowdata$isUps[isUpsProtein & !grepl("UPS", rowdata$Marked.as)] <- "amb"
## 4.
rowData(spikein) <- split(rowdata, rowdata$assay)
## 5. 
spikein <- filterFeatures(spikein, ~ isUps != "amb")
```

#### Remove failed protein inference

Next, we remove PSMs that could not be mapped to a protein or that map
to multiple proteins, i.e. a protein group. For the latter, the
protein identifier contains multiple identifiers separated by a `;`).

```{r}
spikein <- filterFeatures(
    spikein, ~ Protein.Accessions != "" & ## Remove failed protein inference
        !grepl(";", Protein.Accessions)) ## Remove protein groups
```

#### Remove inconsistent protein inference

We also remove peptide ions that map to a different protein depending
on the run.

```{r}
rowdata <- rbindRowData(spikein, names(spikein))
rowdata <- data.frame(rowdata) |>
    group_by(Annotated.Sequence, Charge) |>
    mutate(nProtsMapped = length(unique(Protein.Accessions)))
rowData(spikein) <- split(rowdata, rowdata$assay)
spikein <- filterFeatures(spikein, ~ nProtsMapped == 1)
```

#### Remove one-run wonders

We also remove proteins that can only be found in one run as such
proteins may not be trustworthy.

```{r}
idProteins <- lapply(rowData(spikein), function(x) unique(x$Protein.Accessions))
idInNRuns <- table(unlist(idProteins))
oneRunWonders <- names(idInNRuns)[idInNRuns == 1]
spikein <- filterFeatures(spikein, ~ !Protein.Accessions %in% oneRunWonders)
```

#### Remove duplicated PSMs

Finally, peptide ions that were identified with multiple PSMs in a run
are collapsed to the PSM with the highest summed intensity over the
channels, a strategy that is also used by MSstats.

We therefore

1. Make a new variable for ionID in the rowData.
2. We calculate the `rowSums` for each ion.
3. Make a new variable `psmRank` that ranks the PSMs for each ionID
   based on the summed intensity.
4. We store the new information back in the `rowData`.
5. For each ion that maps to multiple PSMs, only keep the PSM with the
   highest summed intensity, that is that ranks first.
6. Filter ions for which the rowSum equals 0.

```{r}
for (i in names(spikein)) {
    rowdata <- rowData(spikein[[i]])
    rowdata$ionID <- paste0(rowdata$Annotated.Sequence, rowdata$Charge) ## 1.
    rowdata$rowSums <- rowSums(assay(spikein[[i]]), na.rm=TRUE) ## 2.
    rowdata <- data.frame(rowdata) |>
        group_by(ionID) |>
        mutate(psmRank = rank(-rowSums)) ## 3.
    rowData(spikein[[i]]) <- DataFrame(rowdata) ## 4.
}
spikein <- filterFeatures(spikein, ~ psmRank == 1) ## 5.
spikein <- filterFeatures(spikein, ~ rowSums > 0) ## 6.
```

#### Remove highly missing PSMs

We then remove PSMs with 5 or more missing values out of 10 TMT
channels (>= 50%). This is an arbitrary value that may need to be
adjusted depending on the experiment and the data set.

```{r}
spikein <- filterNA(spikein, names(spikein), pNA = 0.5)
```

### Log2 transformation {#sec-log2}

We need to log2 transform the intensities. The plot below shows the 
intensities (left) and log2-intensities (right) for one of the UPS
precursor ions as the UPS spike-in concentration increases. We can
clearly see that the variation around the mean for each dilution
factor increases as the mean increases. This is known as
heteroskedasticity. We will later see that `msqrob2` assumes that
variance of the error should be consistent across the different
conditions. Upon, log2-transformation we can see that the problem of
unequal variation is solved.

```{r, echo = FALSE}
## Don't show the code because it is quite tedious to explain and only
## used to illustrate the concpet, this is not part of the workflow.
dat <- filterFeatures(spikein, ~ Protein.Accessions == upsProteins[1]) |> 
    longForm(colvars = colnames(colData(spikein)), rowvars = "ionID") |> 
    data.frame() |> 
    filter(ionID == "[R].dLLHVLAFSk.[S]3")
p <- ggplot(dat) +
    aes(x = as.numeric(Condition)) +
    geom_point() 
p + aes(y = value) +
    p + aes(y = log2(value)) +
    plot_annotation(title = "UPS Precursor: [R].dLLHVLAFSk.[S]3") +
    plot_layout(axis_titles = "collect_x") &
    labs(x = "Spike-in dilution factor")
```

Another advantages of log2-transformation is that it provides a scale
that directly relates to biological interpretation. In biology, a
change induced by some condition often results in a fold change in
concentration. Interestingly, the log2 fold change (logFC), which is
the log of the ratio between two conditions, is identical to the
difference between the log of each condition.

$$log_2FC_{B-A} = log_2B - log_2A = log_2 \frac{B}{A}$$

This simplifies the modelling since the effects are now additive, and
the interpretration since a logFC of 1 means that the abundance in B
are $2\times$ higher in $B$ than in $A$, a logFC of 2 means an
increase of $4\times$, for instance.

We perform log2-transformation with `logTransform()` from the
`QFeatures` package.

```{r}
sNames <- names(spikein)
spikein <- logTransform(
    spikein, sNames, name = paste0(sNames, "_log"), base = 2
)
```

### Normalisation

The most common application of `msqrob2` is understand the biological
changes in protein abundance between experimental conditions. However,
changes in measurements between groups can be caused due to technical
factors. For instance, there are systematic fluctuations from
run-to-run that shift the measured intensity distribution. We can 
this explore as follows:

1. We extract the sets containing the log transformed data. This is 
   performed using `QFeatures`' 3-way subsetting. The first entry will
   subset particular features (we select all features so we leave it
   blank), the second entry selects columns of interest (we select all
   columns) and the third entry selects sets of interest (we keep only
   the sets with log data).
2. We use `longForm()` to convert the `QFeatures` object into a long
   table, where each row contains the quantitative information about
   one observation, in which column, row and set it was found. Long
   tables are particularly for manipulating data with the `tidyverse`
   ecosystem, namely with `ggplot2` for visualisation. `longForm()`
   also allows to include annotations, and we here include `Mixture`
   and `TechRepMixture` for filtering and colouring.
3. `longForm()` returns a `DataFrame` which we convert to a 
   `data.frame`. To facilitate interpretation, we filter the data to 
   keep only for the first TMT mixture. 
4. We visualise the density of the quantitative values within each
   sample using the `ggplot2` package. We colour each sample based on 
   its corresponding technical replicate. Remember that each TMT
   mixture has been acquired in triplicate, one run per replicate.

```{r}
spikein[, , paste0(sNames, "_log")] |> ## 1.
    longForm(colvars = c("Mixture", "TechRepMixture")) |> ## 2.
    data.frame() |> ## 3.
    filter(Mixture == "Mixture1") |> 
    ggplot() + ## 4.
    aes(x = value, colour = as.factor(TechRepMixture), group = colname) +
    geom_density() +
    labs(title = "Intensity distribution for each observational unit",
         subtitle = "Before normalisation",
         colour = "Technical replicate")
```

While the intensity distributions overlap, they are not perfectly
aligned. Moreover, the intensity distributions to cluster by technical
replicate. Since each replicate contains all experimental conditions,
we know that these difference stem from technical variability and not
biological variability. Ignoring this effect will, in case of balanced
designs, increase the noise and reduce the statistical power of the
experiment, and may, in case of imbalanced designs, introduce
confounding effects that will bias the results.

Therefore, normalisation will transform the data to put all the
distributions on the same location, such as centering on the mean or
the median, so that the distributions better coincide and overlap.
Here, we will use `normalize()` to subtract the median intensity within
each run. 

```{r}
spikein <- normalize(
    spikein, paste0(sNames, "_log"), name = paste0(sNames, "_norm"),
    method = "center.median"
)
```

Formally, the function applies the follow operation on each sample $i$
across all PSMs $p$:

$$
y_{ip}^{\text{norm}} = y_{ip} - \hat{\mu}_i
$$

with $\hat{\mu}_i$ the median intensity over all observed peptides in
sample $i$. Upon normalisation, we can see that the distribution
nicely overlap (using the same code as above)

```{r}
spikein[, , paste0(sNames, "_norm")] |> ## 1.
    longForm(colvars = c("Mixture", "TechRepMixture")) |> ## 2.
    data.frame() |> ## 3.
    filter(Mixture == "Mixture1") |> 
    ggplot() + ## 4.
    aes(x = value, colour = as.factor(TechRepMixture), group = colname) +
    geom_density() +
    labs(title = "Intensity distribution for each observational unit",
         subtitle = "After normalisation",
         colour = "Technical replicate")
```

Beware there exist numerous types of normalisation methods (see
`?normalize`) and which method to use may be data set dependent. For
instance, some data set may show low overlap of distribution tails
upon normalisation indicating that a simple shift is not sufficient.
In micro-array literature, quantile normalisation is used to force the
median and all other quantiles to be equal across samples, but in
proteomics, quantile normalisation often introduces artifacts due to a
difference in missing peptides across samples

It is important to understand that most normalisation procedures
assume that the majority of the proteins do not change across
conditions and only a small proportion of the proteins are
differentially abundant. This assumption may not be valid in poorly
design spike-in studies [@O-Brien2024-lr] or for pull-down studies,
for example. Dedicated normalisation strategies are then required. 

We completed the data preprocessing for the case we want to use
precursor-level data for the modelling (we will discuss below how to
model protein-level changes from ion-level data). Up to now, the data
from different runs were kept in separate assays. We can now the
normalised sets into an `ions` set using `joinAssays()`. Sets are
joined by stacking the columns (samples) in a matrix and rows
(features) are matched according to a row identifier, here the `ionID`
from the `rowData`.

```{r}
(spikein <- joinAssays(
    spikein, paste0(sNames, "_norm"), fcol = "ionID", name = "ions"
))
```

We have a new set contain 15 runs $\times$ 8 labelled sample = 120
data columns. Note that the 15 sets have `r nrows(spikein)[["ions"]]`
ions in common, leading to a joined set with `r
nrows(spikein)[["ions"]]` rows.

If we want to use protein-level data for modelling, we will need a
summarisation step. Note that this last step is optional.

### Summarisation

The objective of summarisation (also referred to as aggregation) is to
summarise the ion-level intensities into a protein expression value.
We illustrate the motivation behind summarisation using the data for
one of the UPS proteins in Mixture 1 (separating the data for each
technical replicate). We also focus on the 0.125x and the 1x
spike-in conditions. We illustrate the different precursor ions on the
x axis and plot the log2 normalised intensities across samples on y
axis. All the points belonging to the same sample are linked through a
grey line.

```{r, echo = FALSE, fig.height=6, fig.width=6}
spikein[, , paste0(sNames, "_norm")] |>
    filterFeatures(~ Protein.Accessions == "P02787ups") |> 
    longForm(colvars = colnames(colData(spikein)), rowvars = "ionID") |> 
    data.frame() |> 
    filter(Mixture == "Mixture1" & Condition %in% c("1", "0.125")) |> 
    rename(Replicate = "TechRepMixture") |> 
    mutate(colname = factor(colname, levels = unique(colname[order(Condition)]))) |> 
    ggplot() +
    aes(x = ionID, 
        y = value,
        group = colname) +
    geom_line(linewidth = 0.1) +
    geom_point(aes(fill = Condition), size = 3, shape = 21) +
    facet_grid(Replicate ~ ., labeller = label_both) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjus = 0.5),
          legend.position = "top") +
    labs(title = "P02787ups (in Mixture 1)",
         x = "Precursor", y = "log2(norm Intensity)")
```

1. We can see that data for a protein can consist of many precursor
   ions, hence the need for summarisation.
2. We observe that different precursor ions have different 
   intensities, even within the same sample (same line) or within the
   same experimental group (same colour). This is because different
   peptides have different properties and hence different ionisation
   properties which will influence the detectability in the MS.
3. Most precursors are missing in one or two replicates. This problem
   is mitigated in this example as the UPS dilution groups are well
   distributed within each TMT mixture^[For TMT experiments, there is
   one MS2 spectrum for all the labeled samples within the TMT pool.
   So, once the spectrum is identified, it is identified for all the
   samples within that pool.]. However, for unbalanced TMT designs and
   for LFQ experiments, the precursor identification may be 
   inconsistent between groups of interest. Moreover, missed
   identifications can also be caused by low protein abundance.
4. We can see subtle intensity shifts for the same precursor across
   different replicates. These are known as spectrum effects and are
   caused by small run-to-run fluctuations. Note that the data points
   from one precursor in one replicate has been extracted from a
   single MS2 spectrum.
5. We also find outliers. For instance, the first precursor ion 
   doesn't show the same change in intensity between conditions
   compared to majority of the precursors. These outliers can be the
   results of misidentification or fluctuations during MS acquisition.
  
The fact that different precursors have different intensities (2.) and
may be inconsistently identified (3. and 4.) and/or quantified (5.)
can lead to bias if we use simple summarisation approaches such as
summing or averaging the precursor intensities for each sample.
Instead, we will resort to more advanced summarisation approaches to
accommodate for these issues.

Here, we summarise the precursor-level data into protein intensities
through the median polish approach, which alternately removes the
precursor and the sample medians from the data until the summaries
stabilise. Removing the precursor medians will solve issue 2. as it
removes the precursor specific effects. Using the median instead of
the mean will solve issue 5. Note that we perform summarisation for
each run separately, hence the precursor effect will be different for
each run, effectively allowing for a spectrum effect and solviing
issue 5.

`aggregateFeatures()` streamlines this process. It requires the name
of a `rowData` column to group the precursor into proteins (or protein
groups), here `Protein.Accessions`. Summarisation methods are
available from the `MsCoreUtils` package. The function will return a
`QFeatures` object with 15 new sets, each generated from its 
normalised precursor set.

```{r, warning=FALSE}
(spikein <- aggregateFeatures(
    spikein, i = paste0(sNames, "_norm"), 
    name = paste0(sNames, "_proteins"),
    fcol = "Protein.Accessions", fun = MsCoreUtils::medianPolish,
    na.rm = TRUE
))
```

In case of unbalanced designs where issue 3. becomes 
problematic, we found that robust summarisation performs well
[@Sticker2020-rl]. `MsCoreUtils::medianPolish` can then simply be 
replaced with `MsCoreUtils::robustSummary`. 

We can now join the different protein sets into a single set. We omit
the `fcol` argument, meaning that the set rows will be matched based
on the row names (generated by `aggregateFeatures()`).

```{r}
spikein <- joinAssays( 
    spikein, paste0(sNames, "_proteins"), "proteins"
)
```

## Data exploration

Data exploration aims to highlight the main sources of variation in
the data prior to data modelling and can pinpoint to outlying or
off-behaving samples. A common approach for data exploration is to
perform dimension reduction, such as Multi Dimensional Scaling (MDS).
We will first extract the set to explore using `getWithColData()`.
This function extracts the set of interest along with all the
associated sample annotations (used for plot colouring).

```{r}
se <- getWithColData(spikein, "ions")
```

We then use the `scater` package to compute and plot the PCA. For
technical reasons, it requires `SingleCellExperiment` class object,
but these can easily be generated from a `SummarizedExperiment`
object. 

```{r}
library("scater")
se <- runMDS(as(se, "SingleCellExperiment"), exprs_values = 1)
```

We can now explore the data structure while colouring for factors of
interest, here `Condition`, `Run` and `Mixture`.

```{r, fig.width=8, fig.height=3}
plotMDS(se, colour_by = "Condition") +
  plotMDS(se, colour_by = "Run") + 
  plotMDS(se, colour_by = "Mixture")
```

There is a strong run-to-run effect, which is partly explained by a
mixture effect as the runs from the same cluster tend to be closer
than runs from different mixtures. The condition effect is much more
subtle to find, probably because we know only a few UPS proeins were
spiked in while the majority of the background proteins are unchanged.

As discussed above, the median polish summarisation should remove part
of the run to run effect. We repeat the data exploration, but using
the protein-level data.

```{r}
se <- getWithColData(spikein, "proteins")
se <- runMDS(as(se, "SingleCellExperiment"), exprs_values = 1)
plotMDS(se, colour_by = "Run")
```

While the run effects are smaller on the protein-level MDS compared to
the precursor-level MDS (the samples are less clustered per run), we
can see that normalisation and summarisation alone are not sufficient
to correct for these unwanted effects. We will take care of these
effects during the data modelling.

## Data modelling{#sec-modelling}

Proteomics data contain several sources of variation that need to be
accounted for by the model. Before delving into these sources of 
variation, we here show how to run the model that accounts for all
relevant sources of variation in the spike-in experiment, which we
have shown performs best [@Vandenbulcke2025-sj].

```{r, eval = FALSE}
spikein <- msqrobAggregate(
    spikein,  i = "ions",
    formula = ~ 0 + Condition + ## fixed effect for experimental condition
        (1 | Channel) + ## random effect for channel
        (1 | Mixture) + ## random effect for mixture
        (1 | Run) + ## random effect for run
        (1 | Run:Channel) + ## random effect for PSMs for the same protein in a channel of a run
        (1 | Run:ionID), ## random effect for ions in the same spectrum of an MS run
    fcol = "Protein.Accessions",
    modelColumnName = "msqrob_psms_rrilm",
    robust = TRUE, ridge = TRUE
)
```

We will now build up the model by progressively adding the
different sources of variation.

### Effect of treatment of interest{#sec-run_model}

We model the source of variation induced by the experimental
treatment of interest as a fixed effect, which we consider non-random,
i.e. the treatment effect is assumed to be the same in repeated
experiments, but it is unknown and has to be estimated. When modelling
a typical label-free experiment at the protein level, the model boils
down to a linear model, again we suppress the index for protein:

$$
y_r = \mathbf{x}^T_r \boldsymbol{\beta} + \epsilon_r,
$$

with $y_r$ the $\log_2$-normalized protein intensities in run r;
$\mathbf{x}_r$ a vector with the covariate pattern for the sample in
run $r$ encoding the intercept, treatment, potential batch effects and
confounders; $\boldsymbol{\beta}$ the vector of parameters that model
the association between the covariates and the outcome; and
$\epsilon_r$ the residuals reflecting variation that is not captured
by the fixed effects. Note that $\mathbf{x}_r$ allows for a flexible
parameterization of the treatment beyond a single covariate, i.e.
including a 1 for the intercept, continuous and categorical variables
as well as their interactions. For all models considered in this work,
we assume the residuals to be independent and identically distributed
(i.i.d) according to a normal distribution with zero mean and constant
variance, i.e. $\epsilon_{r} \sim N(0,\sigma_\epsilon^2)$, that can
differ from protein to protein.

Now we defined a model, we must estimate from the data. Using 
`msqrob()`, the model translates into the following code:

```{r run_msqrob_protein1, cache=TRUE, warning=FALSE}
spikein <- msqrob(
    spikein,  i = "proteins",
    formula = ~  0 + Condition, ## fixed effect for experimental condition
    robust = TRUE, ridge = TRUE,
    modelColumnName = "msqrob_rrilm"
)
```

The function takes the `QFeatures` object, extracts the quantitative
values from the `"proteins"` set generated during summarisation, and
fits a simple linear model with `Condition` as covariate, which is
automatically retrieved from `colData(spikein)`. Note, that we use an
encoding without intercept `~ 0 +`. This makes it more straightforward
to define contrasts for one-way ANOVA designs with a treatment
involving a single factor. Indeed, by suppressing the intercept, a
model parameters is estimated for each group. Otherwise, `msqrob2`
selects one of the groups as the reference group, for which its model
parameter is absorbed in the intercept.

**TODO**: do we need to suppress the intercept? We documented this for
the msqrob2TMT vignette but my feeling is that we should learn users
to perform to build contrasts with intercepts. However, regarding 
ridge regression, suppressing the intercept is better. 

**TODO**: expand the paragraph below?

We also enable M-estimation (`robust = TRUE`) for improved robustness
against outliers. We also enable ridge regression (`ridge = TRUE`)
for fixed effects. Ridge regression stabilises the parameter
estimation in case where the number of parameters are close to the
number of available samples. Keep in mind that ridge regression is
irrelevant when modelling a single fixed effect with only 2 factors.

The fitting results are available in the `msqrob_rrilm` column of the
`rowData` (by default, the new column is called `msqrobModels`). More
specifically, the modelling output is stored in the `rowData` as a
`statModel` object, one model per row (protein). We will see in a
later section how to perform statistical inference on the estimated
parameters. 

```{r}
models <- rowData(spikein[["proteins"]])[["msqrob_rrilm"]]
models[1:3]
```

### Effect of TMT channel and run

As label-free experiments contain only a single sample per run,
run-specific effects will be absorbed in the residuals. However, the
data analysis of labeled experiments, e.g. using TMT multiplexing,
involving multiple MS runs has to account for run- and label-specific
effects, explicitly. If all treatments are present in each run, and if
channel swaps are performed so as to avoid confounding between channel
and treatment, then the model parameters can be estimated using fixed
channel and run effects. Indeed, for these designs run acts as a
blocking variable as all treatment effects can be estimated within
each run.

However, for more complex designs this is no longer possible and the
uncertainty in the estimation of the mean model parameters can involve
both within and between channel and run variability. For these designs
we can resort to mixed models where the channel and run effect are
modelled using random effects, i.e. they are considered as a random
sample from the population of all possible runs (channel labels),
which are assumed to be i.i.d normally distributed with mean 0 and
constant variance,  $u_r \sim N(0,\sigma^{2,\text{run}})$
($u_{channel} \sim N(0,\sigma^{2,\text{channel}})$). The use of random
effects thus models the correlation in the data, explicitly. Indeed,
protein intensities that are measured within the same run (channel)
will be more similar than protein intensities between runs (channels).

Hence, the model is extended to:

$$
y_{rc} =
\mathbf{x}^T_{rc} \boldsymbol{\beta} + u_c^\text{channel} + u_r^\text{run} +
\epsilon_{rc}
$$
with $y_{rc}$ the normalised $\log_2$ protein intensities in run $r$
and channel $c$, $u_c^\text{channel}$ the effect introduced by
the label of channel $c$, and $u_r^\text{run}$ the effect for MS run
$r$.

This translates in the following code:

```{r run_msqrob_protein2, cache=TRUE}
spikein <- msqrob(
    spikein,  i = "proteins",
    formula = ~  0 + Condition + ## fixed effect for experimental condition
        (1 | Channel) + ## random effect for channel
        (1 | Run), ## random effect for MS run
    robust = TRUE, ridge = TRUE,
    modelColumnName = "msqrob_rrilmm"
    )
```

Note here that we have commented out the random effect for channel. In
practice, normalisation already removes part of the channel effect and
is sufficient. You can experiment this yourself by removing the
comment sign `#` in front of `(1 | Channel) +` across the vignette,
and see how the results may change.

### Effect of replication

Some experiments also include technical replication where a TMT
mixture can be acquired multiple times. This again will induce
correlation. Indeed, protein intensities from the same mixture will be
more alike than those of different mixtures. Hence, we also include a
random effect to account for this pseudo-replication, i.e.
$u^\text{mix}_m \sim N(0, \sigma^{2,\text{mix}})$. The model thus
extends to:

$$
y_{rcm} =
\mathbf{x}^T_{rcm} \boldsymbol{\beta} +  u_{c}^\text{channel} +
u_r^\text{run} + u_m^\text{mix} + \epsilon_{rcm}
$$

with $m$ the index for mixture.

The model translates to the following code:

```{r run_msqrob_protein3, cache=TRUE, warning=FALSE}
spikein <- msqrob(
    spikein,  i = "proteins",
    formula = ~  0 + Condition + ## fixed effect for experimental condition
        (1 | Channel) + ## random effect for channel
        (1 | Run) + ## random effect for MS run
        (1 | Mixture), ## random effect for mixture
    robust = TRUE, ridge = TRUE,
    modelColumnName = "msqrob_rrilmm",
    overwrite = TRUE
)
```

We use `overwrite = TRUE` to overwrite the previous results in the
`rowData`.

### PSM-level modelling

Above, we modelled the data at the protein level. However, we could
also directly estimate the treatment effect from PSM-level data. This
will again induce additional levels of correlation. Indeed, the
intensities for the different reporter ions in a TMT run within the
same spectrum (PSM) will be more similar than the intensities between
PSMs. We therefore need to add a random effect term to account for the
within PSM correlation structure, i.e. $u^\text{PSM}_{rp} \sim
N(0,\sigma^{2,\text{PSM}})$. Moreover, in each channel of a run
multiple PSM intensities are picked up for each protein. Hence,
intensities from different PSMs for a protein in the same channel of a
run will be more alike than intensities of different PSMs for the same
protein between channels of runs, and we will address this correlation
with a channel-specific random effect nested in run, i.e.
$u_{rc}^{channel} \sim N(0,\sigma^{2,\text{channel}})$. The model then
becomes:

$$
y_{rcmp} =
\mathbf{x}^T_{rcmp} \beta + u_{c}^\text{channel} +
u_r^\text{run} + u_m^\text{mix}  +
u_{rc}^\text{channel} + u_{rp}^\text{PSM} + \epsilon_{rcmp}
$$
with $y_{rcmp}$ the $\log_2$-normalized PSM intensities for run $r$
with label $c$ in mixture $m$ and peptide ion $p$. Note, that the peptide ion random
effect is also nested within each run since each spectrum is described
by run-specific characteristics.

The model translates to the code below. Note that we here no longer
use `msqrob()`, but `msqrobAggregate()`. The latter will combine
annotations from the `colData` (i.e. `"Condition"`, `"Channel"`,
`"Run"`, `"Mixture"`) and from the `rowData` (i.e.
`"ionID"`). Moreover, we need to tell the function how the PSM-level
data is grouped to protein data through the `fcol` argument, here we
will group PSMs by the `Protein.Accessions`.

```{r msqrob_psm_rrilmm, cache=TRUE, warning=FALSE}
spikein <- msqrobAggregate(
    spikein,  i = "ions",
    formula = ~  0 + Condition + ## fixed effect for experimental condition
        (1 | Channel) + ## random effect for channel
        (1 | Run) + ## random effect for Run
        (1 | Mixture) + ## random effect for mixture
        (1 | Run:Channel) + ## random effect for channel nested in run
        (1 | Run:ionID), ## random effect for ion nested in run
    fcol = "Protein.Accessions",
    modelColumnName = "msqrob_psm_rrilmm",
    name = "proteins_msqrob",
    robust = TRUE, ridge = TRUE
)
```

So, we built the model shown at the beginning of this section,
effectively accounting for all sources of variation in TMT-based
proteomics data.

### Precursor or protein-level model?

**TODO**: discuss precursor-level vs protein-level models

### Robust ridge estimation?

**TODO** discuss ridge vs no ridge and robust vs no robust

## Statistical inference

We can now convert the biological question "does the spike-in
condition affect the protein intensities?" into a statistical
hypothesis. In other words, we must convert this question in a
combination of the model parameters, also referred to as a contrast.
To aid defining contrasts, we will visualise the experimental design
using the `ExploreModelMatrix` package. Since we are not interested in
technical effects, we will only focus on the variable of interest,
here `Condition`.

```{r}
library("ExploreModelMatrix")
vd <- VisualizeDesign(
    sampleData =  colData(spikein),
    designFormula = ~ 0 + Condition,
    textSizeFitted = 4
)
vd$plotlist
```

The plot above depicts that the average protein intensity for the 
spike-in dilution factor 1x is provided by the parameter `Condition1`,
the `Condition0.667` parameter for the dilution factor 0.667x, etc.

With `getCoef()`, we can retrieve the estimated model parameters. We
will focus on the last model as an illustration, but the same approach
applies for any model estimated by `msqrob()` or `msqrobAggregate()`.
We start with extracting the model output, stored as `StatModel`
objects, from the `rowData`. Next, `getCoef()` retrieves the estimated
model parameters:

```{r}
models <- rowData(spikein[["proteins_msqrob"]])$msqrob_psm_rrilmm
params <- getCoef(models[[1]])
head(params)
```

The PSM model estimated `r #length(params)` parameters to model the
fixed and random effects. However, we are interested, for this data
set, in the parameters that model the effect of `Condition`.

```{r}
params[grep("Condition", names(params))]
```

Note the `"ridge"` tag in front of the parameter names that indicates
the parameters have been estimated using ridge penalisation. For this
protein we can see that the effects of condition are very close to
zero, as expected since the protein is part of the HeLa background.
However, we can explore the parameters for one of the UPS proteins.

```{r}
params <- getCoef(models[["O00762ups"]])
params[grep("Condition", names(params))]
```

Let's know verify the result provide the expected fold change. To do
so we define a contrast, that is a parameter combination that provide
an answer to the research question, for instance for the average
log2 difference in intensity between condition 1x and condition 0.5x.
Since this is a benchmark study, the obvious answer is $log_2(1) -
log_2(0.5) = 1$.

```{r}
unname(params["ridgeCondition1"] - params["ridgeCondition0.5"])
```

This value is close to the expected value. Now, the question is how
statistically significant is the estimated log2 fold change.

### Hypothesis testing

As shown above, the average difference intensity between the 1x and
the 0.5x conditions is provided by `ridgeCondition1 -
ridgeCondition0.5`. This combination of parameters is called a 
contrast. We next define a null hypothesis, here that the differences
between the two groups is zero.

```{r}
hypothesis <- "ridgeCondition1 - ridgeCondition0.5 = 0"
```

`makeContrast()` converts the hypothesis into a formal contrast 
matrix with parameter names as rows and hypotheses in columns (you 
can specify [multiple hypotheses](#sec-multiple_contrasts)). 

```{r}
(L <- makeContrast(
    "ridgeCondition1 - ridgeCondition0.5 = 0",
    c("ridgeCondition1", "ridgeCondition0.5")
))
```

We can now test our null hypothesis using `hypothesisTest()` which
takes the `QFeatures` object with the fitted model and the contrast we
just built (recall that the model estimation has been stored in the
`proteins_msqrob` set). `msqrob2` automatically applies the hypothesis
testing to all proteins in the data.

```{r}
spikein <- hypothesisTest(
    spikein, i = "proteins_msqrob", contrast = L,
    modelColumn = "msqrob_psm_rrilmm"
)
```

The results are stored in the set containing the model, here
`proteins_msqrob`. Let's retrieve the results from the `rowData`.

```{r}
inference <- rowData(spikein[["proteins_msqrob"]])$"ridgeCondition1 - ridgeCondition0.5"
inference$Protein <- rownames(inference)
inference$isUps <- grepl("ups", inference$Protein)
head(inference)
```

The last row is filled with missing values because data modelling
resulted in a `fitError` (we will explore in a [later
section](#sec-fiterror) how we can deal with proteins that could not
be fit).

### Volcano plots

We can use the table above directly to build a volcano plot using
`ggplot2` functionality. We also highlight which proteins are UPS
standards, known to be differentially abundant by experimental design.

```{r}
ggplot(inference) +
  aes(x = logFC,
      y = -log10(adjPval),
      color = isUps) +
  geom_point() +
  scale_color_manual(
    values = c("grey20", "firebrick"), name = "",
    labels = c("HeLA background", "UPS standard")
  ) +
  ggtitle("msqrob_psm_rrilm model",
          "Hypothesis test: Condition 1x - 0.5x = 0")
```

Note, that `r sum(inference$adjPval < 0.05, na.rm = TRUE)` proteins
are found to be differentially abundant containing almost all UPS
proteins, as expected.

```{r}
table(is_significant = inference$adjPval < 0.05, 
      is_ups = grepl("ups", inference$Protein))
```

### Fold change distributions

As this is a spike-in study with known ground truth, we can also plot
the log2 fold change distributions against the expected values, in
this case 0 for the HeLa proteins and 1 for the UPS standards.

```{r}
ggplot(inference) +
    aes(y = logFC,
        x = isUps,
        colour = isUps) +
    geom_boxplot() +
    geom_hline(yintercept = c(0, 1), colour = c("grey20", "firebrick")) +
    scale_color_manual(
        values = c("grey20", "firebrick"), name = "",
        labels = c("HeLA background", "UPS standard")
    ) +
    ggtitle("Distribution of the log2 fold changes",
            "Hypothesis test: Condition 1x - 0.5x = 0")
```

Estimated log2 fold change for HeLa proteins are closely distributed
around 0, as expected. log2 fold changes for UPS standard proteins are
distributed toward 1, although it is underestimated as reported
previously [@Savitski2011-qi].

### Heatmap

We can also build a heatmap for the significant proteins which are
obtained by filtering the inference table.

**TODO** use ComplexHeatmap for building a heatmap? 

### Detail plots

We can explore the PSM intensities for a protein to validate the
statistical inference results. For example, let's explore the
intensities for the protein with the most significant difference.

```{r}
(targetProtein <- rownames(inference)[which.min(inference$adjPval)])
```

To obtain the required data, we perform a little data manipulation
pipeline:

1. We use the `QFeatures` subsetting functionality to retrieve all data
   related to `r #targetProtein` and focusing on the `ions` set that
   contains the peptide ion data used for model fitting.
2. We use `longForm()` to convert the object into a table suitable for
   plotting.
3. We remove missing values for plotting.
4. We reorder the sample identifiers to improve visualisation.

```{r}
ionData <- spikein[targetProtein, , "ions"] |> #1
    longForm(colvars = colnames(colData(spikein)), #2
               rowvars = c("Protein.Accessions", "ionID")) |>
    data.frame() |>
    filter(!is.na(value)) |> #3
    mutate(colname = factor(colname, levels = unique(colname[order(Condition)]))) #4
```

Finally, we plot the log2 normalised intensities for each sample.
Since the protein is modelled at the peptide ion level, multiple ion
intensities are recorded in each sample. Each ion is linked across
samples using a grey line. Samples are colored according to UPS
spike-in condition. Finally, we split the plot in facets, one for each
mixture, to visualise the heterogeneity induced by sample preparation.

```{r, fig.width=10, fig.height=3}
ggplot(ionData) +
    aes(x = colname,
        y = value) +
    geom_line(aes(group = ionID), linewidth = 0.1) +
    geom_point(aes(colour = Condition)) +
    facet_grid(~ Mixture, scales = "free") +
    ggtitle(targetProtein) +
    theme_minimal() +
    theme(axis.text.x = element_blank())
```

## Protein-level models

Performing the statistical inference for summarisation-based models,
hence modelling protein-level data, is very similar as for the
PSM-based models shown above. Let's apply the same statistical
inference pipeline for the `msqrob_rrilmm` model stored in the
`QFeatures` object.

```{r}
L <- makeContrast(
    "ridgeCondition1 - ridgeCondition0.5 = 0",
    c("ridgeCondition1", "ridgeCondition0.5")
)
spikein <- hypothesisTest(
    spikein, i = "proteins", contrast = L,
    modelColumn = "msqrob_rrilmm"
)
inferenceProt <- rowData(spikein[["proteins"]])$"ridgeCondition1 - ridgeCondition0.5"
```

We build the volcano using the same code:

```{r}
inferenceProt$protein <- rownames(inferenceProt)
inferenceProt$isUps <- grepl("ups", inferenceProt$protein)
ggplot(inferenceProt) +
    aes(x = logFC,
        y = -log10(adjPval),
        color = isUps) +
    geom_hline(yintercept = -log10(0.05)) +
    geom_point() +
    scale_color_manual(
        values = c("grey20", "firebrick"), name = "",
        labels = c("HeLA background", "UPS standard")
    ) +
    ggtitle("msqrob_rrilm model",
            "Hypothesis test: Condition 1x - 0.5x = 0\nProtein-level modelling")
```

We plot the fold change distributions:

```{r}
ggplot(inferenceProt) +
    aes(y = logFC,
        x = isUps,
        colour = isUps) +
    geom_boxplot() +
    geom_hline(yintercept = c(0, 1), colour = c("grey20", "firebrick")) +
    scale_color_manual(
        values = c("grey20", "firebrick"), name = "",
        labels = c("HeLA background", "UPS standard")
    ) +
    ggtitle("Distribution of the log2 fold changes",
            "Hypothesis test: Condition 1x - 0.5x = 0\nProtein-level modelling")
```

Exploring the intensities at the protein level is simplified compared
to PSM-level exploration since every sample now contains a single
observation, the protein intensity.

```{r}
data.frame(intensity = assay(spikein[["proteins"]])[targetProtein, ],
           colData(spikein),
           colname = colnames(spikein[["proteins"]])) |>
    mutate(colname = factor(colname, levels = unique(colname[order(Condition)]))) |>
    ggplot() +
    aes(x = colname,
        y = intensity) +
    geom_point(aes(colour = Condition)) +
    facet_grid(~ Mixture, scales = "free") +
    ggtitle(targetProtein) +
    theme_minimal() +
    theme(axis.text.x = element_blank())
```

Notice how the summarisation-based approach hides the variation
associated with the measurement of different peptide ions within the
same protein, as well as discrepancies between peptide identification
rates across mixtures.

### Inference for all pairwise comparisons between conditions

For a factor variable, we often want to infer on all pairwise
comparisons between the groups. Note, that our models have a fixed
effect component that consist of a single factor and that we have
chosen to suppress the intercept. `msqrob2` therefore returned models
with a separate model parameter to estimate the mean for every group.

```{r}
design_fixed  <- model.matrix(~ 0 + Condition, colData(spikein))
(param_names_fixed <- colnames(design_fixed))
```

If we use ridge regression, `msqrob2` by default will put the prefix
`ridge` to the parameter names of the fixed effects.

```{r}
(param_names_fixed <- paste0("ridge", param_names_fixed))
```

We now make all pairwise contrasts. The function `combn()` can make all
combinations of a vector and we apply the function `paste()` with the
argument `collapse = " - "` to these combinations. This makes a vector
of strings specifying all contrasts of interest. Upon pasting "= 0"
to each of the contrasts, all null hypotheses corresponding to the
pairwise comparisons are specified.

Note, that we first sort the parameter names in decreasing order to
ensure that a positive log2 fold change estimate refers to an
upregulation in the highest spike-in condition involved in the
comparison.

```{r}
(hypotheses <- param_names_fixed |>
     sort(decreasing = TRUE) |>
     combn(2, paste, collapse=" - ") |>
     paste("= 0"))
```

We now have specified the null hypotheses for all pairwise contrasts
of interest. Below, we will generate the contrast matrix for these six
contrasts.

```{r}
(L <- makeContrast(hypotheses, parameterNames = param_names_fixed))
```

The next step is to perform hypothesis tests for each contrast

```{r}
spikein <- hypothesisTest(
    spikein, i = "proteins_msqrob",
    contrast = L,
    modelColumn = "msqrob_psm_rrilmm",
    overwrite = TRUE
)
```

Six columns have been added to the row data, one for each contrast.

```{r}
colnames(rowData(spikein[["proteins_msqrob"]]))
```

The results of contrast `"ridgeCondition1 - ridgeCondition0.5"` can be
retrieved as follows.

```{r}
head(rowData(spikein[["proteins_msqrob"]])[,"ridgeCondition1 - ridgeCondition0.5"])
```

Note, the we can use the same code to perform the hypothesis tests and
extract the results for the protein-level model.

```{r}
spikein <- hypothesisTest(
    spikein, i = "proteins",
    contrast = L,
    modelColumn = "msqrob_rrilmm",
    overwrite = TRUE
)
```

```{r}
head(rowData(spikein[["proteins"]])[,"ridgeCondition1 - ridgeCondition0.5"])
```

## Dealing with `fitErrors`{#sec-fiterror}

Missing value patterns in the data may lead to non-estimable
parameters. This is recognised by `msqrob2` and will lead to
`fitError`s which is a type of model output where the model could not
be fit. This information is available from the `StatModel` objects.

```{r}
rowData(spikein[["proteins_msqrob"]])[["msqrob_psm_rrilmm"]] |>
    sapply(function(x) x@type) |>
    table()
```

We suggest 3 strategies for dealing with these `fitError`s.

### Removing the random effect of sample

This strategy only applies for PSM-level models. Some proteins are
difficult to detect and may be quantified by a single peptide ion
species. In these cases, every sample contains a single observation
for the protein and hence no random effect of `Run:Channel` can be
estimated. While the results for such one-hit wonders are
questionable, we provide `msqrobRefit()` to refit a new model for a
subset of proteins of interest.

**Work in progress**: we plan to include soon the function to perform
the refitting in `msqrob2`. Below, you can find a prototype of such
functionality. See `?msqrobAggregate` for documentation of the
arguments.

```{r}
msqrobRefit <- function(object, formula, i, subset, fcol, name,
                        modelColumnName, ...) {
    seti <- getWithColData(object, i)
    setj <- getWithColData(object, name)
    if (any(!subset %in% rowData(seti)[[fcol]]))
        stop("Some entries in 'subset' not found in '", fcol,
             "' (rowData of set '", i, "')")
    setjRefit <- msqrobAggregate(
        seti[rowData(seti)[[fcol]] %in% subset, ],
        formula = formula, fcol = fcol, modelColumnName = modelColumnName,
        ...
    )
    rowData(setj)[[modelColumnName]][subset] <-
        rowData(setjRefit)[[modelColumnName]][subset]
    modelsNew <- rowData(setj)[[modelColumnName]]
    hlp <- limma::squeezeVar(
        var = vapply(modelsNew, getVar, numeric(1)),
        df = vapply(modelsNew, getDF, numeric(1))
    )
    for (ii in seq_along(modelsNew)) {
        modelsNew[[ii]]@varPosterior <- as.numeric(hlp$var.post[ii])
        modelsNew[[ii]]@dfPosterior <- as.numeric(hlp$df.prior + getDF(modelsNew[[ii]]))
    }
    rowData(object[[name]])[[modelColumnName]] <- modelsNew
    object
}
```

In this case, we want to refit a model without a sample effect for
one-hit-wonder proteins. This information can be retrieved from the
aggregation results, using `aggcounts()`. This getter function
provides the number of features used when performing summarisation for
each protein in each sample.

```{r}
counts <- aggcounts(spikein[["proteins_msqrob"]])
counts[1:5, 1:5]
```

One-hit wonder proteins are proteins for which the number of feature
used for summarisation does not exceed 1 peptide ion across samples.

```{r}
oneHitProteins <- rownames(counts)[rowMax(counts) == 1]
```

Using `msqrobRefit()` is very similar to `msqrobAggregate()`, see here
however that we adapted the formula to remove the random effect for
channel nested within run. We also mention which proteins must be
refit using the `subset` argument.

```{r msqrobRefit, cache = TRUE}
spikein <- msqrobRefit(
    spikein, i = "ions",
    subset = oneHitProteins,
    formula = ~ 0 + Condition + ## fixed effect for experimental condition
        (1 | Channel) + ## fixed effect for channel
        (1 | Mixture) + ## random effect for mixture
        (1 | Run ) + ## random effect for run
        (1 | Run:ionID), ## random effect for PSM nested in MS run
        ## random effect for channel nested in run has been removed
    fcol = "Protein.Accessions",
    modelColumnName = "msqrob_psm_rrilmm",
    name = "proteins_msqrob",
    robust = TRUE, ridge = TRUE
)
```

Let's see how removing the random effect of channel within run for one-hit-wonder proteins reduced the number of `fitError`s.

```{r}
fitTypes <- rowData(spikein[["proteins_msqrob"]])[["msqrob_psm_rrilmm"]] |>
    sapply(function(x) x@type)
table(fitTypes)
```

### Manual inspection

One protein is still non-estimable upon refitting and requires
additional data exploration to understand why the model cannot be
estimated. Let us take the protein that cannot be fitted.

```{r}
proteinError <- names(fitTypes[fitTypes == "fitError"])[[1]]
```

To understand the problem, we plot the data for that protein using
the same `QFeatures` pipeline described above.

```{r}
ionData <- spikein[proteinError, , "ions"] |>
    longForm(colvars = colnames(colData(spikein)),
               rowvars = c("Protein.Accessions", "ionID")) |>
    data.frame() |>
    filter(!is.na(value)) |>
    mutate(colname = factor(colname, levels = unique(colname[order(Condition)]))) #4
```

Hence, we here plot the data in function of the `Channel`
(x-axis), `Condition` (colour) and `Mixture` (shape).

```{r}
ggplot(ionData) +
    aes(x = colname,
        y = value) +
    geom_point(aes(colour = Condition)) +
    facet_grid(~ Mixture, scales = "free") +
    ggtitle(targetProtein) +
    theme_minimal() +
    theme(axis.text.x = element_blank())
```

We can immediately spot that PSM intensities are only present in
mixture 3. Hence, the mixed model cannot be fitted with a random
effect for mixture. A solution would be drop the random effect for
mixture, provided that a data analysis expert and/or a field
specialist deems it reasonable. This requires expert intervention to
simplify the model definition based on the available data set so as to
provide valid statistical inference on the research hypotheses.

`msqrob2` flags these problematic proteins instead of defining ad-hoc
heuristics, avoiding potentially misleading conclusions. The expert
can then decide to refit a simpler model using `msqrobRefit()`.

Note, that the same approach can be applied for summarisation-based
models that start from protein data.

```{r}
se <- getWithColData(spikein, "proteins")
data.frame(intensity = assay(se)[proteinError, ],
           colData(spikein),
           colname = colnames(se)) |>
    filter(!is.na(intensity)) |>
    mutate(colname = factor(colname, levels = unique(colname[order(Condition)]))) |>
    ggplot() +
    aes(x = colname,
        y = intensity) +
    geom_point(aes(colour = Condition)) +
    facet_grid(~ Mixture, scales = "free") +
    ggtitle(proteinError, "associated to a fitError\nSummarised protein intensities (median polish)") +
    theme_minimal() +
    theme(axis.text.x = element_blank())
```

The same conclusion applies as for the PSM-level data. In fact, this
is the same plot as above since the protein is also a one-hit wonder,
what seriously questions the reliability of the data for protein. This
example illustrates the relevance of `msqrob2` to safeguard against
automatic model simplification that may be otherwise fall unnoticed by
the user.

### Imputation

The last strategy to deal with fit errors is to impute missing values
so that all models can be estimated. `QFeatures` provides a large
panel of imputation strategies through `impute()`. Identifying which
imputation strategy is most suited for this data set is outside the
scope of this vignette, and we here arbitrarily decide to use KNN
imputation.

```{r}
(spikein <- impute(
    spikein, i = "ions", name = "ions_imputed",
    method = "knn", colmax = 1
))
```

The function added a new set `ions_imputed` which we can use to fit
the PSM model.

```{r msqrob_psm_rrilmm_imputed, cache=TRUE}
spikein <- msqrobAggregate(
    spikein,  i = "ions_imputed",
    formula = ~ 0 + Condition + ## fixed effect for experimental condition
        (1 | Channel) + ## random effect for channel
        (1 | Mixture) + ## random effect for mixture
        (1 | Run) + ## random effect for run
        (1 | Run:Channel) + ## random effect for PSMs from the same protein in a channel of a run
        (1 | Run:ionID), ## random effect for ions in the same spectrum of an MS run
    fcol = "Protein.Accessions",
    modelColumnName = "msqrob_psm_rrilmm",
    name = "proteins_msqrob_imputed",
    robust = TRUE, ridge = TRUE
)
```

We here assess how many models have been estimated for all proteins
upon imputation.

```{r}
rowData(spikein[["proteins_msqrob_imputed"]])[["msqrob_psm_rrilmm"]] |>
    sapply(function(x) x@type) |>
    table()
```

Again `fitError`s were generated for one-hit-wonder proteins.

```{r, cache=TRUE}
counts <- aggcounts(spikein[["proteins_msqrob_imputed"]])
oneHitProteins <- rownames(counts)[rowMax(counts) == 1]
spikein <- msqrobRefit(
    spikein, i = "ions_imputed",
    subset = oneHitProteins,
    formula = ~ 0 + Condition + ## fixed effect for experimental condition
        (1 | Channel) + ## random effect for channel
        (1 | Mixture) + ## random effect for mixture
        (1 | Run ) + ## random effect for run
        (1 | Run:ionID), ## random effect for PSM nested in MS run
        ## random effect for channel nested in run has been removed
    fcol = "Protein.Accessions",
    modelColumnName = "msqrob_psm_rrilmm",
    name = "proteins_msqrob_imputed",
    robust = TRUE, ridge = TRUE
)
rowData(spikein[["proteins_msqrob_imputed"]])[["msqrob_psm_rrilmm"]] |>
    sapply(function(x) x@type) |>
    table()
```

Upon refit, no `fitError`s were generated for any proteins, as expected. Be
mindful that although this approach no longer requires strong
statistical insights, the results upon imputation will be highly
depended on the suitability of the imputation approach.

We can apply the same approach for upon summarisation, starting from
the imputed peptide ion data.

```{r, cache=TRUE}
spikein <- aggregateFeatures(
    spikein, i = "ions_imputed", name = "proteins_imputed",
    fcol = "Protein.Accessions", fun = MsCoreUtils::medianPolish,
    na.rm = TRUE
)
spikein <- msqrob(
    spikein,  i = "proteins_imputed",
    formula = ~ 0 + Condition + ## fixed effect for experimental condition
        (1 | Channel) + ## random effect for channel
        (1 | Mixture) + ## random effect for mixture
        (1 | Run), ## random effect for MS run
    robust = TRUE, ridge = TRUE,
    modelColumnName = "msqrob_rrilmm",
    overwrite = TRUE
)
models <- rowData(spikein[["proteins_imputed"]])[["msqrob_rrilmm"]]
table(sapply(models, function(x) x@type))
```

## Testing muliple contrasts at once{#sec-multiple_contrasts}

**TODO**

## Conclusion

In this vignette, we have demonstrated how to run msqrob2TMT
workflows. Because the packages relies on the `QFeatures` data class,
we could demonstrate the implementation of a complete pre-processing
workflow: sample filtering, PSM filtering, missing value management,
log2-transformation, normalisation, (optionally) summarisation and
(optionally) imputation.

Once pre-processed, we use the `msqrob2` package to model all sources
of variability in the MS experiment: effect of treatment of interest,
effect of TMT labelling, effect of the MS acquisition run, and the
effect of replication. We built protein-level models, but we have also
shown that we can build PSM-level models if we also include a spectrum
effect and an effect for channel nested within run.

We showed how to run statistical inference on the modelling results to
retrieve the significance of differentially abundant proteins. We
explored statistical results through volcano plots and boxplots of the
log2 fold changes and visually validated the results for one protein
by plotting the input data. We have shown the inference pipeline is
similar for both PSM-level models and protein-level models.
Furthermore, we illustrated how to streamline the analysis of multiple
hypothesis tests.

Finally, we have demonstrated how to deal with proteins that cannot be
modelled due to missing values. For PSM-level models, we can remove
the random effects for channel within run that cannot be estimated for
one-hit-wonder proteins. We can also manually inspect how missing
values can influence the model design, and refit a simplified model
upon expert's intervention. Finally, we can impute missing values,
which unlocks model fitting, but imposes strong assumption on the
validity of the imputation approach and the reliability of the
predicted values.
