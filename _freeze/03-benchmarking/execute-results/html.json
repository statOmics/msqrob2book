{
  "hash": "0b1226547def0e7f23a3201d9bb288fd",
  "result": {
    "engine": "knitr",
    "markdown": "# Benchmarking workflows {#sec-benchmarking}\n\n\n::: {.cell}\n\n:::\n\n\nIn the previous chapters we have seen three different approaches to\nmodel the data:\n\n- [Approach 1](#sec-tmt_protein_model): start from a PSM-level table,\n  compute the protein summaries and model the data at the protein \n  level.\n- [Approach 2](#sec-tmt_ion_model): start from a PSM-level table \n  and model the ion-level data to obtain protein-level results.\n- [Approach 3](#sec-basics): start from a peptide-level table, \n  compute the protein summaries and model the data at the protein\n  level.\n\nThere are further possible approaches to model the data: \n\n- Approach 4: start from a peptide-level table and model the \n  peptide-level data to obtain protein-level results. \n- Approach 5: start from a protein-level table (generated by MaxQuant\n  using maxLFQ) and model the protein-level data to obtain \n  protein-level results.\n\nIn this chapter, we will attempt to understand whether these different\napproaches lead to difference in modelling performance. To\nexplore these differences, we will conduct a benchmarking experiment \nusing the [E. coli spike-in experiment](#sec-ecoli_experiment),\ncontaining ground truth information that will be used for an objective\ncomparison of the workflows. \n\n**Important**: the first sections of the chapter are meant for \nadvanced users that are familiar with R scripting since benchmarking\nrequires some degree of automation. However, for novice users\ninterested in the key messages of the benchmarking and that want to\nimplement the best practices, we refer to the [take home message\nsection](#sec-take_home) for more accessible guidelines.\n\n## Load packages\n\nWe load the `msqrob2` package, along with additional packages for\ndata manipulation and visualisation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"msqrob2\")\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"data.table\")\nlibrary(\"ggplot2\")\nlibrary(\"patchwork\")\n```\n:::\n\n\n**TODO**: move some functions from utils.R to msqrob2, eg \nmsqrobCollect, pairwise contrasts\n\nWe also configure the [parallelisation](#sec-parallel) framework.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"BiocParallel\")\nregister(SerialParam())\n```\n:::\n\n\n## Data\n\nWe will reuse the data by [@Shen2018-gw] as in @sec-basics. The\n[data](#sec-ecoli_data) were reanalysed using MaxQuant, which\ngenerates results at three levels: the evidence file containing the\n[PSM table](#sec-psm_table), the [peptides file](#sec-peptide_table),\nand the protein group file.\n\n### Data files\n\nWe here retrieve those three data files.\n\n**TODO**: put data on Zenodo or MsDataHub, and update code below\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"MsDataHub\")\n# myurl <- \"https://github.com/statOmics/MSqRobSumPaper/raw/refs/heads/master/spikein/data/maxquant/peptides.zip\"\n# download.file(myurl,\"data/sticker2020/peptides.zip\", method = \"curl\", extra = \"-L\")\n# unzip(\"data/sticker2020/peptides.zip\", exdir = \"data/sticker2020/\")\n# myurl <- \"https://github.com/statOmics/MSqRobSumPaper/raw/refs/heads/master/spikein/data/maxquant/evidence.zip\"\n# download.file(myurl,\"data/sticker2020/evidence.zip\", method = \"curl\", extra = \"-L\")\n# unzip(\"data/sticker2020/evidence.zip\", exdir = \"data/sticker2020/\")\n# myurl <- \"https://github.com/statOmics/MSqRobSumPaper/raw/refs/heads/master/spikein/data/maxquant/proteinGroups.zip\"\n# download.file(myurl,\"data/sticker2020/proteinGroups.zip\", method = \"curl\", extra = \"-L\")\n# unzip(\"data/sticker2020/proteinGroups.zip\", exdir = \"data/sticker2020/\")\nevidenceFile <- \"data/sticker2020/evidence.txt\"\npeptidesFile <- \"data/sticker2020/peptides.txt\"\nproteinGroupsFile <- \"data/sticker2020/proteinGroups.txt\"\n```\n:::\n\n\nWe also load the [annotation table](#sec-annotation_table)) that has\nbeen generated by the authors. Since the evidence, peptides and\nprotein-groups tables all contain the same samples, the annotation\ntable will be shared across the MaxQuant data tables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nannotFile <- \"data/sticker2020/sticker2020_annotation.csv\"\ncoldata <- read.csv(annotFile)\n```\n:::\n\n\nWe retrieve all the E. coli protein identifiers to later identify\nwhich proteins are known to be differentially abundant (E. coli\nproteins) or constant (human) across condition.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"BiocFileCache\")\nbfc <- BiocFileCache()\necoli <- bfcrpath(bfc, \"https://raw.githubusercontent.com/statOmics/MSqRobSumPaper/refs/heads/master/spikein/data/fasta/ecoli_up000000625_7_06_2018.fasta\")\necoli <- readLines(ecoli)\necoli <- ecoli[grepl(\"^>\", ecoli)]\necoli <- gsub(\">sp\\\\|(.*)\\\\|.*\", \"\\\\1\", ecoli)\n```\n:::\n\n\n### Convert to QFeatures\n\nWe combine each MaxQuant file with the annotation table into a \n[`QFeatures` object](#sec-qfeatures).\n\n- Load and convert the evidence table.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevidence <- fread(evidenceFile, check.names = TRUE)\ncoldata$runCol <- coldata$Raw.file\nevidence <- readQFeatures(\n    evidence, colData = coldata, runCol = \"Raw.file\", \n    quantCols = \"Intensity\"\n)\n```\n:::\n\n\n- Load and convert the peptide table.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npeptides <- read.delim(peptidesFile)\ncoldata$quantCols <- paste0(\"Intensity.\", coldata$Sample)\npeptides <- readQFeatures(\n    peptides, colData = coldata, name = \"peptides\", \n    fnames = \"Sequence\"\n)\n```\n:::\n\n\n- Load and convert the protein-groups table\n\n\n::: {.cell}\n\n```{.r .cell-code}\nproteinGroups <- read.delim(proteinGroupsFile)\nproteinGroups <- readQFeatures(\n    proteinGroups, colData = coldata, name = \"proteinGroups\",\n    fnames = \"Protein.IDs\"\n)\n```\n:::\n\n\n## Data preprocessing\n\nTo exclude differences in data processing between the different data \nfiles, we will create a common data processing workflow in a\ndedicated function^[Another option would be to copy-paste the workflow\ncode for every approach, but we refrain from doing so as this can lead\nto incoherent code when the workflow needs to be changed. This is a\ncommon malpractice that reduces code maintainability.].\n\n### Preprocessing workflow\n\nWe will use the same `QFeatures` data preprocessing workflow as\npresented in the [basic concepts chapter](#sec-basic_preprocess)\nstarting from the peptides table. However, we will account for the\nincreased complexity in filtering when starting from PSM-level tables,\nwhere we need to exclude PSM mapping to multiple ions (as explained in\nthe [advanced concepts chapter](#sec-duplicated_psms)). Conversely,\nthe protein group table (containing LFQ normalised data) already\nunderwent several data processing steps that will be ignored. We also\nneed to provide the correct protein identifiers across data levels. We\nwill use the `Proteins` column for the PSM-level and the peptide-level\ndata, while we will use the `Protein.IDs` for the protein-group-level\ndata.\n\nHere is an overview of the data processing workflow: \n\n1. [Encode](#sec-encode_missing) missing values with `NA`\n2. Perform [log2-transformation](#sec-log2)\n3. (Only for PSM-level data) Remove [duplicated \n   PSMs](#sec-duplicated_psms) for each ion and join the data from\n   different runs, effectively leading to ion-level data.\n4. (Only for protein-level data) Rename `Protein.IDs` to `Protein` for\n   consistent protein identifier column name. \n5. [Filter features](#sec-filter) by removing failed protein inference\n   and removing decoys and contaminants.\n6. Filter missing values, keeping features that are observed in at \n   least 4 samples. This is the last step for the workflow starting \n   from protein group data, because maxLFQ values are already\n   normalised and summarised to protein values.\n7. Perform [normalisation](#sec-norm). \n8. Perform [summarisation](#sec-summarisation). The summarised values \n   will only be used for protein-level modelling while the normalised\n   data prior to normalisation will be used for ion-level and\n   peptide-level modelling. \n\nThe workflow is implemented in a functions with one argument, `object`,\nwhich is the `QFeatures` we generated, either from the evidence file, \nthe peptides file or the protein-groups file. \n\n\n::: {.cell}\n\n```{.r .cell-code}\npreprocessing_workflow <- function(object) {\n    ## 1. Encode missing values\n    i <- names(object) ## store the input set names\n    object <- zeroIsNA(object, i)\n    ## 2. Log transformation\n    logName <- paste0(i, \"_log\") ## generate the log set names\n    object <- logTransform(object, i, name = logName, base = 2)\n    ## 3. PSM filtering (only for psm-level data)\n    if (length(i) > 1) {\n        for (ii in logName) {\n            rowdata <- rowData(object[[ii]]) \n            rowdata$ionID <- paste0(rowdata$Sequence, rowdata$Charge) \n            rowdata$rowSums <- rowSums(assay(object[[ii]]), na.rm = TRUE)\n            rowdata <- data.frame(rowdata) |>\n                group_by(ionID) |>\n                mutate(psmRank = rank(-rowSums))\n            rowData(object[[ii]]) <- DataFrame(rowdata)    \n        }\n        object <- filterFeatures(object, ~ psmRank == 1, keep = TRUE)\n        i <- \"evidence\"\n        joinName <- paste0(i, \"_log\")\n        object <- joinAssays(object, logName, joinName, \"ionID\")\n        logName <- joinName \n    }\n    ## 4. Match protein identifiers across data levels\n    if (i == \"proteinGroups\") { \n        ## We need to match the protein IDs in the evidence/peptide\n        ## table with the protiein IDs in the protein group table\n        rowdata <- rbindRowData(object, names(object))\n        rowdata$Proteins <- rowdata$Protein.IDs\n        rowData(object) <- split(rowdata, rowdata$assay)\n    }\n    ## 5. Feature filtering\n    object <- filterFeatures(\n        object, ~ Proteins != \"\" & ## Remove failed protein inference\n          !grepl(\";\", Proteins) & ## Remove protein groups\n          Reverse != \"+\" & ## Remove decoys\n          (Potential.contaminant != \"+\") ## Remove contaminants\n    )\n    ## 6. Missing value filtering\n    n <- ncol(object[[logName]])\n    object <- filterNA(object, i = logName, pNA = (n - 4) / n)\n    ## (The steps below are not for protein-group data)\n    if (i == \"proteinGroups\") return(object)\n    ## 7. Normalisation\n    normName <- paste0(i, \"_norm\")\n    pseudoRef <- rowMeans(assay(object[[logName]]), na.rm = TRUE)\n    nfLog <- sweep(assay(object[[logName]]), MARGIN = 1, pseudoRef) |> \n      colMedians(na.rm = TRUE)\n    object <- sweep(\n      object, MARGIN = 2, STATS = nfLog, i = logName, name = normName\n    )\n    ## 8. Summarisation\n    summName <- paste0(i, \"_proteins\")\n    aggregateFeatures(\n        object, i = normName, name = summName, fcol = \"Proteins\",\n        fun = MsCoreUtils::robustSummary\n    )\n}\n```\n:::\n\n\n### Run the workflow\n\nNow that we have defined a common data processing function, we apply\nto each input data level: the ion data, the peptide data and the\nprotein-group data. We then combine all the data in a single\n`QFeatures` object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevidence <- preprocessing_workflow(evidence)\npeptides <- preprocessing_workflow(peptides)\nproteinGroups <- preprocessing_workflow(proteinGroups)\nspikein <- c(evidence, peptides, proteinGroups)\n```\n:::\n\n\n## Data modelling\n\nSimilarly to the data processing, we will use the same modelling \nworkflow for each data level. For ion-level data (starting from the\nevidence file) and peptide-level data, we will both model the data\nbefore and after summarisation. In other words, we will model the data\nat the ion/peptide level (as described in the [advanced\nchapter](#sec-tmt_ion_model)) and at the protein level (as described in\nthe [basics chapter](#sec-modelling)).\n\n### Model definition\n\nDepending on the input level (ion, peptide or protein), different \nmodels are required. The simplest model is the protein model where we\naccount for the effect of `Condition` (spike-in amount group) using a\n[fixed effect](#sec-fixed_effect). For the peptide and the ion models,\nthe data contains multiple peptides per proteins, and we expect that\nintensities from the same peptide are more similar than intensities\nfrom different peptides. Similarly, modelling multiple peptides per\nprotein implies that we have multiple intensities per sample and hence\nthat intensities from the same sample are more similar that\nintensities from different samples. The ion and peptide models \ntherefore include a random effect for ion (`ionID`) and peptide\n(`Sequence`), and a random effect for sample (`Sample`). All three\nmodel definitions are stored in a list to streamline later access.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodels <- list(\n    protein = ~ Condition,\n    peptide = ~ Condition + (1 | Sample) + (1 | Sequence),\n    ion = ~ Condition + (1 | Sample) + (1 | ionID)\n)\n```\n:::\n\n\nWe will benchmark the performance of the modelling approaches by\ncomparing all possible combination of 2 spike-in conditions^[There are\n5 conditions, so 10 unique pairwise combinations.]. All models assess\nthe same comparisons of conditions, hence the same contrasts. We\ntherefore build a [contrast matrix](#sec-hypothesis_testing) that is\nshared across all models.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nallContrasts <- createPairwiseContrasts(\n    models$protein, colData(spikein), var = \"Condition\", ridge = TRUE\n)\nL <- makeContrast(\n    allContrasts, \n    c(\"ridgeConditionB\", \"ridgeConditionC\", \"ridgeConditionD\", \"ridgeConditionE\")\n)\n```\n:::\n\n\n### Modelling workflow\n\nWe will use the same `msqrob2` data modelling and statistical\ninference workflow as presented in the [basic concepts\nchapter](#sec-msqrob). However, for ion-level and peptide-level\nmodels, we will rely on mixed models that have been introduced in the\n[advanced chapter](#sec-run_model), including the\n[refitting](#sec-msqrob_refit) of proteins for which there is only 1\nfeature (ion or peptide). We implement the workflow in a function that\nwe will call for all modelling approaches. It has 5 arguments:\n\n- `object` is the preprocessed `QFeatures` object containing the data\n  to model.\n- `i` is the name of the set to start (see `names(spikein)`).\n- `model` is a formula defining the model to estimate.\n- `L` is the contrast matrix to perform hypothesis testing.\n- `modelLevel` indicates whether the model should be fit at the \n  `\"ion\"`, `\"peptide\"` or `\"protein\"` level.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelling_workflow <- function(object, i, model, L, modelLevel) {\n    ## 1. Estimate the model\n    if (modelLevel == \"protein\") {\n        object <- msqrob(\n            object,  i = i, formula = model,\n            ridge = TRUE, robust = TRUE\n        )\n    } else {\n        ## 1a. Estimate\n        object <- msqrobAggregate(\n            object,  i = i, formula = model, \n            fcol = \"Proteins\", name = \"msqrob\",\n            robust = TRUE, ridge = TRUE\n        )\n        i <- \"msqrob\"\n        ## 1b. Refit one-hit-wonders\n        counts <- aggcounts(object[[\"msqrob\"]])\n        oneHitProteins <- rownames(counts)[rowMax(counts) == 1]\n        object <- msqrobRefit(\n          object, i = i, subset = oneHitProteins,\n          formula = ~ Condition,\n          fcol = \"Proteins\", name = \"msqrob\",\n          robust = TRUE, ridge = TRUE\n        )\n    }\n    ## 2. Hypothesis testing\n    object <- hypothesisTest(object, i, contrast = L)\n    ## 3. Collect the results\n    out <- msqrobCollect(object[[i]], L, combine = TRUE)\n    out\n}\n```\n:::\n\n\n### Run the workflow\n\nWe will now run the above function for the different approaches. To do\nso, we create a table containing the main modelling settings^[Note the\napproach names match some of the sets in the `QFeatures` object.]:\n\n- Approach 1 (called `evidence_proteins`): model the data from the \n  evidence file using the protein level data.\n- Approach 2 (called `evidence_norm`): model the data from the \n  evidence file using the normalised ion data\n- Approach 3 (called `peptides_proteins`): model the data from the \n  peptides file using the protein level data.\n- Approach 4 (called `peptides_norm`): model the data from the \n  peptides file  using the normalised peptide data.\n- Approach 5 (called `proteinGroups_log`): model the data from the \n  protein groups file using the protein level data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(approaches <- data.frame(\n    inputLevel = c(\"evidence_proteins\", \"evidence_norm\", \"peptides_proteins\", \"peptides_norm\", \"proteinGroups_log\"),\n    modelLevel = c(\"protein\", \"ion\", \"protein\", \"peptide\", \"protein\")\n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         inputLevel modelLevel\n1 evidence_proteins    protein\n2     evidence_norm        ion\n3 peptides_proteins    protein\n4     peptides_norm    peptide\n5 proteinGroups_log    protein\n```\n\n\n:::\n:::\n\n\nFor each row of this table, we retrieve the different arguments and\nrun our data modelling workflow. Notice how every approach is run\nusing the same code. Every `apply` iteration returns a table of\nstatistical inference results for all pairwise comparisons. We combine\nall the tables in a single table for result exploration.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults <- apply(approaches, 1, function(x) {\n    out <- modelling_workflow(\n        spikein, i = x[[\"inputLevel\"]], model = models[[x[[\"modelLevel\"]]]],\n        L = L, modelLevel = x[[\"modelLevel\"]]\n    )\n    out$inputLevel <- x[[\"inputLevel\"]]\n    out$modelLevel <- x[[\"modelLevel\"]]\n    out\n})\nresults <- do.call(rbind, results)\n```\n:::\n\n\nWe also add whether each modelled protein is a E. Coli protein (known\nto be differentially abundant) or not. We also simplify the naming of\nthe contrasts for visualisation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults$isEcoli <- results$feature %in% ecoli\nresults$contrast <- gsub(\"ridgeCondition\", \"\", results$contrast)\nresults$contrast <- gsub(\"^([B-E])$\", \"\\\\1 - A\", results$contrast)\n```\n:::\n\n\n## Performance benchmark{#sec-performance}\n\nWe now can compare the performance of the different modelling \napproaches. We will compare the approaches based on 4 objectives \ncriteria: \n\n1. The number of fitted proteins across conditions.\n2. The number of true positives and false positives at a 5% FDR \n   threshold. \n3. The sensitivity against the rate of missidentification.\n4. The accuracy and pricision of the log2-fold change estimatione\n\n### Number of fits\n\nWe compare the number of proteins that could be estimated by each \napproach, where a model that fits more proteins is preferred. Note \nthat the number of fits exceeds the number of measured proteins \nbecause we summed the fits over all comparisons.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngroup_by(results, inputLevel) |> \n    summarise(n = sum(!is.na(adjPval))) |> \n    ggplot() +\n    aes(x = inputLevel, y = n, fill = inputLevel) +\n    geom_bar(stat = \"identity\")\n```\n\n::: {.cell-output-display}\n![ ](03-benchmarking_files/figure-html/benchmarking_nfits-1.png){width=672}\n:::\n:::\n\n\nWe can see that the approaches that fits least proteins is when\nstarting from the protein-group file. However, all other four\napproaches can fit the same number of proteins.\n\n### TP and FP at 5% FDR\n\nAn approach that fits more proteins is preferred, provided that the\nadditional fits lead to meaningful results. Because this data set\ncontains ground truth information, we can assess whether the modelling\napproaches correctly prioritised the proteins given the known\ndifferential abundant proteins. We therefore benchmark the approaches\nby examining the number of reported proteins that are true positive\n(TP) (i.e., E. Coli proteins), and false positive (FP) (i.e., human\nproteins) considering a 5% false discovery rate (FDR) threshold, which\nis typically used. We will therefore first construct the table with\nTPs and FPs obtained from each data modelling approach for each \ncomparison.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntpFpTable <- group_by(results, inputLevel, contrast) |>\n    filter(adjPval < 0.05) |>\n    summarise(\"True Positives\" = sum(isEcoli),\n              \"False Positives\" = sum(!isEcoli)) |>\n    pivot_longer(cols = c(\"True Positives\", \"False Positives\"))\n```\n:::\n\n\nWe then plot the table as a bar plot, facetting for every comparison. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(tpFpTable) +\n    aes(x = inputLevel,\n        y = value,\n        fill = inputLevel) +\n    geom_bar(stat = \"identity\") +\n    facet_grid(contrast ~ name, scales = \"free\") +\n    labs(x = \"\", y = \"Count\") +\n    theme(axis.text.x = element_blank(),\n          axis.ticks.x = element_blank(),\n          legend.position = \"bottom\") +\n    guides(fill = guide_legend(nrow = 3)) ## to avoid legend getting cropped\n```\n\n::: {.cell-output-display}\n![ ](03-benchmarking_files/figure-html/benchmarking_tp_fp-1.png){width=384}\n:::\n:::\n\n\nThe plot clearly shows that starting from MaxQuant's proteinGroups file leads to \na severe decrease in performance as the number of TP is systematically\nlower compared to other approaches, while there is no dramatic\ndifference with the number of FPs. \n\nThe four other approaches lead to comparable results. We could argue\nthat for some specific comparisons (C-B, D-C, E-D) approaches starting\nfrom the evidence file recover slightly more TP without impact on the\nnumber of FP. Similarly modelling at the peptide/ion level leads to\nslight increase in performance compared to modelling at the protein\nlevel, but these difference are subtle.\n\n### TPR-FDP  curves{#sec-tpr_fdp}\n\nAdditionally, we construct true positive rate (TPR)-false discovery\nproportion (FDP) plots. TPR represents the fraction of truly DA\nproteins reported by the method, calculated as $TPR =\n\\frac{TP}{TP+FN}$, with FN false negatives (i.e., E. Coli proteins\nthat were not flagged as differential abundant). FDP denotes the\nproportion of false positives among all proteins flagged as\ndifferential abundant, calculated as $FDP = \\frac{FP}{TP + FP}$.\n\nSo we first compute the FDP and TPR using the custom functions below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncomputeFDP <- function(pval, tp) {\n    ord <- order(pval)\n    fdp <- cumsum(!tp[ord]) / 1:length(tp)\n    fdp[order(ord)]\n}\ncomputeTPR <- function(pval, tp, nTP = NULL) {\n    if (is.null(nTP)) nTP <- sum(tp)\n    ord <- order(pval)\n    tpr <- cumsum(tp[ord]) / nTP\n    tpr[order(ord)]\n}\n```\n:::\n\n\nBefore computing these metrics, we first remove any failed\ninference^[When statistical inference fails for a protein, `msqrob2`\nwill fill the (adjusted) p-value and log2-fold change with missing\nvalues. So excluding NAs will ignore any failed inference.]. This\nmeans that we are comparing the approach based on a set of proteins\nthat is specific to each approach. However, proteins that are fit by\nsome approaches but not by others may be harder to estimate and hence\nwill decrease the overall performance. So, for a fair comparison, we\nalso created a plot that compares the approaches when considering all\nthe proteins measured in the data set (see the\n[appendix section](#sec-appendix3_1)). Any failed inference for a DA\nprotein will results in a FP. Similarly, we could also compare the\napproaches based on a common set of proteins that has been fit by all\napproaches  (see the following [appendix section](#sec-appendix3_2)).\n\nWe compute the TPR and FDP for each approach (given by `inputLevel`)\nand each pairwise spike-in comparison (given by `contrast`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance <- group_by(results, inputLevel, contrast) |> \n    na.exclude() |>\n    mutate(tpr = computeTPR(pval, isEcoli),\n           fdp = computeFDP(pval, isEcoli)) |>\n    arrange(fdp)\n```\n:::\n\n\nWe also highlight the observed FDP at a 5\\% FDR threshold. Since the\nFDR represent the expected FDP, i.e. the average of the FDPs obtained\nwhen the spike-in experiment were to be repeated an infinite number of\ntimes, an observed FDP that is very far away from 5\\% is indicative\nfor a workflow that provides poor FDR control.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nworkPoints <- group_by(performance, inputLevel, contrast) |>\n    filter(adjPval < 0.05) |>\n    slice_max(adjPval) |>\n    filter(!duplicated(inputLevel))\n```\n:::\n\n\nWe can now generate the TPR-FDP curves. The best performing approach \nis characterised by the largest area under the curve. These curves\nprovide the performance over a range of FDP values, but we limit the \nplot to the $[0, 0.2]$ range because researchers are rarely interest\nin the performance when the FDP exceeds 20\\%.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(performance) +\n    aes(y = fdp,\n        x = tpr,\n        colour = inputLevel) +\n    geom_line() +\n    geom_point(data = workPoints, size = 3) +\n    geom_hline(yintercept = 0.05, linetype = 2) +\n    facet_wrap(~ contrast) +\n    coord_flip(ylim = c(0, 0.2)) +\n    theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![ ](03-benchmarking_files/figure-html/benchmarking_tpr_fdp_curve1-1.png){width=960}\n:::\n:::\n\n\nThe results are in line with the previous bechmark criteria, that is\nstarting from the proteinGroups file lead to a severe backlash on\nperformance. The other approaches show comparable performance,\nalthough for challenging comparisons where the performance is\ngenerally low (C-B, D-C, E-D) we find a subtle increase in performance \nfor ion/peptide level models.\n\nOveral, we find that all approaches lead to a good FDR control. A\nnotable exception is for challenging comparisons when starting from\nprotein group data, where the performance is so low that FDR cannot be\ncontrolled. We also find that the other approaches tend to be \nconservative for the D-C and E-D comparisons.\n\nThe same results apply when considering [all proteins in the\ndata]({#sec-appendix3_1) or when considering [proteins estimated by\nall approaches]({#sec-appendix3_2), indicating that the conclusions do\nnot depend on the set of proteins considered. \n\n### Fold change boxplots{#sec-benchmark_with_boxplots}\n\nNext to correctly prioritising the differentially abundant proteins,\nanother object is to correctly estimate the log2-fold change between\nconditions. Since every condition contains E. Coli proteins that have\nbeen spiked in experimentally controlled amounts, we know the real log2-fold change between any two conditions. We will explore\nthe model accuracy, i.e. how close the estimations are from the\ntrue value on average, and the model precision, i.e. how narrow\nthe estimations are spread around the average estimation. In this data\nset, there are two target values. For E. Coli proteins, the expected\nvalue is the experimentally induced log2-fold change. For human\nproteins, the expected value is a log2-fold change of 0, as these\nproteins are experimentally known to be constant.\n\nWe explore the results using boxplots of the estimated log2-fold \nchanges, but we first create a small table with the expected values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrealLogFC <- data.frame(\n  logFC = t(L) %*% lm(log2(Concentration) ~ Condition, colData(spikein))$coef[-1]\n)\nrealLogFC$contrast <- gsub(\"ridgeCondition\",\"\",colnames(L))\nrealLogFC$contrast <- gsub(\"^([B-E])$\", \"\\\\1 - A\", realLogFC$contrast)\n```\n:::\n\n\nWe can now create the boxplots with the estimated log2-fold changes,\nadding horizontal lines with the corresponding target values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(results) +\n  aes(y = logFC,\n      x = isEcoli,\n      colour = isEcoli) +\n  geom_boxplot()  +\n  scale_color_manual(\n    values = c(\"grey20\", \"firebrick\"), name = \"\",\n    labels = c(\"Human proteins\", \"E. coli proteins\")\n  ) +\n  facet_grid(contrast ~ inputLevel, scales = \"free\") +\n  geom_hline(data = realLogFC, aes(yintercept = logFC), \n             colour = \"firebrick\") +\n  geom_hline(yintercept = 0) +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![ ](03-benchmarking_files/figure-html/benchmarking_boxplot-1.png){width=480}\n:::\n:::\n\n\nFor all approaches, the boxplots are roughly centred on the expected \nvalue, indicating good model accuracy. Starting from MaxQuant's\nprotein-group data leads to wider boxplots, hence less stable\nestimation and hence decreased precision. The approach starting from\nthe evidence file seems to provide somewhat more precise estimations\nas it shows less outliers compared to starting from the peptides file.\n\n## Take home messages{#sec-take_home}\n\nWe found a striking drop in performance when starting from the \nprotein-group data compared to the other approaches, suggesting that\nthis approach leads to suboptimal results. We couldn't find strong\ndifferences in performance between the remaining apporaches. For some\ncomparisons, we found a slight increase in performance when starting\nfrom the evidence file compared to starting from the peptides file.\nSimilarly, for some comparisons, we found a slight increase in\nperformance when modelling data at the ion/peptide level compared to \nthe protein level.\n\nProcessing the data from the evidence file only leads to one \nadditional step compared to processing the data from the peptides\nfile: we need to find a low-level feature definition that is shared\nacross rus, which we here defined as the ion level (i.e. the\ncombination of the peptide sequence and its charge). This additional\nstep has little impact on the complexity of the workflow, hence we\nwould advice to start from the evidence file. However, modelling the\ndata at the ion/peptide level is more advanced than modelling at the \nprotein level, as it requires the inclusion of random effects to\naccount for the correlation structure within and between samples and\nwithin and between ions/peptides from the same protein. Moreover, the\ndata modelling is performed at the ion/peptide level, but the\nstatistical inference results are reported at the protein level,\nmeaning that no direct protein summaries are available to explore and\nsupport the statistical outcome^[Although these protein data are\nindirectly generated using a summarisation approach (c.f.\n`msqrobAggregate()`).]. Therefore, we leave it to the user to decide\nwhether the slight improvement in performance is worth the cost of\nmore complex statistical analysis [@Sticker2020-rl].\n\nHence, this chapter showed how to perform benchmarking on different\ntypes of data input. Note that the same framework could be used to\ncompare different search and quantification engines. Similarly, this\nframework can also be applied to compare different instruments or\nanalytical protocols and setups. In the [next\nchapter](sec-workflow_optimisation) we demonstrate how to compare the\nimpact of analysis steps for the same data.\n\nIn the remainder of this section, we provide a recap on how to perform\na proteomics analysis from the evidence file^[We build on the concepts\nintroduced in the [basic concepts chapter](#sec-basics) and the\n[advanced concepts chapter](#sec-advanced)], either at the ion-level\nor at the protein level.\n\n### Preprocessing the evidence file{#sec-preprocess_evidence}\n\nThe first step is to read the data. Remember that we need two pieces\nof data, the [sample annotation table](#sec-annotation_table) and, in\nthis case, the [PSM table](#sec-psm_table) obtained after reading\nMaxQuant's evidence file.\n\nHere are the first 6 lines (first 6 samples) of the sample\nannotations, note we added `runCol` and `quantCol` that are required\nfor the [conversion to a `QFeatures` object](#sec_advanced_readqf). \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoldata <- read.csv(annotFile)\n```\n:::\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|Raw.file                                                         |Condition |Sample | Concentration|\n|:----------------------------------------------------------------|:---------|:------|-------------:|\n|B03_03_150304_human_ecoli_C_3ul_3um_column_95_HCD_OT_2hrs_30B_9B |C         |c1     |           6.0|\n|B03_08_150304_human_ecoli_C_3ul_3um_column_95_HCD_OT_2hrs_30B_9B |C         |c2     |           6.0|\n|B03_18_150304_human_ecoli_C_3ul_3um_column_95_HCD_OT_2hrs_30B_9B |C         |c3     |           6.0|\n|B03_19_150304_human_ecoli_B_3ul_3um_column_95_HCD_OT_2hrs_30B_9B |B         |b1     |           4.5|\n|B03_07_150304_human_ecoli_D_3ul_3um_column_95_HCD_OT_2hrs_30B_9B |D         |d1     |           7.5|\n|B03_14_150304_human_ecoli_D_3ul_3um_column_95_HCD_OT_2hrs_30B_9B |D         |d2     |           7.5|\n\n\n:::\n:::\n\n\nHere are the first 6 lines (first 6 PSMs) of the PSM table. The table\ncontains many columns, most containing information about the\nidentified peptide and the quality of the spectrum matching.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevidence <- fread(evidenceFile, check.names = TRUE)\n```\n:::\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|Sequence               | Length|Modifications |Modified.sequence        |Oxidation..M..Probabilities |Oxidation..M..Score.Diffs | Acetyl..Protein.N.term.| Oxidation..M.| Missed.cleavages|Proteins |Leading.proteins |Leading.razor.protein |Gene.names |Protein.names                     |Type         |Raw.file                                                         |Experiment | MS.MS.m.z| Charge|      m.z|     Mass| Resolution| Uncalibrated...Calibrated.m.z..ppm.| Uncalibrated...Calibrated.m.z..Da.| Mass.error..ppm.| Mass.error..Da.| Uncalibrated.mass.error..ppm.| Uncalibrated.mass.error..Da.| Max.intensity.m.z.0| Retention.time| Retention.length| Calibrated.retention.time| Calibrated.retention.time.start| Calibrated.retention.time.finish| Retention.time.calibration| Match.time.difference| Match.m.z.difference| Match.q.value| Match.score| Number.of.data.points| Number.of.scans| Number.of.isotopic.peaks| PIF| Fraction.of.total.spectrum| Base.peak.fraction|       PEP| MS.MS.count| MS.MS.scan.number|  Score| Delta.score| Combinatorics| Intensity|Reverse |Potential.contaminant | id|Protein.group.IDs | Peptide.ID| Mod..peptide.ID|MS.MS.IDs | Best.MS.MS|AIF.MS.MS.IDs |Oxidation..M..site.IDs |\n|:----------------------|------:|:-------------|:------------------------|:---------------------------|:-------------------------|-----------------------:|-------------:|----------------:|:--------|:----------------|:---------------------|:----------|:---------------------------------|:------------|:----------------------------------------------------------------|:----------|---------:|------:|--------:|--------:|----------:|-----------------------------------:|----------------------------------:|----------------:|---------------:|-----------------------------:|----------------------------:|-------------------:|--------------:|----------------:|-------------------------:|-------------------------------:|--------------------------------:|--------------------------:|---------------------:|--------------------:|-------------:|-----------:|---------------------:|---------------:|------------------------:|---:|--------------------------:|------------------:|---------:|-----------:|-----------------:|------:|-----------:|-------------:|---------:|:-------|:---------------------|--:|:-----------------|----------:|---------------:|:---------|----------:|:-------------|:----------------------|\n|AAAAAAAAAAAAAAAGAGAGAK |     22|Unmodified    |_AAAAAAAAAAAAAAAGAGAGAK_ |                            |                          |                       0|             0|                0|P55011   |P55011           |P55011                |SLC12A2    |Solute carrier family 12 member 2 |MULTI-SECPEP |B03_03_150304_human_ecoli_C_3ul_3um_column_95_HCD_OT_2hrs_30B_9B |c1         |  532.9854|      3| 532.9533| 1595.838|   94394.69|                          -0.5225600|                         -0.0002785|          0.84218|       0.0004488|                       0.31962|                    0.0001703|            532.9553|         76.475|          0.19265|                    76.426|                          76.307|                           76.500|                  -0.049773|                    NA|                   NA|            NA|          NA|                    24|              11|                        3|   0|                          0|                  0| 0.0013949|           1|             31302| 46.133|      33.507|             1|   4268500|        |                      |  0|2115              |          0|               0|0         |          0|NA            |                       |\n|AAAAAAAAAAAAAAAGAGAGAK |     22|Unmodified    |_AAAAAAAAAAAAAAAGAGAGAK_ |                            |                          |                       0|             0|                0|P55011   |P55011           |P55011                |SLC12A2    |Solute carrier family 12 member 2 |MULTI-SECPEP |B03_08_150304_human_ecoli_C_3ul_3um_column_95_HCD_OT_2hrs_30B_9B |c2         |  532.9863|      3| 532.9533| 1595.838|   89387.45|                           0.0021322|                          0.0000011|         -0.25348|      -0.0001351|                      -0.25135|                   -0.0001340|            533.2871|         76.225|          0.16901|                    76.426|                          76.314|                           76.483|                   0.200350|                    NA|                   NA|            NA|          NA|                    13|               8|                        2|   0|                          0|                  0| 0.0069352|           1|             31103| 38.377|      32.662|             1|   7099400|        |                      |  1|2115              |          0|               0|1         |          1|NA            |                       |\n|AAAAAAAAAAAAAAAGAGAGAK |     22|Unmodified    |_AAAAAAAAAAAAAAAGAGAGAK_ |                            |                          |                       0|             0|                0|P55011   |P55011           |P55011                |SLC12A2    |Solute carrier family 12 member 2 |MSMS         |B03_18_150304_human_ecoli_C_3ul_3um_column_95_HCD_OT_2hrs_30B_9B |c4         |  798.9761|      2| 798.9263| 1595.838|        NaN|                                 NaN|                                NaN|              NaN|             NaN|                           NaN|                          NaN|                 NaN|         76.225|          1.00000|                    76.639|                          76.139|                           77.139|                   0.413920|                    NA|                   NA|            NA|          NA|                    NA|              NA|                       NA|   0|                          0|                  0| 0.0000000|           1|             31830| 98.407|      82.183|             1|        NA|        |                      |  2|2115              |          0|               0|2         |          2|NA            |                       |\n|AAAAAAAAAAAAAAAGAGAGAK |     22|Unmodified    |_AAAAAAAAAAAAAAAGAGAGAK_ |                            |                          |                       0|             0|                0|P55011   |P55011           |P55011                |SLC12A2    |Solute carrier family 12 member 2 |MSMS         |B03_19_150304_human_ecoli_B_3ul_3um_column_95_HCD_OT_2hrs_30B_9B |b4         |  798.9767|      2| 798.9263| 1595.838|        NaN|                                 NaN|                                NaN|              NaN|             NaN|                           NaN|                          NaN|                 NaN|         75.981|          1.00000|                    76.733|                          76.233|                           77.233|                   0.752060|                    NA|                   NA|            NA|          NA|                    NA|              NA|                       NA|   0|                          0|                  0| 0.0000000|           1|             31810| 71.241|      53.805|             1|        NA|        |                      |  3|2115              |          0|               0|3         |          3|NA            |                       |\n|AAAAAAAAAAAAAAAGAGAGAK |     22|Unmodified    |_AAAAAAAAAAAAAAAGAGAGAK_ |                            |                          |                       0|             0|                0|P55011   |P55011           |P55011                |SLC12A2    |Solute carrier family 12 member 2 |MULTI-MATCH  |B03_07_150304_human_ecoli_D_3ul_3um_column_95_HCD_OT_2hrs_30B_9B |d2         |        NA|      3| 532.9533| 1595.838|   83252.61|                          -0.4043600|                         -0.0002155|         -0.31288|      -0.0001667|                      -0.71725|                   -0.0003823|            532.9532|         76.332|          0.11982|                    76.533|                          76.433|                           76.553|                   0.200930|             -0.016489|           -0.0001398|           NaN|      37.285|                    10|               8|                        2| NaN|                        NaN|                NaN|       NaN|           0|                NA|    NaN|         NaN|             0|   8563700|        |                      |  4|2115              |          0|               0|          |         NA|NA            |                       |\n|AAAAAAAAAAAAAAAGAGAGAK |     22|Unmodified    |_AAAAAAAAAAAAAAAGAGAGAK_ |                            |                          |                       0|             0|                0|P55011   |P55011           |P55011                |SLC12A2    |Solute carrier family 12 member 2 |MULTI-MATCH  |B03_14_150304_human_ecoli_D_3ul_3um_column_95_HCD_OT_2hrs_30B_9B |d3         |        NA|      3| 532.9533| 1595.838|   98783.58|                          -0.3048300|                         -0.0001625|         -0.31827|      -0.0001696|                      -0.62310|                   -0.0003321|            532.9531|         76.046|          0.10846|                    76.498|                          76.403|                           76.511|                   0.451640|             -0.051605|           -0.0001484|           NaN|      37.285|                     7|               5|                        2| NaN|                        NaN|                NaN|       NaN|           0|                NA|    NaN|         NaN|             0|   6597000|        |                      |  5|2115              |          0|               0|          |         NA|NA            |                       |\n\n\n:::\n:::\n\n\nNote that `Intensity` column contains the quantitative values and the\n`Raw.file` column indicates in which run the sample was acquired. We\nuse the latter to link the sample annotation with the PSM table. We\ntherefore need to add `runCol` to the sample annotation that will\nserve as the linker. We can then convert the tables to a `QFeatures`\nobject.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoldata$runCol <- coldata$Raw.file\n(evidence <- readQFeatures(\n    evidence, colData = coldata, runCol = \"Raw.file\", \n    quantCols = \"Intensity\"\n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAn instance of class QFeatures (type: bulk) with 20 sets:\n\n [1] B03_02_150304_human_ecoli_B_3ul_3um_column_95_HCD_OT_2hrs_30B_9B: SummarizedExperiment with 40057 rows and 1 columns \n [2] B03_03_150304_human_ecoli_C_3ul_3um_column_95_HCD_OT_2hrs_30B_9B: SummarizedExperiment with 41266 rows and 1 columns \n [3] B03_04_150304_human_ecoli_D_3ul_3um_column_95_HCD_OT_2hrs_30B_9B: SummarizedExperiment with 41396 rows and 1 columns \n ...\n [18] B03_19_150304_human_ecoli_B_3ul_3um_column_95_HCD_OT_2hrs_30B_9B: SummarizedExperiment with 39388 rows and 1 columns \n [19] B03_20_150304_human_ecoli_A_3ul_3um_column_95_HCD_OT_2hrs_30B_9B: SummarizedExperiment with 39000 rows and 1 columns \n [20] B03_21_150304_human_ecoli_A_3ul_3um_column_95_HCD_OT_2hrs_30B_9B: SummarizedExperiment with 38783 rows and 1 columns \n```\n\n\n:::\n:::\n\n\nNote that the data from every run is contained in a separate set. We\ncannot yet join the sets together since we don't have a specific\nfeature identifier, yet^[A PSM is generated from a spectrum, which is\nspecific to each run and there is not unambiguous way to link a\nspectrum across runs].\n\n1. Encoding missing values as zeros.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevidence <- zeroIsNA(evidence, names(evidence))\n```\n:::\n\n\n2. Log2 transforming\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninputNames <- names(evidence)\nlogNames <- paste0(inputNames, \"_log\")\nevidence <- logTransform(evidence, inputNames, name = logNames, base = 2)\n```\n:::\n\n\n3. Keeping only the most intense PSM per ion (see \n   [here](#sec-duplicated_psms) for a step-by-step explanation of the\n   code). Upon this filtering every feature is unique to a ion\n   identifier (peptide sequence + charge), and we hence can join sets\n   using that identifier.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor (i in logNames) {\n  rowdata <- rowData(evidence[[i]]) \n  rowdata$ionID <- paste0(rowdata$Sequence, rowdata$Charge) \n  rowdata$value <- assay(evidence[[i]])[, 1]\n  rowdata <- data.frame(rowdata) |>\n    group_by(ionID) |>\n    mutate(psmRank = rank(-value))\n  rowData(evidence[[i]])$psmRank <- rowdata$psmRank\n  rowData(evidence[[i]])$ionID <- rowdata$ionID\n}\nevidence <- filterFeatures(evidence, ~ psmRank == 1, keep = TRUE)\nevidence <- joinAssays(evidence, logNames, \"ions_log\", \"ionID\")\n```\n:::\n\n\n4. Feature filtering\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevidence <- filterFeatures(\n        evidence, ~ Proteins != \"\" & ## Remove failed protein inference\n          !grepl(\";\", Proteins) & ## Remove protein groups\n          Reverse != \"+\" & ## Remove decoys\n          (Potential.contaminant != \"+\") ## Remove contaminants\n)\n```\n:::\n\n\n5. Missing value filtering\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- ncol(evidence[[\"ions_log\"]])\nevidence <- filterNA(evidence, i = \"ions_log\", pNA = (n - 4) / n)\n```\n:::\n\n\n6. Normalisation\n\n\n::: {.cell}\n\n```{.r .cell-code}\npseudoRef <- rowMeans(assay(evidence[[\"ions_log\"]]), na.rm = TRUE)\nnfLog <- sweep(assay(evidence[[\"ions_log\"]]), MARGIN = 1, pseudoRef) |> \n  colMedians(na.rm = TRUE)\nevidence <- sweep(\n  evidence, MARGIN = 2, STATS = nfLog, \n  i = \"ions_log\", name = \"ions_norm\"\n)\n```\n:::\n\n\n7. Summarisation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevidence <- aggregateFeatures(\n  evidence, i = \"ions_norm\", name = \"proteins\", fcol = \"Proteins\",\n  fun = MsCoreUtils::robustSummary\n)\n```\n:::\n\n\n### Modelling the preprocessed data\n\nWe can model the data either at the ion level or at the protein level.\nRegardless of the modelling approach, we can readily generate the\n[contrast matrix](#sec-multiple_contrasts) to assess all pairwise\ncomparisons between the experimental spike-in conditions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nallContrasts <- createPairwiseContrasts(\n    ~ Condition, colData(evidence), var = \"Condition\", ridge = TRUE\n)\nL <- makeContrast(\n    allContrasts, \n    c(\"ridgeConditionB\", \"ridgeConditionC\", \"ridgeConditionD\", \"ridgeConditionE\")\n)\n```\n:::\n\n\n#### Modelling at the protein-level\n\nWe first need to define the model we want to estimate, which descirbes\nthe sources of variation in the data. For the protein-level data, the\nonly potential source of variation identified from the experiment is\nthe spike-in condition of interest. We model it as a fixed effect.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelProtein <- ~ Condition\n```\n:::\n\n\nThen, we estimate the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevidence <- msqrob(\n  evidence,  i = \"proteins\", formula = modelProtein,\n  ridge = TRUE, robust = TRUE\n)\n```\n:::\n\n\nAnd we perform statistical inference on the estimated model \nparameters.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevidence <- hypothesisTest(evidence, \"proteins\", contrast = L)\nresultsProtein <- msqrobCollect(evidence[[\"proteins\"]], L, combine = TRUE)\nresultsProtein$isEcoli <- resultsProtein$feature %in% ecoli\n```\n:::\n\n\nNote that this workflows closely follows the workflow described in the \n[basics chapter](#sec-multiple_contrasts). We can report the result\nusing a volcano plot, for instance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(resultsProtein) +\n    aes(x = logFC,\n        y = -log10(pval),\n        shape = adjPval < 0.05,\n        color = isEcoli) +\n    geom_point() +\n    scale_color_manual(\n      values = c(\"grey20\", \"firebrick\"), name = \"\",\n      labels = c(\"HeLA background\", \"UPS standard\")\n    ) +\n    facet_wrap(~ contrast, scales = \"free\") +\n    ggtitle(\"Statistical inference for all pairwise comparisons\") \n```\n\n::: {.cell-output-display}\n![ ](03-benchmarking_files/figure-html/benchmarking_volcano_proteins-1.png){width=960}\n:::\n:::\n\n\n#### Modelling at the ion-level{#sec-ion_level_modelling}\n\nThe model definition for the ion-level data is more ellaborate than\nfor the protein-level data. We need to account for the fact that\nintensities within the same sample are more correlated than\nintensities across samples. Similarly, we need to account for the fact\nthat intensities for the same ion will be more similar than\nintensities between ions of the same proteins. On top of the condition\neffect that we model as a fixed effect, we will account for these\nsample and ion effects using a random effect. \n\n::: {.cell}\n\n```{.r .cell-code}\nmodelIon <- ~ Condition + (1 | Sample) + (1 | ionID)\n```\n:::\n\n\nThen, we estimate the model using `msqrobAggregate()` instead of\n`msqrob()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevidence <- msqrobAggregate(\n  evidence,  i = \"ions_norm\", formula = modelIon, \n  fcol = \"Proteins\", name = \"msqrob\",\n  robust = TRUE, ridge = TRUE\n)\n```\n:::\n\n\nBecause some proteins are only measured by a single ion, its\ncorresponding sample and ion effects cannot be estimated and hence the\nmodel for those proteins will not be estimated. We therefore refit a\nsimplified model for those proteins using the refitting workflow\ndescribed in the [advanced chapter](#sec-msqrob_refit).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncounts <- aggcounts(evidence[[\"msqrob\"]])\noneHitProteins <- rownames(counts)[rowMax(counts) == 1]\nevidence <- msqrobRefit(\n  evidence, i = \"ions_norm\", subset = oneHitProteins,\n  formula = ~ Condition,\n  fcol = \"Proteins\", name = \"msqrob\",\n  robust = TRUE, ridge = TRUE\n)\n```\n:::\n\n\nAnd we perform statistical inference on the estimated model \nparameters (same as above).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevidence <- hypothesisTest(evidence, \"msqrob\", contrast = L)\nresultsIon <- msqrobCollect(evidence[[\"msqrob\"]], L, combine = TRUE)\nresultsIon$isEcoli <- resultsIon$feature %in% ecoli\n```\n:::\n\n\nWe can report the result using a volcano plot, for instance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(resultsIon) +\n    aes(x = logFC,\n        y = -log10(pval),\n        shape = adjPval < 0.05,\n        color = isEcoli) +\n    geom_point() +\n    scale_color_manual(\n      values = c(\"grey20\", \"firebrick\"), name = \"\",\n      labels = c(\"HeLA background\", \"UPS standard\")\n    ) +\n    facet_wrap(~ contrast, scales = \"free\") +\n    ggtitle(\"Statistical inference for all pairwise comparisons\") \n```\n\n::: {.cell-output-display}\n![ ](03-benchmarking_files/figure-html/benchmarking_volcano_ion-1.png){width=960}\n:::\n:::\n\n\n## Appendix\n\nThis section provides a complement to the [TPR-FDR\ncurves](#sec-tpr_fdp)\n\n### TPR-FDP curves using all proteins in the data{#sec-appendix3_1}\n\nThis code is almost the same as for the main plot, except we removed\nthe `na.exclude()` statement. This means that all proteins, even if\nnot estimated, are included. The missing p-values will be ranked at\nthe end (as if they were estimated at 1), meaning they will be\naccounted for when computing the TPR and FDP. This will inevitably\nlead to a decrease in the maximum TPR, especially for approaches that\nestimated less proteins.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance_all <- group_by(results, inputLevel, contrast) |> \n    mutate(tpr = computeTPR(pval, isEcoli),\n           fdp = computeFDP(pval, isEcoli)) |>\n    arrange(fdp)\nworkPoints <- group_by(performance_all, inputLevel, contrast) |>\n    filter(adjPval < 0.05) |>\n    slice_max(adjPval) |>\n    filter(!duplicated(inputLevel))\nggplot(performance_all) +\n    aes(y = fdp,\n        x = tpr,\n        colour = inputLevel) +\n    geom_line() +\n    geom_point(data = workPoints, size = 3) +\n    geom_hline(yintercept = 0.05, linetype = 2) +\n    facet_wrap(~ contrast) +\n    coord_flip(ylim = c(0, 0.2)) +\n    theme(legend.position = \"bottom\") +\n    ggtitle(\"TPR-FDP curves using all proteins in the data\")\n```\n\n::: {.cell-output-display}\n![ ](03-benchmarking_files/figure-html/benchmarking_tpr_fdp_2-1.png){width=960}\n:::\n:::\n\n\n### TPR-FDP curves using only the proteins fit by all approaches{#sec-appendix3_2}\n\nThe code is almost the same as for the main plot, except we add a\nfiltering step where we require, for each comparison, that p-values\nare not missing for all 5 approaches, effectively focusing on the set\nof proteins that have been estimated by all approaches. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance_common <- group_by(results, feature, contrast) |> \n  filter(!is.na(adjPval),\n         n() == 5) |> \n  group_by(inputLevel, contrast) |> \n  mutate(tpr = computeTPR(pval, isEcoli),\n         fdp = computeFDP(pval, isEcoli)) |>\n  arrange(fdp)\nworkPoints <- group_by(performance_common, inputLevel, contrast) |>\n    filter(adjPval < 0.05) |>\n    slice_max(adjPval) |>\n    filter(!duplicated(inputLevel))\nggplot(performance_common) +\n    aes(y = fdp,\n        x = tpr,\n        colour = inputLevel) +\n    geom_line() +\n    geom_point(data = workPoints, size = 3) +\n    geom_hline(yintercept = 0.05, linetype = 2) +\n    facet_wrap(~ contrast) +\n    coord_flip(ylim = c(0, 0.2)) +\n    theme(legend.position = \"bottom\") +\n    ggtitle(\"TPR-FDP curves using only the proteins fit by all approaches\")\n```\n\n::: {.cell-output-display}\n![ ](03-benchmarking_files/figure-html/benchmarking_tpr_fdp_3-1.png){width=960}\n:::\n:::\n",
    "supporting": [
      "03-benchmarking_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}