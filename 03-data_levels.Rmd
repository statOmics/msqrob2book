
# PSM, peptide or protein-level modelling?{#sec-data_levels}

In the previous chapters we have seen three different approaches to
model the data:

1. [Approach 1](#sec-tmt_protein_model): start from a PSM-level table,
compute the protein summaries and model the data at the protein 
level.
2. [Approach 2](#sec-tmt_ion_model): start from a PSM-level table 
and model the ion-level data to obtain protein-level results.
3. [Approach 3](#sec-basics): start from a peptide-level table, 
compute the protein summaries and model the data at the protein
level.

In this chapter, we will explore the differences in performance among
these approaches by reanalysing the Clinical Proteomic Tumor Analysis
Consortium [(CPTAC) data set](#sec-cptac_experiment). For a
comprehensive comparison, we will also include the following
approaches:

4. Approach 4: start from a peptide-level table and model the 
peptide-level data to obtain protein-level results. 
5. Approach 5: start from a protein-level table (generated by MaxQuant
using maxLFQ) and model the protein-level data to obtain 
protein-level results. 

Since the CPTAC data set is a spike-in experiment with known input
amounts, we will compare the performance of these approaches using the
ground truth. This chapter is therefore also a demonstration of how to
benchmark data analysis workflows.

## Load packages

We load the `msqrob2` package, along with additional packages for
data manipulation and visualisation.

```{r}
library("msqrob2")
library("dplyr")
library("tidyr")
library("ggplot2")
library("patchwork")
```

We also configure the [parallelisation](#sec-parallel) framework.

```{r}
library("BiocParallel")
register(SerialParam())
register(SnowParam(workers = 4))
```

```{r, echo=FALSE}
source("utils.R")
```

**TODO**: move function from utils to msqrob2

## Data

### MaxQuant tables

```{r}
evidenceFile <- "data/cptac/evidence.txt"
peptidesFile <- "data/cptac/peptides.txt"
proteinGroupsFile <- "data/cptac/proteinGroups.txt"
```

**TODO**: put data on Zenodo or MsDataHub

### Annotation table

```{r}
annotFile <- "data/cptac/cptac_annotation.csv"
coldata <- read.csv(annotFile)
```

## Data preprocessing

### The preprocessing workflow

```{r}
preprocessing_workflow <- function(object, i, level) {
    level <- match.arg(level, c("psm", "peptide", "protein"))
    ## Encode missing values
    object <- zeroIsNA(object, i)
    ## Log transformation
    logName <- paste0(i, "_log")
    object <- logTransform(object, i, name = logName, base = 2)
    ## PSM filtering (only for psm-level data)
    if (level == "psm") {
        for (ii in logName) {
            rowdata <- rowData(object[[ii]]) 
            rowdata$ionID <- paste0(rowdata$Sequence, rowdata$Charge) 
            rowdata$rowSums <- rowSums(assay(object[[ii]]), na.rm = TRUE)
            rowdata <- data.frame(rowdata) |>
                group_by(ionID) |>
                mutate(psmRank = rank(-rowSums))
            rowData(object[[ii]]) <- DataFrame(rowdata)    
        }
        object <- filterFeatures(object, ~ psmRank == 1, keep = TRUE)
        i <- "evidence"
        joinName <- paste0(i, "_log")
        object <- joinAssays(object, logName, joinName, "ionID")
        logName <- joinName 
    
    }
    ## Feature filtering
    if (level == "protein") { 
        ## So we need to match the protein ID in the evidence/peptide
        ## table with the protiein ID in the protein group table
        rowdata <- rbindRowData(object, names(object))
        rowdata$Proteins <- rowdata$Protein.IDs
        rowData(object) <- split(rowdata, rowdata$assay)
    }
    object <- filterFeatures(
        object, ~ Proteins != "" & ## Remove failed protein inference
            Proteins %in% smallestUniqueGroups(Proteins) & ## Remove protein groups
            Reverse != "+" & ## Remove decoys
            (Potential.contaminant != "+") | ## Remove contaminants
            grepl("ups", Proteins) ## always keep UPS-1 proteins (some are listed as contaminants)
    )
    ## The steps below are not for protein data
    if (level == "protein") return(object)
    ## Missing value filtering (only to avoid complains from robustSummary)
    n <- ncol(object[[logName]])
    object <- filterNA(object, i = logName, pNA = (n - 2) / n)
    ## Normalisation
    normName <- paste0(i, "_norm")
    object <- normalize(
        object, logName, name = normName, method = "center.median"
    )
    ## Summarisation
    summName <- paste0(i, "_proteins")
    aggregateFeatures(
        object, i = normName, name = summName, fcol = "Proteins",
        fun = MsCoreUtils::robustSummary, 
        # fun = MsCoreUtils::medianPolish, 
        # na.rm = TRUE
    )
}
```

**NOTE**: I thought removing lab1 (contains ionisation issues) to 
improve the results, but this would lead to an unfair comparison
because maxLFQ has already been computed and combines the data from
all samples (hence all labs).

**TODO**: robust summary fails because "contrasts can be applied only 
to factors with 2 or more levels".

**TODO**: Discuss - we need to apply a stringent NA filtering to 
ensure differences in performance are not due to difference in
available data due to our missing values filters.

**TODO**: MaxQuant is doing weird stuff with protein IDs... Eg TAL1_YEAST is not part
of a protein group, whereas it is part of a protein group with TAL2 in
the protein table... See here:
```{r, eval=FALSE}
rowData(peptides[["peptides"]]) |>
    data.frame() |>
    filter(grepl("TAL._YEAST", Proteins)) |>
    select(Leading.razor.protein, Proteins)
rowData(proteins[["proteins"]]) |>
    data.frame() |>
    filter(grepl("TAL._YEAST", Majority.protein.IDs)) |>
    select(Protein.IDs, Majority.protein.IDs)
```

### Evidence data

```{r}
evidence <- read.delim(evidenceFile)
coldata$runCol <- coldata$Raw.file
evidence <- readQFeatures(
    evidence, colData = coldata, runCol = "Raw.file", 
    quantCols = "Intensity"
)
evidence <- preprocessing_workflow(
    evidence, names(evidence), level = "psm"
)
```

### Peptides file

```{r}
peptides <- read.delim(peptidesFile)
coldata$quantCols <- paste0("Intensity.", coldata$sample)
peptides <- readQFeatures(
    peptides, colData = coldata, name = "peptides", 
    fnames = "Sequence"
)
peptides <- preprocessing_workflow(
    peptides, "peptides", level = "peptide"
)
```

### ProteinGroups data

```{r}
proteinGroups <- read.delim(proteinGroupsFile)
proteinGroups <- readQFeatures(
    proteinGroups, colData = coldata, name = "proteinGroups",
    fnames = "Protein.IDs"
)
proteinGroups <- preprocessing_workflow(
    proteinGroups, "proteinGroups", level = "protein"
)
```

```{r}
cptac <- c(evidence, peptides, proteinGroups)
```

## Data modelling

### Model definition

```{r}
models <- list(
    psm = ~ condition + (1 | lab) + (1 | sample) + (1 | ionID), 
    peptide = ~ condition + (1 | lab) + (1 | sample) + (1 | Sequence), 
    protein = ~ condition + (1 | lab)
)
```

### Hypothesis testing

The same contrasts are shared across approaches

```{r}
allContrasts <- createPairwiseContrasts(
    models$protein, colData(cptac), var = "condition", ridge = TRUE
)
L <- makeContrast(
    allContrasts, 
    .getParamNames(
        models$protein, colData(cptac), var = "condition", ridge = TRUE
    )
)
```

### The modelling workflow

```{r}
modelling_workflow <- function(object, i, model, L, fcol = NA) {
    if (is.na(fcol)) {
        object <- msqrob(
            object,  i = i, formula = model,
            ridge = TRUE, robust = TRUE
        )
    } else {
        object <- msqrobAggregate(
            object,  i = i, formula = model, 
            fcol = fcol, name = "msqrob",
            robust = TRUE, ridge = TRUE
        )
        i <- "msqrob"
    }
    object <- hypothesisTest(object, i, contrast = L)
    out <- msqrobCollect(object[[i]], L, combine = TRUE)
    out
}
```


```{r}
(approaches <- data.frame(
    inputLevel = c("psm", "psm", "peptide", "peptide", "protein"),
    modelLevel = c("protein", "psm", "protein", "peptide", "protein"),
    set = c("evidence_proteins", "evidence_norm", "peptides_proteins", "peptides_norm", "proteinGroups_log"),
    fcol = c(NA, "Proteins", NA, "Proteins", NA)
))
```


```{r}
results <- apply(approaches, 1, function(x) {
    out <- modelling_workflow(
        cptac, i = x[["set"]], model = models[[x[["modelLevel"]]]],
        L = L, fcol = x[["fcol"]]
    )
    out$modelLevel <- x[["modelLevel"]]
    out$inputLevel <- x[["set"]]
    out
})
results <- do.call(rbind, results)
```


```{r}
results$isUps <- grepl("ups", results$feature)
results$contrast <- gsub("ridgecondition", "", results$contrast)
results$contrast <- gsub("^(6[B-E])$", "\\1 - 6A", results$contrast)
```

## Performance benchmark

### Number of fits

```{r}
group_by(results, inputLevel) |> 
    summarise(n = sum(!is.na(adjPval))) |> 
    ggplot() +
    aes(x = inputLevel, y = n, fill = inputLevel) +
    geom_bar(stat = "identity")
```


### TPR-FDP  curves

```{r}
computeFDP <- function(pval, tp) {
    ord <- order(pval)
    fdp <- cumsum(!tp[ord]) / 1:length(tp)
    fdp[order(ord)]
}
computeTPR <- function(pval, tp, nTP = NULL) {
    if (is.null(nTP)) nTP <- sum(tp)
    ord <- order(pval)
    tpr <- cumsum(tp[ord]) / nTP
    tpr[order(ord)]
}
```

```{r}
performance <- group_by(results, inputLevel, contrast) |> 
    filter(!is.na(adjPval)) |>
    mutate(tpr = computeTPR(pval, isUps),
           fdp = computeFDP(pval, isUps)) |>
    arrange(fdp)
```

```{r}
workPoints <- group_by(performance, inputLevel, contrast) |>
    filter(adjPval < 0.05) |>
    slice_max(adjPval) |>
    filter(!duplicated(inputLevel))
```

```{r, fig.width=10, fig.height=8}
ggplot(performance) +
    aes(y = fdp,
        x = tpr,
        colour = inputLevel) +
    geom_line() +
    geom_point(data = workPoints, size = 3) +
    geom_hline(yintercept = 0.05, linetype = 2) +
    facet_wrap(~ contrast) +
    coord_flip(ylim = c(0, 0.2)) +
    theme(legend.position = "bottom")
```

### TP and FP at 5% FDR

```{r, fig.height=20, fig.width=6}
tpFpTable <- group_by(results, inputLevel, contrast) |>
    filter(!is.na(adjPval)) |>
    summarise("True Positives" = sum(adjPval < 0.05 & isUps),
              "False Positives" = sum(adjPval < 0.05 & !isUps)) |>
    pivot_longer(cols = c("True Positives", "False Positives"))
```


```{r, fig.height=20, fig.width=6}
ggplot(tpFpTable) +
    aes(x = inputLevel,
        y = value,
        fill = inputLevel) +
    geom_bar(stat = "identity") +
    facet_grid(contrast ~ name, scales = "free") +
    guides(fill = guide_legend(nrow = 2)) +
    labs(x = "", y = "Count") +
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          legend.position = "bottom")
```
