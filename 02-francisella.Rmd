# The francisella use case: a MaxQuant LFQ dataset {#sec-francisella}

```{r, include = FALSE}
knitr::opts_chunk$set(
    warning = FALSE,
    message = FALSE
)
```

## Introduction

TODO write section

In this vignette,...

## Load packages

First, we load the `msqrob2` package.

```{r}
library("msqrob2")
```

We also load 4 additional packages for data manipulation and
visualisation.

```{r}
library("ggplot2")
library("ggrepel")
library("dplyr")
```

`msqrob2` relies on parallelisation to improve computational speed.
To ensure this vignette can be run regardless of hardware, we will
disable parallelisation. Parallelisation is controlled using the
`BiocParallel` package.

```{r}
library("BiocParallel")
register(SerialParam())
```

## Load data

### Experimental context

A study on the facultative pathogen Francisella tularensis was
conceived by [Ramond et al.
(2015)](https://www.mcponline.org/article/S1535-9476(20)33188-1/fulltext).
F. tularensis enters the cells of its host by phagocytosis. The
authors showed that F. tularensis is arginine deficient and imports
arginine from the host cell via an arginine transporter, ArgP, in
order to efficiently escape from the phagosome and reach the cytosolic
compartment, where it can actively multiply. In their study, they
compared the proteome of wild type F. tularensis (WT) to ArgP-gene
deleted F. tularensis (knock-out, D8). For this exercise, we use a
subset of the F. tularensis dataset where bacterial cultures were
grown in biological quadruplicate and each biorep was run in technical
triplicate on a nanoRSLC-Q Exactive PLUS instrument. 

**TODO** the design mentions quadruplicates, but the vignette has triplicates

### Getting the data

The data were
searched with MaxQuant version 1.4.1.2. and are available on the PRIDE
repository:
[PXD001584](https://www.ebi.ac.uk/pride/archive/projects/PXD001584).

**TODO** put on Zenodo and use BiocFileCache
```{r}
pepFile <- "../data/francisella/peptides.txt"
```

Now the files are downloaded, we can load the psm table. Each row in
the psm data table contains information for one PSM (the table below
shows the first 6 rows). Note that columns that start with
`"Abundance."` contain the quantitative values for each TMT label.

```{r, warning=FALSE, message=FALSE}
peps <- read.delim(pepFile)
quantcols <- grep("Intensity\\.", names(peps), value = TRUE)
```
```{r, echo=FALSE}
knitr::kable(head(peps))
```

We now extract the sample annotations. We will build a table where
each row in the annotation table contains information for one sample
(the table below shows the first 6 rows). This information is
extracted from the sample names.

**TODO** work on full data (20 and 100) or on subset?

```{r}
coldata <- data.frame(quantCols = quantcols) |> 
  filter(grepl("_20_", quantCols) & grepl("_n\\d", quantCols)) |> 
  mutate(genotype  = substr(quantCols, 12, 13)) |> 
  mutate(biorep  = paste0(genotype, "_", substr(quantCols, 21, 22)))
```
```{r, echo=FALSE}
knitr::kable(head(coldata))
```

### The `QFeatures` data class

Finally, we combine the data into a `QFeatures` object. The
`QFeatures` package provides infrastructure to manage and analyse
quantitative features from mass spectrometry experiments. The
`readQFeatures()` allows for seamless conversion of tabular data into
a `QFeatures` object. The `quantCols` column in the annotation will be
used to link the annotations with the quantitative columns of the
peptide data. See `?readQFeatures()` for more details.

```{r}
pe <- readQFeatures(
  peps, colData = coldata, fnames = "Sequence", name = "peptides"
)
```

Peptides with zero intensities are missing peptides and should be
represent with a `NA` value rather than `0`.

```{r}
pe <- zeroIsNA(pe, "peptides") # convert 0 to NA
```

We calculate how many non zero intensities we have per peptide and
this is often useful for filtering.

```{r}
naResults <- nNA(pe, "peptides")
data.frame(naResults$nNArows) |> 
  ggplot() +
  aes(x = nNA) +
  geom_histogram()
```

Because every biorep is assessed in technical triplicate, we will also
calculate the number of biorepeats in which each peptide is observed.

**TODO** make a function for this?

```{r}
rowData(pe[["peptides"]])$nNonZeroBiorep <- apply(
  assay(pe[["peptides"]]), 1, function(intensity)
    pe$biorep[intensity > 0] |> 
    unique() |> 
    length()
)
```

## Data preprocessing

`msqrob2` relies on the `QFeatures` data structure, meaning that we
can directly make use of `QFeatures`' data preprocessing functionality
(see also the `QFeatures`
[documentation](https://rformassspectrometry.github.io/QFeatures/articles/Processing.html)).

### PSM filtering

We filter features based on 3 criteria.

1. Handling overlapping protein groups

In our approach a peptide can map to multiple proteins, as long as
there is none of these proteins present in a smaller subgroup. We use
`filterFeatures()` to perform the filtering. It uses information from
the `rowData` (here the `Proteins` column) and a formula to generate a
filter for each feature (row) in each set across the object. If the
filter returns `TRUE`, the corresponding row is retained, otherwise it
is removed. In this case, we build a filter that only keeps the
protein groups for which none of its member proteins is present in a
smaller protein group.

```{r}
pe <- filterFeatures(pe,
  ~ Proteins %in% smallestUniqueGroups(Proteins)
)
```

2. Remove reverse sequences (decoys) and contaminants

We now remove the contaminants and peptides that map to decoy 
sequences. These features bear no information of interest and will
reduce the statistical power upon multiple test adjustment.

```{r}
pe <- filterFeatures(pe, ~ Reverse != "+" & Contaminant != "+")
```

3. Drop peptides that were only identified in a single biorepeat

Note, that in experiments without technical repeats we filter on the
number of samples in which a peptide is picked up (this is typically 
performed using `filterNA()`). Here, we will require that a peptide is
picked up in at least two biorepeats. We already computed the number
of biorepeats that were observed for each peptide (that is the number
of biorepeats that contain at least one observed value).

```{r}
(pe <- filterFeatures(pe, ~ nNonZeroBiorep >= 2))
```

We keep `r nrow(pe[["peptides"]])` peptides upon filtering.

### Preprocessing workflow

We can now prepare the data for modelling. The workflow ensures the
data complies to `msqrob2`'s requirements:

1. Intensities are log-transformed.

```{r}
pe <- logTransform(pe, base = 2, i = "peptides", name = "peptides_log")
```

2. Samples are normalised by substracting the sample median from every
   intensity for peptide $p$  in a sample $i$. $y_{ip}^\text{norm} =
   y_{ip} - \hat\mu_i$, with $\hat\mu_i$ the median intensity over all
   observed peptides in sample $i$.

```{r}
pe <- normalize(
  pe, i = "peptides_log", name = "peptides_norm", method = "center.median"
)
```

Upon the normalisation the density curves should be nicely centred. To
confirm this, we will plot the intensity distributions for each
biorepeat (mouse). `longForm()` seamlessly combines the quantification
and annotation data into a table suitable for `ggplot2` visualisation.
We also subset the object with the data before and after normalisation.

```{r}
longForm(pe[, , c("peptides_log", "peptides_norm")], colvar = "biorep") |> 
  ggplot() +
  aes(x = value, group = colname, color = biorep) +
  geom_density() +
  facet_wrap(~ assay, scale = "free")
```

3. Summarisation to protein level. We use the robust summary approach 
   to infer protein-level data from peptide-level data, accounting for
   the fact that different peptides have ionisation efficiencies hence
   leading to different intensity baselines. This effect can be
   ignored if the same set of peptides were measured across all
   samples, but this is often not the case, leading to biased
   estimates. Moreover, our approach also uses a robust estimation to
   avoid that outliers distort the summaries.

```{r,warning=FALSE}
pe <- aggregateFeatures(
  pe, i = "peptides_norm", fcol = "Proteins", 
  fun = MsCoreUtils::robustSummary, na.rm = TRUE, name = "proteins"
)
```

## Statistical modelling

The preprocessed data can now be modelled to answer biologically
relevant questions. First, we will explore the data. 

### Data exploration

Data exploration aims to highlight the sources of variation in the
data prior to data modelling and can pinpoint to outlying or
off-behaving samples. A common approach for data exploration is to
perform Multi Dimensional Scaling (MDS). We will first extract the set
to explore using `getWithColData()`. This function extracts the set of
interest along with all the associated sample annotations (used for
plot colouring).

```{r}
se <- getWithColData(pe, "proteins")
```

We then use the `scater` package to compute and plot the PCA. For
technical reasons, it requires `SingleCellExperiment` class object,
but these can easily be generated from a `SummarizedExperiment`
object.

```{r}
library("scater")
se <- runMDS(as(se, "SingleCellExperiment"), exprs_values = 1)
plotMDS(se, colour_by = "genotype")
```
Note that the samples upon robust summarisation show a clear
separation according to the genotype in the first dimension of the MDS
plot.

### Model definition

#### Experimental design

As described above, samples (bacterial cultures) originate from either
a wildtype (WT) or a ArgP knockout (D8). Each genotype was cultured in
biological triplicate. Each biological triplicate was acquired in
technical triplicate, leading to $2 \times 3 \times 3 = 18$ samples.
In this context, we are interested in the effects of genotype on the
protein abundances. 

The table below confirms we have a balanced design
for each condition and biological triplicate.

```{r}
table(genotype = pe$genotype, biorep = pe$biorep)
```

### Sources of variation

We will model two sources of variation:

1. **Genotype**: we model the source of variation induced by the
   experimental group of interest as a **fixed effect**. Fixed effects
   are effect that are considered non-random, i.e. the treatment
   effect is assumed to be the same and reproducible across repeated
   experiments, but it is unknown and has to be estimated. We will
   include `genotype` as a fixed effect that models the fact that a
   change in genotype can induce changes in protein abundance.

2. **Biological replicate effect**: the experiment involves biological
   replication as the bacterial cultures are repeated. Replicate-specific
   effects occurs due to uncontrollable factors, such as variation in
   the number of bacterium seeded, position in the incubator,
   transient contamination,... Two bacterial cultures will never
   provide exactly the same sample material. These effects are typically
   modelled as random effects which are considered as a random sample
   from the population of all possible mice and are assumed to be
   i.i.d normally distributed with mean 0 and constant variance,
   $u_{biorep} \sim
   N(0,\sigma^{2,\text{biorep}})$. The use of random effects thus
   models the correlation in the data, explicitly. We expect that
   intensities from the same bacterial culture are more alike than 
   intensities between cultures.

We model the protein level expression values using `msqrob2`.
`msqrob2` workflows rely on linear mixed models, which are models that
can estimate and predict fixed and random effects, respectively. The
fixed effect are estimated using robust regression to avoid that
outliers distort the statistical outcome.

Now we have identified the sources of variation in the experiment, we
can define a model. 

```{r}
model <- ~ genotype + ## (1) fixed effect for genotype
  (1 | biorep)  ## (2) random effect for biological replicate (culture)
```

We can run the `msqrob2` statistical workflow.

### Run the model

The statistical workflow starts with `msqrob()`. The function takes
the `QFeatures` object, extracts the quantitative values from the
`proteins` set generated after preprocessing, and fits `model`. The
variables defined in `model` are automatically retrieved from the
`colData` (i.e. `"genotype"`, and `"biorep"`). Upon modelling, the
function return the `Qfeatures` object containing the modelling
output, stored in the `rowData` (by default, the new column is called
`msqrobModels`). More specifically, the modelling output is stored in
the `rowData` as a `statModel` object, one model per row (protein). We
also enable M-estimation (`robust = TRUE`) for improved robustness
against outliers. Note, that `msqrob2` also features ridge regression
for fixed effects. Ridge regression stabilises the parameter
estimation in case where the number of parameters are close to the
number of available samples. In this case, the genotype factor only
has 2 levels (WT and D8), so ridge regression is irrelevant in this
context. We will therefore leave the ridge regression disabled
(default).

```{r}
pe <- msqrob(pe, i = "proteins", formula = model, robust = TRUE)
```

Once the models are estimated, we can start answering biological
questions.

### Hypothesis testing

We must now convert the biological question "does the bacterial
genotype affect the protein intensities?" into a statistical
hypothesis. In other words, we must convert
this question in a combination of the model parameters, also referred
to as a contrast. To aid defining contrasts, we will visualise the
experimental design using the `ExploreModelMatrix` package. Since we
are not interested in technical effects, we will only focus on the
variable of interest, here `genotype`.

```{r}
library("ExploreModelMatrix")
vd <- VisualizeDesign(
    sampleData =  colData(pe),
    designFormula = ~ genotype,
    textSizeFitted = 4
)
vd$plotlist
```

This plot shows that the average protein intensity for the D8 group is
estimated by `(Intercept)`, and the the average protein intensity for
the WT group is estimated by `(Intercept) + genotypeWT`. These values
can get be retrieved from the `rowData`, here showing an example for
the first protein:

```{r}
getCoef(rowData(pe)[["proteins"]]$msqrobModels[[1]])
```

Note that additionnal intercepts are printed, one for each level of
the random effect.

Assessing the difference between the WT and D8 groups boils down to 
`(Intercept) + genotypeWT - (Intercept)`, which simplifies to the
`genotypeWT` parameters:

```{r}
contrast <- "genotypeWT"
```

We can further specify the null hypothesis, that is we are interest
whether the differences between the two groups is different from zero.

```{r}
(hypothesis <- paste(contrast, "= 0"))
```

We next use `makeContrast()` to build a contrast matrix.

```{r}
(L <- makeContrast(hypothesis, parameterNames = "genotypeWT"))
```

In this case, the contrast matrix is trivial, but for more complex
design, it becomes a matrix with parameter names as rows and
hypotheses in columns (you can specify multiple hypotheses).

We can now test our null hypothesis using `hypothesisTest()` which
takes the `QFeatures` object with the fitted model and the contrast
matrix we just built. Again, the results are stored in the set
containing the model, here `proteins`.

```{r}
pe <- hypothesisTest(pe, i = "proteins", contrast = L)
```

Let us retrieve the result table from the `rowData`. Note that the
model column is named after the column name (here `genotypeWT`) of the
contrast matrix `L`.

```{r}
inference <- rowData(pe[["proteins"]])[[colnames(L)]]
inference$Protein <- rownames(inference)
head(inference)
```

`msqrob2` automatically applied the hypothesis testing to all proteins
in the data. Notice that some rows contain missing values. Notice that
some rows contain missing values. This is because data modelling
resulted in a `fitError` for some proteins, probably because not
enough data was available for model fitting due to missing values in
the quantitative data.

### Plots

We will now demonstrate how to visualise the results upon modelling
and hypothesis testing.

#### Volcano-plot

Volcano plots are straightforward to generate from the inference table
above. We also use `ggrepel` to annotate the 20 most significant 
proteins.

```{r}
ggplot(inference) +
  aes(x = logFC, y = -log10(pval), color = adjPval < 0.05) +
  geom_point() +
  geom_text_repel(data = slice_min(inference, adjPval, n = 20),
                  aes(label = Protein)) +
  scale_color_manual(values = alpha(c("black", "red"), 0.5)) + 
  ggtitle("Statistical inference on differences between WT and D8",
          paste("Hypothesis test:", colnames(L), "= 0"))
```

Note, that `r sum(inference$adjPval < 0.05, na.rm = TRUE)` proteins
are found to be differentially abundant.

#### Heatmap

We can also build a heatmap for the significant proteins which are
obtained by filtering the inference table.

**TODO** use ComplexHeatmap for adding annotations? 

```{r}
sigNames <- inference |> 
  filter(!is.na(adjPval), adjPval < 0.05) |> 
  pull()
heatmap(assay(pe[["proteins"]])[sigNames, ])
```

#### Detail plots

Let us visualise the most significant protein. We perform this with a
little data manipulation pipeline:

1. Identify the target protein with largest logFC.
2. We use the `QFeatures` subsetting functionality to retrieve all
   data related to the target protein, focusing on the `proteins`
   set that contains the preprocessed data used for modelling.
3. We use `longForm()` to convert the object into a table suitable
   for plotting.
4. We remove missing values for plotting.
5. Plot the data with `ggplot2`.

```{r}
targetProtein <- rownames(inference)[which.min(inference$adjPval)] #1
pe[targetProtein, , "proteins"] |> #2
  longForm(colvars = "genotype") |>  #3
  data.frame() |>
  filter(!is.na(value)) |> #4
  ggplot() + #5
  aes(x = colname,
      y = value) +
  geom_point(aes(colour = genotype)) +
  labs(x = "Sample", y = "log2 intensity") +
  ggtitle(targetProtein) +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))
```

**TODO** include peptide workflow as well? add one line that quickly shows how to perform it.

## Conclusion

**TODO**

## License

This vignette is distributed under a
[Artistic-2.0](https://opensource.org/license/artistic-2-0) license.

## Session Info

```{r}
sessionInfo()
```


## References
