# The francisella use case: a MaxQuant LFQ DDA dataset {#sec-francisella}

## Introduction

**TODO** write section
**TODO** describe the general experimental design, and mention 
         that this design is also applicable when having multiple
         samples from patients

In this vignette,...

If you never used `msqrob2`, we suggest to familiarise yourself
with the [concept chapter](#sec-concepts) first.

## Load packages

First, we load the `msqrob2` package and additional packages for data
manipulation and visualisation.

```{r}
library("msqrob2")
library("ggplot2")
library("ggrepel")
library("dplyr")
```

We also configure the [parallelisation](#sec-parallel) framework.

```{r}
library("BiocParallel")
register(SerialParam())
```

## Load data

### Experimental context

A study on the facultative pathogen Francisella tularensis was
conceived by [Ramond et al.
(2015)](https://www.mcponline.org/article/S1535-9476(20)33188-1/fulltext).
F. tularensis enters the cells of its host by phagocytosis. The
authors showed that F. tularensis is arginine deficient and imports
arginine from the host cell via an arginine transporter, ArgP, in
order to efficiently escape from the phagosome and reach the cytosolic
compartment, where it can actively multiply. In their study, they
compared the proteome of wild type F. tularensis (WT) to ArgP-gene
deleted F. tularensis (knock-out, D8). For this exercise, we use a
subset of the F. tularensis dataset where bacterial cultures were
grown in biological triplicate and each biorep was run in technical
triplicate on a nanoRSLC-Q Exactive PLUS instrument. 

### Getting the data

The data were
searched with MaxQuant version 1.4.1.2. and are available on the PRIDE
repository:
[PXD001584](https://www.ebi.ac.uk/pride/archive/projects/PXD001584).

**TODO** put on Zenodo and use BiocFileCache

```{r}
pepFile <- "./data/francisella/peptides.txt"
```

After downloading the files, we can load the peptide table. Contrarily
a [PSM table](#sec-psm_table), the peptide table is provided in a
"wide format", meaning that each row represents a single peptide and
that each quantification column (that starts with `"Intensity"`)
represents a single sample.

```{r, warning=FALSE, message=FALSE}
peps <- read.delim(pepFile)
quantcols <- grep("Intensity\\.", names(peps), value = TRUE)
```
```{r, echo=FALSE}
knitr::kable(head(peps))
```

We now extract the [sample annotations](#sec-annotation_table). We
will build a table where each row in the annotation table contains
information for one sample (the table below shows the first 6 rows).
This information is extracted from the sample names.

```{r}
coldata <- data.frame(quantCols = quantcols) |> 
  filter(grepl("_20_", quantCols) & grepl("_n\\d", quantCols)) |> 
  mutate(genotype  = substr(quantCols, 12, 13)) |> 
  mutate(biorep  = paste0(genotype, "_", substr(quantCols, 21, 22)))
```
```{r, echo=FALSE}
knitr::kable(head(coldata))
```

### The `QFeatures` data class

We combine the two tables into a [`QFeatures` object](#sec-qfeatures).

```{r}
(pe <- readQFeatures(
  peps, colData = coldata, fnames = "Sequence", name = "peptides"
))
```

We now have a `QFeatures` object with 1 set, containing `r
nrows(pe)[[1]]` rows (peptides) and `r ncols(pe)[[1]]` columns
(samples). 

## Data preprocessing

`msqrob2` relies on the `QFeatures` data structure, meaning that we
can directly make use of `QFeatures`' data preprocessing functionality
(see also the `QFeatures`
[documentation](https://rformassspectrometry.github.io/QFeatures/articles/Processing.html)).

### Encoding missing values

Peptides with zero intensities are missing peptides and should be
represent with a `NA` value rather than `0` (see [Encoding missing
values]).

```{r}
pe <- zeroIsNA(pe, "peptides")
```

We calculate how many non zero intensities we have per peptide and
this is often useful for filtering.

```{r}
naResults <- nNA(pe, "peptides")
data.frame(naResults$nNArows) |> 
  ggplot() +
  aes(x = nNA) +
  geom_histogram()
```

Because every biorep is assessed in technical triplicate, we will also
calculate the number of biorepeats in which each peptide is observed.

**TODO** make a function for this?

```{r}
rowData(pe[["peptides"]])$nNonZeroBiorep <- apply(
  assay(pe[["peptides"]]), 1, function(intensity)
    pe$biorep[intensity > 0] |> 
    unique() |> 
    length()
)
```


### PSM filtering

We filter features based on 3 criteria (see [PSM filtering]).

1. Handling overlapping protein groups

In our approach a peptide can map to multiple proteins, as long as
there is none of these proteins present in a smaller subgroup. 

```{r}
pe <- filterFeatures(pe,
  ~ Proteins %in% smallestUniqueGroups(Proteins)
)
```

2. Remove reverse sequences (decoys) and contaminants

We now remove the contaminants and peptides that map to decoy 
sequences. These features bear no information of interest and will
reduce the statistical power upon multiple test adjustment.

```{r}
pe <- filterFeatures(pe, ~ Reverse != "+" & Contaminant != "+")
```

3. Drop peptides that were only identified in a single biorepeat

Note, that in experiments without technical repeats we filter on the
number of samples in which a peptide is picked up (this is typically 
performed using `filterNA()`). Here, we will require that a peptide is
picked up in at least two biorepeats. We already computed the number
of biorepeats that were observed for each peptide (that is the number
of biorepeats that contain at least one observed value).

```{r}
(pe <- filterFeatures(pe, ~ nNonZeroBiorep >= 2))
```

We keep `r nrow(pe[["peptides"]])` peptides upon filtering.

### Standard preprocessing workflow

We can now prepare the data for modelling. The workflow ensures the
data complies to `msqrob2`'s requirements:

1. Intensities are [log-transformed](#sec-log2).

```{r}
pe <- logTransform(pe, base = 2, i = "peptides", name = "peptides_log")
```

2. Samples are normalised by substracting the sample median (see 
   [Normalisation])

```{r}
pe <- normalize(
  pe, i = "peptides_log", name = "peptides_norm", method = "center.median"
)
```

Upon the normalisation the density curves should be nicely centred. To
confirm this, we will plot the intensity distributions for each
biorepeat (mouse). `longForm()` seamlessly combines the quantification
and annotation data into a table suitable for `ggplot2` visualisation.
We also subset the object with the data before and after normalisation.

```{r}
longForm(pe[, , c("peptides_log", "peptides_norm")], colvar = "biorep") |> 
  ggplot() +
  aes(x = value, group = colname, color = biorep) +
  geom_density() +
  facet_wrap(~ assay, scale = "free")
```

3. [Summarisation] to protein level. We use the [robust summary] approach 
   to infer protein-level data from peptide-level data, accounting for
   the fact that different peptides have ionisation efficiencies hence
   leading to different intensity baselines. 

```{r,warning=FALSE}
pe <- aggregateFeatures(
  pe, i = "peptides_norm", fcol = "Proteins", 
  fun = MsCoreUtils::robustSummary, na.rm = TRUE, name = "proteins"
)
```

## Data exploration

We will explore the main sources of variation in the
data using (see [Data exploration]). 

```{r}
library("scater")
getWithColData(pe, "proteins") |> 
  as("SingleCellExperiment") |> 
  runMDS(exprs_values = 1) |> 
  plotMDS(colour_by = "genotype")
```

Note that the samples upon robust summarisation show a clear
separation according to the genotype in the first dimension of the MDS
plot.

## Data modelling

The preprocessed data can now be modelled to answer biologically
relevant questions. As described above, samples (bacterial cultures) originate from either
a wildtype (WT) or a ArgP knockout (D8). Each genotype was cultured in
biological triplicate. Each biological triplicate was acquired in
technical triplicate, leading to $2 \times 3 \times 3 = 18$ samples.
In this context, we are interested in the effects of genotype on the
protein abundances. 

The table below confirms we have a balanced design
for each condition and biological triplicate.

```{r}
table(genotype = pe$genotype, biorep = pe$biorep)
```

### Sources of variation

We will model two [sources of variation](#sec-modelling):

1. **Genotype**: we model the source of variation induced by the
   experimental group of interest as a **fixed effect**. Fixed effects
   are effect that are considered non-random, i.e. the treatment
   effect is assumed to be the same and reproducible across repeated
   experiments, but it is unknown and has to be estimated. We will
   include `genotype` as a fixed effect that models the fact that a
   change in genotype can induce changes in protein abundance.

2. **Biological replicate effect**: the experiment involves biological
   replication as the bacterial cultures are repeated. Replicate-specific
   effects occurs due to uncontrollable factors, such as variation in
   the number of bacterium seeded, position in the incubator,
   transient contamination,... Two bacterial cultures will never
   provide exactly the same sample material. These effects are typically
   modelled as random effects which are considered as a random sample
   from the population of all possible mice and are assumed to be
   i.i.d normally distributed with mean 0 and constant variance,
   $u_{biorep} \sim
   N(0,\sigma^{2,\text{biorep}})$. The use of random effects thus
   models the correlation in the data, explicitly. We expect that
   intensities from the same bacterial culture are more alike than 
   intensities between cultures.

We model the protein level expression values using `msqrob2`.
`msqrob2` workflows rely on linear mixed models, which are models that
can estimate and predict fixed and random effects, respectively. The
fixed effect are estimated using robust regression to avoid that
outliers distort the statistical outcome.

Now we have identified the sources of variation in the experiment, we
can define a model. 

```{r}
model <- ~ genotype + ## (1) fixed effect for genotype
  (1 | biorep)  ## (2) random effect for biological replicate (culture)
```

### Estimate the model

We estimate the model with `msqrob()` (see [the modelling
section](#sec-run_model)). Recall that
variables defined in `model` are automatically retrieved from the
`colData` (i.e. `"genotype"`, and `"biorep"`). Note, that `msqrob2`
also features ridge regression for stabilising the parameter
estimation, but it is irrelevant in this context as the genotype
factor only has 2 levels (WT and D8), so ridge regression . We will
therefore leave the ridge regression disabled (default).

```{r run_msqrob, cache=TRUE}
pe <- msqrob(pe, i = "proteins", formula = model, robust = TRUE)
```

## Statistical inference

Once the models are estimated, we can start answering biological
questions by performing [Statistical inference]. We must convert the
biological question "does the bacterial genotype affect the protein
intensities?" into a statistical hypothesis. In other words, we must
convert this question in a combination of the model parameters, also
referred to as a contrast. To aid defining contrasts, we will
visualise the experimental design using the `ExploreModelMatrix`
package. Since we are not interested in technical effects, we will
only focus on the variable of interest, here `genotype`.

```{r}
library("ExploreModelMatrix")
vd <- VisualizeDesign(
    sampleData =  colData(pe),
    designFormula = ~ genotype,
    textSizeFitted = 4
)
vd$plotlist
```

This plot shows that the average protein intensity for the D8 group is
estimated by `(Intercept)`, and the the average protein intensity for
the WT group is estimated by `(Intercept) + genotypeWT`. 

### Hypothesis testing

Assessing the difference between the WT and D8 groups boils down to
`(Intercept) + genotypeWT - (Intercept)`, which simplifies to the
`genotypeWT` parameter. The null hypothesis is that the differences
between the two groups is zero, hence the estimated parameter is zero.

```{r}
hypothesis <- "genotypeWT = 0"
```

We next use `makeContrast()` to build the contrast matrix.

```{r}
(L <- makeContrast(hypothesis, parameterNames = "genotypeWT"))
```

In this case, the contrast matrix is trivial, but it becomes a matrix
but for [more complex designs](#sec-multiple_contrasts). We can now
test our null hypothesis:

```{r}
pe <- hypothesisTest(pe, i = "proteins", contrast = L)
```

Let us retrieve the result table from the `rowData`. Note that the
hypothesis testing results are stored in `rowData` columns named after
the column names (here `genotypeWT`) of the contrast matrix `L`.

```{r}
inference <- rowData(pe[["proteins"]])[[colnames(L)]]
inference$Protein <- rownames(inference)
head(inference)
```

Notice that some rows contain missing values. This is because data
modelling resulted in a `fitError` for some proteins, probably because
not enough data was available for model fitting due to missing values
in the quantitative data (see [how to deal with
`fitError`s](#sec-fiterror)).
 
### Volcano-plot

Volcano plots are straightforward to generate from the inference table
above. We also use `ggrepel` to annotate the 20 most significant 
proteins.

```{r}
ggplot(inference) +
  aes(x = logFC, y = -log10(pval), color = adjPval < 0.05) +
  geom_point() +
  geom_text_repel(data = slice_min(inference, adjPval, n = 20),
                  aes(label = Protein)) +
  scale_color_manual(values = alpha(c("black", "red"), 0.5)) + 
  ggtitle("Statistical inference on differences between WT and D8",
          paste("Hypothesis test:", colnames(L), "= 0"))
```

Note, that `r sum(inference$adjPval < 0.05, na.rm = TRUE)` proteins
are found to be differentially abundant.

### Heatmap

We can also build a heatmap for the significant proteins which are
obtained by filtering the inference table.

**TODO** use ComplexHeatmap for adding annotations? 

```{r}
sigNames <- inference |> 
  filter(!is.na(adjPval), adjPval < 0.05) |> 
  pull()
heatmap(assay(pe[["proteins"]])[sigNames, ])
```

### Detail plots

Let us visualise the most significant protein. We perform this with a
little data manipulation pipeline:

1. Identify the target protein with largest logFC.
2. We use the `QFeatures` subsetting functionality to retrieve all
   data related to the target protein, focusing on the `proteins`
   set that contains the preprocessed data used for modelling.
3. We use `longForm()` to convert the object into a table suitable
   for plotting.
4. We remove missing values for plotting.
5. Plot the data with `ggplot2`.

```{r}
targetProtein <- rownames(inference)[which.min(inference$adjPval)] #1
pe[targetProtein, , "proteins"] |> #2
  longForm(colvars = "genotype") |>  #3
  data.frame() |>
  filter(!is.na(value)) |> #4
  ggplot() + #5
  aes(x = colname,
      y = value) +
  geom_point(aes(colour = genotype)) +
  labs(x = "Sample", y = "log2 intensity") +
  ggtitle(targetProtein) +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))
```

## Conclusion

**TODO** mention peptide workflows exist as well and link to first 
chapter?

**TODO** write conclusion

