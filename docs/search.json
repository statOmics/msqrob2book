[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical analysis of mass spectrometry-based proteomics data",
    "section": "",
    "text": "Preamble\nThis book provides comprehensive hands-on tutorials on how to apply the msqrob2 software for the statistical analysis of mass spectrometry (MS)-based proteomics data. It includes the latest improvements of the software that enable statistical modelling for a wide panel of use cases. The book first introduces general concepts of statistical proteomics data analysis and msqrob2. Further chapters will demonstrate the application of msqrob2 for assessing different biological questions starting from datasets with different experimental designs, acquisition strategies, instruments, and search engines. The book aims to help proteomics researchers and data analysists tailoring their statistical analysis workflow to their specific datasets and research questions.\nThe sticker is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "index.html#why-msqrob2",
    "href": "index.html#why-msqrob2",
    "title": "Statistical analysis of mass spectrometry-based proteomics data",
    "section": "Why msqrob2?",
    "text": "Why msqrob2?\nMS-based proteomics experiments often imposes a complex correlation structure among observations. Addressing this correlation is key for correct statistical inference and reliable biomarker discovery. This msqrob2 book provides a set of (mixed) model-based workflows dedicated to differential abundance analysis for label-free as well as labeled MS-based proteomics data. The key features of msqrob2 workflows are:\n\nModularity: all core functions rely on the QFeatures class, a standardised data structure, meaning that output of a function can be fed as input to any other function. Hence, different functions are assembled as modular blocks into a complete data analysis workflows that can be easily adapted to the peculiarities of any MS-based proteomics data set. Therefore, the approach extends well beyond the use case presented in this chapter\nFlexibility: the msqrob2 modelling approach relies on the lme4::lmer() model specification syntax, meaning that any linear model can be specified. For fixed effects, this includes modelling categorical and numerical variables, as well as their interaction. Moreover, msqrob2 can model both sample-specific and feature-specific (e.g. peptide or protein) covariates, which unlocks the inference to experiments with arbitrarily complex designs as well as to correct explicitly for feature-specific properties.\nPerformance: thanks to the inclusion of robust ridge regression, we demonstrated improved performance of msqrob2 workflows upon the competing software (Goeminne, Gevaert, and Clement 2016; Sticker et al. 2020; Vandenbulcke et al. 2025).",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "index.html#outline",
    "href": "index.html#outline",
    "title": "Statistical analysis of mass spectrometry-based proteomics data",
    "section": "Outline",
    "text": "Outline\nThe book is divided in three parts.\n\nConcepts\nThis parts introduces the user to the key concepts in differential proteomics data analysis and provides extensive description of the code. While this part is conceptual, the concepts are illustrated using a real spike-in study.\n\n1  Statistical analysis with msqrob2 introduces the basic concepts for MS-based proteomics analysis. We recommend our users to first read this chapter before reading any other chapter.\n2  Advanced statistical analysis with msqrob2 builds upon the previous chapter and introduces more advanced concepts that will be used in later chapters that involve complex designs and analyses.\n\n\n\nBenchmarking\nThis part illustrates how to benchmark data analysis workflows and demonstrates how the guidelines presented in this book were derived. The main sections of the chapters in this part are intended for advanced users with R programming skills. However, the conclusions in each chapter are more accessible and also intended for entry-level users that want to understand how to apply the guidelines and recommendations to their analyses.\n\nChapter 3  Benchmarking workflows explains how to conduct a benchmarking experiment that compares different workflows. As an example, the chapter compares the performance when starting from the different MaxQuant input files: the evidence file, the peptides file, and the protein-group file. The same benchmark strategy could be used to compare different data sources, such as data generated by different sample preparation protocols, LC-MS approaches and/or search engines.\n4  Optimisation of a data analysis workflow demonstrates how to optimise a data analysis workflow. As an example, the chapter compares the performance of two normalisation approaches (median of ratios and median centering) in combination with three summarisation approaches (median, median polish, and robust regression).\n\n\n\nUse cases\nThis part contains a set of chapter that illustrate the data analysis for a range of experimental designs and technological setups.\n\n5  The francisella use case: a MaxQuant LFQ DDA dataset with technical replication analyses the francisella use case: a MaxQuant LFQ DDA dataset with technical replication.\n6  Heart use case: a MaxQuant LFQ DDA dataset with a more complex design analyses the heart use case: a MaxQuant LFQ DDA dataset with a more complex design.\n7  The mouse diet use case: a Skyline TMT DDA dataset analyses the mouse diet use case: a Skyline TMT DDA dataset.\n\nTODO make table with dataset descriptions to let users easily find their relevant use case.",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "index.html#targeted-audience-and-assumed-background",
    "href": "index.html#targeted-audience-and-assumed-background",
    "title": "Statistical analysis of mass spectrometry-based proteomics data",
    "section": "Targeted audience and assumed background",
    "text": "Targeted audience and assumed background\nThe course material is targeted to either proteomics practitioners or data analysts/bioinformaticians that would like to learn how to analyse proteomics data.\nA working knowledge of R (R syntax, commonly used functions, basic data structures such as data frames, vectors, matrices, … and their manipulation) is required. Familiarity with MS or proteomics in general is recommended, this would allow for a better understanding of the modelling assumptions taken throughout this book. Familiarity with other Bioconductor omics data classes and the tidyverse syntax is useful.\nWe highly recommend reading the quantitative proteomics chapter of the R for mass spectrometry book.",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "index.html#setup",
    "href": "index.html#setup",
    "title": "Statistical analysis of mass spectrometry-based proteomics data",
    "section": "Setup",
    "text": "Setup\nTo install all the necessary package, please use the latest release of R and execute:\n\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(c(\n   \"BiocParallel\",\n   \"BiocFileCache\",\n   \"ComplexHeatmap\",\n   \"dplyr\",\n   \"ExploreModelMatrix\",\n   \"ggpattern\",\n   \"ggplot2\",\n   \"ggrepel\",\n   \"impute\",\n   \"MsDataHub\",\n   \"patchwork\",\n   \"scater\",\n   \"tidyr\",\n   \"bookdown\"\n))\n\nAll software versions used to generate this document are recorded at the end of the book in 8  Additional information.",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "Statistical analysis of mass spectrometry-based proteomics data",
    "section": "Citation",
    "text": "Citation\nIf you need to cite this book, please use the following reference:\nTODO add citation when available on Zenodo (and paper)",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Statistical analysis of mass spectrometry-based proteomics data",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nWe thank the R for Mass Spectrometry initiative:\n\nFor developing the QFeatures package on which msqrob2 depends\nFor openly sharing their book, which we used as a template.",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Statistical analysis of mass spectrometry-based proteomics data",
    "section": "License",
    "text": "License\nThis material is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. You are free to share (copy and redistribute the material in any medium or format) and adapt (remix, transform, and build upon the material) for any purpose, even commercially, as long as you give appropriate credit and distribute your contributions under the same license as the original.\n\n\n\n\nGoeminne, Ludger J E, Kris Gevaert, and Lieven Clement. 2016. “Peptide-Level Robust Ridge Regression Improves Estimation, Sensitivity, and Specificity in Data-Dependent Quantitative Label-Free Shotgun Proteomics.” Mol. Cell. Proteomics 15 (2): 657–68.\n\n\nSticker, Adriaan, Ludger Goeminne, Lennart Martens, and Lieven Clement. 2020. “Robust Summarization and Inference in Proteome-Wide Label-Free Quantification.” Mol. Cell. Proteomics 19 (7): 1209–19.\n\n\nVandenbulcke, Stijn, Christophe Vanderaa, Oliver Crook, Lennart Martens, and Lieven Clement. 2025. “Msqrob2TMT: Robust Linear Mixed Models for Inferring Differential Abundant Proteins in Labeled Experiments with Arbitrarily Complex Design.” Mol. Cell. Proteomics 24 (7): 101002.",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "01-basics.html",
    "href": "01-basics.html",
    "title": "1  Statistical analysis with msqrob2",
    "section": "",
    "text": "1.1 Background\nThis chapter explains the main concepts for statistical analysis of proteomics data using msqrob2. To illustrate these concepts, we will use using a publicly available spike-in study with PRIDE identifier PXD003881 (Shen et al. 2018). This dataset contains ground truth information about which proteins are differentially abundant, enabling us to objectively demonstrate the key aspects of differential proteomics data analysis and their implementation in msqrob2. This dataset has a relatively simple experimental design (which does not imply that the analysis is easy), allowing us to assess differential abundance using a data analysis workflow with a single factor for the spike-in condition. For more advanced analyses with a more complex experimental design, we refer to our advanced concepts chapter and to the case studies.\nMass spectrometry (MS)-based proteomics aims at characterising the proteome abundance of biological samples. A popular approach is label-free quantification (LFQ), where every sample is analysed in a separate MS run. This section provides an overview of the analytical workflow and its main challenges regarding data modelling.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "01-basics.html#background",
    "href": "01-basics.html#background",
    "title": "1  Statistical analysis with msqrob2",
    "section": "",
    "text": "1.1.1 LFQ workflow\nIn a nutshell, the wetlab workflow starts with sample preparation where the samples are collected, and the protein content is extracted and digested into peptides. To reduce the sample complexity, the peptides are then separated based on physicochemical properties (mostly hydrophobicity) using liquid chromatography (LC). Peptides are then ionised by an electrospray as they elute from the chromatographic column. The signal over time generated by the eluting ions is called the total ion chromatogram. The ions are then sent for a first round of MS to record their m/z distribution for the intact ions. This provides an overview of the ions that elute from the column and allows for further separation of the ions in the m/z space. The second round of MS (MS2) records the fragmented ions for a selection of ions, generally the most intense MS1 peaks1. This process is repeated for every sample so that every sample is acquired in one MS run. This provides the ion’s mass fingerprint. For LFQ workflows, the accumulated MS1 intensity over time, also known as the area under the curve, around the target mass is used as a quantification measure. On the other hand, the ion mass fingerprint, called the MS2 spectrum, enables computational identification of the corresponding peptide using search engines (e.g. Andromeda has been used for this data set) that will provide peptide-to-spectrum matches (PSM). The quantified PSM are further processed by the software (MaxQuant) to obtain a peptide table2, where every row corresponds to an identified peptide and every column contains information about the peptide and its quantification in one of the samples.\n\n\n\n\n\nOverview of an LFQ-based proteomics workflow.\n\n\n\n\n\n\n1.1.2 Challenges\nBehind this workflow lies several challenges that will affect the data modelling:\n\nMS-based proteomics does not measure proteins directly, but their constituting peptide ions. The protein-level information needs to be reconstructed from the ion data. In this tutorial, we will start from the peptide data, which has been constructed from the ion data by MaxQuant.\nAll peptides do not ionise with the same efficiency. Poor ionisation will lead to reduced signal as less ions will hit the detector, hence leading to a huge variability in intensity among different peptide species, even when they originate from the same protein.\nThe identification step is not trivial and prone to errors3. PSM misidentification leads to the assignment of a quantitative values from another peptide with likely another ionisation efficiency and relative abundance. Hence this misassigned values often lead to outliers.\nMoreover, the ion selection for MS2 depends on its intensity4. Therefore, the chance to measure and, subsequently, identify a peptide will depend on its abundance. Non identified peptides will lead to data missingness, which is related to the underlying quantification value. This phenomenon is known as missingness not at random. Next to that, many reasons can lead to ions not being selected or identified irrespective of their quantification value leading to missingness that is not related to its quantitative value. This is referred to as missingness completely at random. The missingness issue is not negligible as we shall see upon reading the data.\nThe identification issues lead to unbalanced peptide missingness across samples, and the patterns of missing values are potentially different for every peptide, highlighting the need for an automatised solution that is robust against missing values.\nTechnical variations during the experiment can lead to systematic fluctuations across samples. The most obvious reason is when different sample amounts are injected into the instruments, due to small pipetting inconsistencies for instance. However, these differences lead to unwanted variation that should be discarded when answering biological questions.\n\n\n\n1.1.3 Experimental context\nThe samples were synthetically constructed, starting from a trypsin-digested human background, hence human proteins are known to be constant across samples. E. coli lysates were spiked at five different concentrations (3%, 4.5%, 6%, 7.5% and 9% wt/wt). So the E. coli proteins are known to be differentially abundant, and we know exactly in what amount they differ. There are four replicates per spike-in condition. The samples were run on an Orbitrap Fusion mass spectrometer. Raw data files were processed with MaxQuant (version 1.6.1.0) using default search settings unless otherwise noted. Spectra were searched against the UniProtKB/SwissProt human and E. coli reference proteome databases (07/06/2018), concatenated with the default Maxquant contaminant database. Carbamidomethylation of Cystein was set as a fixed modification, and oxidation of Methionine and acetylation of the protein amino-terminus were allowed as variable modifications. In silico cleavage was set to use trypsin/P, allowing two miscleavages. Match between runs was also enabled using default settings. The resulting peptide-to-spectrum matches (PSMs) were filtered by MaxQuant at 1% FDR.\nWe will start from the peptide data generated by MaxQuant and infer protein-level differences between samples. To achieve this goal, we will apply an msqrob2 workflow, a data processing and modelling workflow dedicated to the analysis of MS-based proteomics datasets. We will demonstrate how the workflow can retrieve the spiked-in proteins from the E. coli data set, while introducing the key statistical concepts of differential proteomics data analysis. Before delving into the analysis, we first set the concentrations for the different spike-ins, and will prepare our computational environment.\n\nconcentrations &lt;- (2:6) * 1.5\nnames(concentrations) &lt;- letters[1:5]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "01-basics.html#software",
    "href": "01-basics.html#software",
    "title": "1  Statistical analysis with msqrob2",
    "section": "1.2 Software",
    "text": "1.2 Software\n\n1.2.1 Load packages\nWe load the msqrob2 package, along with additional packages for data manipulation and visualisation.\n\nlibrary(\"msqrob2\")\nlibrary(\"dplyr\")\nlibrary(\"ggplot2\")\nlibrary(\"patchwork\")\n\n\n\n1.2.2 Parallelisation\nmsqrob2 can parallelise computations during the model estimation to improve speed. However, we will disable parallelisation to ensure this vignette can be run regardless of hardware. Parallelisation is controlled using the BiocParallel package.\n\nlibrary(\"BiocParallel\")\nregister(SerialParam())\n\nIf you want to use msqrob2 with parallelisation enabled and using 4 cores, you can run the following:\n\nregister(MulticoreParam(workers = 4))\n\nBe mindful that, while parallelisation can improve speed, it will also consume more RAM because part of the data will be copied multiple times over your different workers. If you experience crashes because you exceeded the amount of available RAM on your machine, you should reduce the number of requested workers.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "01-basics.html#sec-ecoli_data",
    "href": "01-basics.html#sec-ecoli_data",
    "title": "1  Statistical analysis with msqrob2",
    "section": "1.3 Data",
    "text": "1.3 Data\nThe data were reanalysed by Sticker et al. (2020) using MaxQuant and deposited on GitHub. We here retrieve MaxQuant’s peptides.txt for the E. coli study.\n\nlibrary(\"BiocFileCache\")\nbfc &lt;- BiocFileCache()\n# myurl &lt;- \"https://github.com/statOmics/MSqRobSumPaper/raw/refs/heads/master/spikein/data/maxquant/peptides.zip\"\n# download.file(myurl,\"data/sticker2020/peptides.zip\", method = \"curl\", extra = \"-L\")\n# unzip(\"data/sticker2020/peptides.zip\", exdir = \"data/sticker2020/\")\npeptideFile &lt;- \"data/sticker2020/peptides.txt\"\n\nTODO: put data on Zenodo. BiocFileCache will be used for fetching these data.\n\nPeptide table\nEach row in the peptide data table contains information about one peptide (the table below shows the first 6 rows). The columns contains various descriptors about the peptide, such as its sequence, its charge, the amino acid composition, etc. Some of these columns (those starting with Intensity.) contain the quantification values for each sample. The table format where the quantitative values for each sample are contained in a separate column is depicted as the “wide format”, as opposed to the “long format” (eg, the [PSM table]).\n\npeptides &lt;- read.delim(peptideFile)\nquantCols &lt;- grep(\"Intensity[.]\", names(peptides), value = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequence\nN.term.cleavage.window\nC.term.cleavage.window\nAmino.acid.before\nFirst.amino.acid\nSecond.amino.acid\nSecond.last.amino.acid\nLast.amino.acid\nAmino.acid.after\nA.Count\nR.Count\nN.Count\nD.Count\nC.Count\nQ.Count\nE.Count\nG.Count\nH.Count\nI.Count\nL.Count\nK.Count\nM.Count\nF.Count\nP.Count\nS.Count\nT.Count\nW.Count\nY.Count\nV.Count\nU.Count\nO.Count\nLength\nMissed.cleavages\nMass\nProteins\nLeading.razor.protein\nStart.position\nEnd.position\nGene.names\nProtein.names\nUnique..Groups.\nUnique..Proteins.\nCharges\nPEP\nScore\nIdentification.type.a1\nIdentification.type.a2\nIdentification.type.a3\nIdentification.type.a4\nIdentification.type.b1\nIdentification.type.b2\nIdentification.type.b3\nIdentification.type.b4\nIdentification.type.c1\nIdentification.type.c2\nIdentification.type.c3\nIdentification.type.c4\nIdentification.type.d1\nIdentification.type.d2\nIdentification.type.d3\nIdentification.type.d4\nIdentification.type.e1\nIdentification.type.e2\nIdentification.type.e3\nIdentification.type.e4\nExperiment.a1\nExperiment.a2\nExperiment.a3\nExperiment.a4\nExperiment.b1\nExperiment.b2\nExperiment.b3\nExperiment.b4\nExperiment.c1\nExperiment.c2\nExperiment.c3\nExperiment.c4\nExperiment.d1\nExperiment.d2\nExperiment.d3\nExperiment.d4\nExperiment.e1\nExperiment.e2\nExperiment.e3\nExperiment.e4\nIntensity\nIntensity.a1\nIntensity.a2\nIntensity.a3\nIntensity.a4\nIntensity.b1\nIntensity.b2\nIntensity.b3\nIntensity.b4\nIntensity.c1\nIntensity.c2\nIntensity.c3\nIntensity.c4\nIntensity.d1\nIntensity.d2\nIntensity.d3\nIntensity.d4\nIntensity.e1\nIntensity.e2\nIntensity.e3\nIntensity.e4\nReverse\nPotential.contaminant\nid\nProtein.group.IDs\nMod..peptide.IDs\nEvidence.IDs\nMS.MS.IDs\nBest.MS.MS\nOxidation..M..site.IDs\nMS.MS.Count\nLFQ.intensity.a1\nLFQ.intensity.a2\nLFQ.intensity.a3\nLFQ.intensity.a4\nLFQ.intensity.b1\nLFQ.intensity.b2\nLFQ.intensity.b3\nLFQ.intensity.b4\nLFQ.intensity.c1\nLFQ.intensity.c2\nLFQ.intensity.c3\nLFQ.intensity.c4\nLFQ.intensity.d1\nLFQ.intensity.d2\nLFQ.intensity.d3\nLFQ.intensity.d4\nLFQ.intensity.e1\nLFQ.intensity.e2\nLFQ.intensity.e3\nLFQ.intensity.e4\n\n\n\n\nAAAAAAAAAAAAAAAGAGAGAK\nQSRFQVDLVSENAGRAAAAAAAAAAAAAAA\nAAAAAAAAGAGAGAKQTPADGEASGESEPA\nR\nA\nA\nA\nK\nQ\n18\n0\n0\n0\n0\n0\n0\n3\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n22\n0\n1595.8380\nP55011\nP55011\n93\n114\nSLC12A2\nSolute carrier family 12 member 2\nyes\nyes\n2;3\n0.00e+00\n98.407\nBy matching\n\n\n\n\n\n\nBy MS/MS\nBy MS/MS\nBy MS/MS\n\nBy MS/MS\n\nBy matching\nBy matching\n\n\n\nBy matching\n\n1\nNA\nNA\nNA\nNA\nNA\nNA\n1\n1\n1\nNA\n1\nNA\n1\n1\nNA\nNA\nNA\n1\nNA\n39754000\n6378300\n0\n0\n0\n0\n0\n0\n0\n4268500\n7099400\n0\n0\n0\n8563700\n6597000\n0\n0\n0\n6846700\n0\n\n\n0\n2115\n0\n0;1;2;3;4;5;6;7\n0;1;2;3\n2\n\n2\n5715600\n0\n0\n0\n0\n0\n0\n0\n4324900\n8047900\n0\n0\n0\n9420400\n5673000\n0\n0\n0\n5761500\n0\n\n\nAAAAAAAAAAGAAGGR\n______________________________\nAAAAAAAAAGAAGGRGSGPGRRRHLVPGAG\nM\nA\nA\nG\nR\nG\n12\n1\n0\n0\n0\n0\n0\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n16\n0\n1197.6214\nQ86U42\nQ86U42\n2\n17\nPABPN1\nPolyadenylate-binding protein 2\nyes\nyes\n2\n0.00e+00\n275.000\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy matching\nBy MS/MS\nBy MS/MS\nBy MS/MS\n\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy matching\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\n\nBy MS/MS\nBy MS/MS\n1\n1\n1\n1\n1\n1\n1\n1\nNA\n1\n1\n1\n1\n1\n1\n1\n1\nNA\n1\n1\n1211200000\n76718000\n53670000\n86511000\n79070000\n57211000\n56593000\n81544000\n79032000\n0\n46087000\n62303000\n73292000\n60707000\n50560000\n75644000\n75246000\n52106000\n0\n74366000\n70540000\n\n\n1\n3262\n1\n8;9;10;11;12;13;14;15;16;17;18;19;20;21;22;23;24;25\n4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19\n9\n\n15\n68748000\n59998000\n74863000\n70216000\n57211000\n63173000\n69374000\n69165000\n0\n52244000\n66990000\n62028000\n62554000\n55618000\n65050000\n63171000\n55715000\n0\n62578000\n58656000\n\n\nAAAAAAALQAK\nTILRQARNHKLRVDKAAAAAAALQAKSDEK\nRVDKAAAAAAALQAKSDEKAAVAGKKPVVG\nK\nA\nA\nA\nK\nS\n8\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n11\n0\n955.5451\nP36578\nP36578\n354\n364\nRPL4\n60S ribosomal protein L4\nyes\nyes\n2\n1.00e-07\n182.680\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\n2\n3\n4\n2\n3\n2\n2\n2\n3\n3\n3\n2\n3\n2\n3\n2\n2\n3\n3\n2\n1829100000\n129520000\n56753000\n114890000\n126100000\n33394000\n66695000\n93968000\n125070000\n84220000\n83186000\n102980000\n108620000\n72544000\n76384000\n100270000\n118790000\n67553000\n52009000\n115880000\n100300000\n\n\n2\n1762\n2\n26;27;28;29;30;31;32;33;34;35;36;37;38;39;40;41;42;43;44;45;46;47;48;49;50;51;52;53;54;55;56;57;58;59;60;61;62;63;64;65;66;67;68;69;70;71;72;73;74;75;76\n20;21;22;23;24;25;26;27;28;29;30;31;32;33;34;35;36;37;38;39;40;41;42;43;44;45;46;47;48;49;50;51;52;53;54;55;56;57\n29\n\n30\n116060000\n63444000\n99420000\n111980000\n33394000\n74449000\n79944000\n109450000\n85332000\n94299000\n110730000\n91926000\n74751000\n84026000\n86223000\n99722000\n72233000\n56151000\n97516000\n83401000\n\n\nAAAAAAGAASGLPGPVAQGLK\n______________________________\nGAASGLPGPVAQGLKEALVDTLTGILSPVQ\nM\nA\nA\nL\nK\nE\n9\n0\n0\n0\n0\n1\n0\n4\n0\n0\n2\n1\n0\n0\n2\n1\n0\n0\n0\n1\n0\n0\n21\n0\n1747.9581\nQ96P70\nQ96P70\n2\n22\nIPO9\nImportin-9\nyes\nyes\n2;3\n0.00e+00\n202.440\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n1789100000\n109030000\n72676000\n101320000\n97545000\n77269000\n79290000\n110840000\n110060000\n75937000\n74675000\n68192000\n102570000\n93726000\n72743000\n108550000\n98519000\n70725000\n80125000\n93910000\n91423000\n\n\n3\n3783\n3\n77;78;79;80;81;82;83;84;85;86;87;88;89;90;91;92;93;94;95;96;97;98;99;100;101;102;103;104;105;106;107;108;109;110;111;112;113;114;115;116\n58;59;60;61;62;63;64;65;66;67;68;69;70;71;72;73;74;75;76;77;78;79;80;81;82;83;84;85;86;87;88;89;90;91;92;93;94;95;96;97;98;99;100;101;102;103;104;105;106;107\n85\n\n50\n97706000\n81244000\n87682000\n86622000\n77269000\n88508000\n94294000\n96324000\n76939000\n84650000\n73322000\n86806000\n96578000\n80020000\n93344000\n82709000\n75624000\n86506000\n79024000\n76020000\n\n\nAAAAAAGAGPEMVR\n______________________________\nMAAAAAAGAGPEMVRGQVFDVGPRYTNLSY\nM\nA\nA\nV\nR\nG\n7\n1\n0\n0\n0\n0\n1\n2\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n0\n1\n0\n0\n14\n0\n1241.6187\nP28482\nP28482\n2\n15\nMAPK1\nMitogen-activated protein kinase 1\nyes\nyes\n2\n0.00e+00\n168.740\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\n\nBy MS/MS\nBy MS/MS\nBy MS/MS\n\nBy MS/MS\nBy MS/MS\nBy MS/MS\n\n\n\n\n\n\n\n\n1\n1\n1\n1\nNA\n1\n1\n1\nNA\n2\n1\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n72178000\n0\n29646000\n41064000\n0\n0\n0\n0\n0\n0\n1468400\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n1600\n4\n117;118;119;120;121;122;123;124;125;126;127\n108;109;110;111;112;113;114;115;116;117\n109\n\n10\n0\n33141000\n35535000\n0\n0\n0\n0\n0\n0\n1664500\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nAAAAAAGSGTPREEEGPAGEAAASQPQAPTSVPGAR\n______________________________\nAASQPQAPTSVPGARLSRLPLARVKALVKA\nM\nA\nA\nA\nR\nL\n12\n2\n0\n0\n0\n2\n4\n5\n0\n0\n0\n0\n0\n0\n5\n3\n2\n0\n0\n1\n0\n0\n36\n1\n3287.5767\nQ9NR33\nQ9NR33\n2\n37\nPOLE4\nDNA polymerase epsilon subunit 4\nyes\nyes\n3\n3.34e-05\n40.328\n\n\n\n\n\n\n\n\n\n\n\nBy MS/MS\n\n\n\n\n\n\n\n\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n6961000\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n6961000\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n5\n4289\n5\n128\n118\n118\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n5891200\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\n\n\nSample annotation table\nEach row in the annotation table contains information about one sample. The columns contain various descriptors about the sample, such as the name of the sample or the MS run, the treatment (here the spike-in condition), or any other biological or technical information that may impact the data quality or the quantification. Without an annotation table, no analysis can be performed. The sample annotations are generated by the researcher. In this example, the annotations are extracted from the sample names, although reporting a detailed design of experiments in a table is seen as better practice (Gatto et al. 2023).\n\ncoldata &lt;- data.frame(quantCols = quantCols)\ncoldata$condition &lt;- gsub(\"Intensity.(.).\", \"\\\\1\", quantCols)\ncoldata$concentration &lt;- concentrations[coldata$condition]\n\n\n\n\n\n\nquantCols\ncondition\nconcentration\n\n\n\n\nIntensity.a1\na\n3.0\n\n\nIntensity.a2\na\n3.0\n\n\nIntensity.a3\na\n3.0\n\n\nIntensity.a4\na\n3.0\n\n\nIntensity.b1\nb\n4.5\n\n\nIntensity.b2\nb\n4.5\n\n\n\n\n\nWe will also extract the E. coli protein identifiers from the FASTA file to later annotate the spike-in proteins which are known to be differentially abundant.\n\nWe download the fasta files\nWe read the text file as vector, one line p\nWe keep only the protein headers\nWe extract the proteins identifiers from the headers\n\n\necoli &lt;- bfcrpath(bfc, \"https://raw.githubusercontent.com/statOmics/MSqRobSumPaper/refs/heads/master/spikein/data/fasta/ecoli_up000000625_7_06_2018.fasta\")\necoli &lt;- readLines(ecoli)\necoli &lt;- ecoli[grepl(\"^&gt;\", ecoli)]\necoli &lt;- gsub(\"&gt;sp\\\\|(.*)\\\\|.*\", \"\\\\1\", ecoli)\n\n\n\n1.3.1 Convert to QFeatures\nmsqrob2 is built around the QFeatures class. We refer to the R for mass spectrometry book for a comprehensive description of the class. In a nutshell, the QFeatures package provides infrastructure to manage and analyse quantitative features from mass spectrometry experiments. It is based on the SummarizedExperiment and MultiAssayExperiment classes. It leverages the hierarchical structure of proteomics experiments: data proteins are composed of peptides, themselves produced by spectra. Each piece of information in stored in an individual SummarizedExperiment object, later referred to as a “set”. Throughout the aggregation and processing of these data, the relations between sets are tracked and recorded, thus allowing users to easily navigate across spectra, peptide and protein quantitative data.\n\n\n\n\n\nIllustration of the QFeatures data class.\n\n\n\n\nThe readQFeatures() enables a seamless conversion of tabular data into a QFeatures object. We provide the peptide table and the sample annotation table. The function will use the quantCols column in the sample annotation table to understand which columns in peptides contain the quantitative values, and automatically link the corresponding sample annotation with the quantitative values. We also tell the function to use the Sequence column as peptide identifier, which will be used as rownames. See ?readQFeatures() for more details.\n\n(spikein &lt;- readQFeatures(\n  peptides, coldata, name = \"peptides\", fnames = \"Sequence\"\n))\n\nAn instance of class QFeatures (type: bulk) with 1 set:\n\n [1] peptides: SummarizedExperiment with 32827 rows and 20 columns \n\n\nWe now have a QFeatures object with 1 set, called peptides (which we specified using the name argument). In this toy example, we have information for 32827 peptides across 45 samples, as expected (recall the experimental design).\nThe sample annotations can be retrieved using colData().\n\ncolData(spikein)\n\n\nknitr::kable(head(colData(spikein)))\n\n\n\n\n\nquantCols\ncondition\nconcentration\n\n\n\n\nIntensity.a1\nIntensity.a1\na\n3.0\n\n\nIntensity.a2\nIntensity.a2\na\n3.0\n\n\nIntensity.a3\nIntensity.a3\na\n3.0\n\n\nIntensity.a4\nIntensity.a4\na\n3.0\n\n\nIntensity.b1\nIntensity.b1\nb\n4.5\n\n\nIntensity.b2\nIntensity.b2\nb\n4.5\n\n\n\n\n\nWe can get a sample annotation directly using the $ accessor.\n\nhead(spikein$concentration)\n\n[1] 3.0 3.0 3.0 3.0 4.5 4.5\n\n\nWe can extract the SummarizedExperiment object for the peptides set using double bracket subsetting5\n\nspikein[[\"peptides\"]]\n\nclass: SummarizedExperiment \ndim: 32827 20 \nmetadata(0):\nassays(1): ''\nrownames(32827): AAAAAAAAAAAAAAAGAGAGAK AAAAAAAAAAGAAGGR ...\n  YYVTIIDAPGHRDFIK YYYIPQYK\nrowData names(116): Sequence N.term.cleavage.window ...\n  LFQ.intensity.e3 LFQ.intensity.e4\ncolnames(20): Intensity.a1 Intensity.a2 ... Intensity.e3 Intensity.e4\ncolData names(0):\n\n\nBut notice that the sample annotations were not extracted along with the SummarizedExperiment (colData names(0):). This can be performed using getWithColData(), which extracts the set of interest (like [[]]) along with all the associated sample annotations.\n\ngetWithColData(spikein, \"peptides\")\n\nclass: SummarizedExperiment \ndim: 32827 20 \nmetadata(0):\nassays(1): ''\nrownames(32827): AAAAAAAAAAAAAAAGAGAGAK AAAAAAAAAAGAAGGR ...\n  YYVTIIDAPGHRDFIK YYYIPQYK\nrowData names(116): Sequence N.term.cleavage.window ...\n  LFQ.intensity.e3 LFQ.intensity.e4\ncolnames(20): Intensity.a1 Intensity.a2 ... Intensity.e3 Intensity.e4\ncolData names(3): quantCols condition concentration\n\n\nThe peptides annotations are available for in the corresponding rowData.\n\nrowData(spikein[[\"peptides\"]])\n\n\nknitr::kable(head(rowData(spikein[[\"peptides\"]])))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequence\nN.term.cleavage.window\nC.term.cleavage.window\nAmino.acid.before\nFirst.amino.acid\nSecond.amino.acid\nSecond.last.amino.acid\nLast.amino.acid\nAmino.acid.after\nA.Count\nR.Count\nN.Count\nD.Count\nC.Count\nQ.Count\nE.Count\nG.Count\nH.Count\nI.Count\nL.Count\nK.Count\nM.Count\nF.Count\nP.Count\nS.Count\nT.Count\nW.Count\nY.Count\nV.Count\nU.Count\nO.Count\nLength\nMissed.cleavages\nMass\nProteins\nLeading.razor.protein\nStart.position\nEnd.position\nGene.names\nProtein.names\nUnique..Groups.\nUnique..Proteins.\nCharges\nPEP\nScore\nIdentification.type.a1\nIdentification.type.a2\nIdentification.type.a3\nIdentification.type.a4\nIdentification.type.b1\nIdentification.type.b2\nIdentification.type.b3\nIdentification.type.b4\nIdentification.type.c1\nIdentification.type.c2\nIdentification.type.c3\nIdentification.type.c4\nIdentification.type.d1\nIdentification.type.d2\nIdentification.type.d3\nIdentification.type.d4\nIdentification.type.e1\nIdentification.type.e2\nIdentification.type.e3\nIdentification.type.e4\nExperiment.a1\nExperiment.a2\nExperiment.a3\nExperiment.a4\nExperiment.b1\nExperiment.b2\nExperiment.b3\nExperiment.b4\nExperiment.c1\nExperiment.c2\nExperiment.c3\nExperiment.c4\nExperiment.d1\nExperiment.d2\nExperiment.d3\nExperiment.d4\nExperiment.e1\nExperiment.e2\nExperiment.e3\nExperiment.e4\nIntensity\nReverse\nPotential.contaminant\nid\nProtein.group.IDs\nMod..peptide.IDs\nEvidence.IDs\nMS.MS.IDs\nBest.MS.MS\nOxidation..M..site.IDs\nMS.MS.Count\nLFQ.intensity.a1\nLFQ.intensity.a2\nLFQ.intensity.a3\nLFQ.intensity.a4\nLFQ.intensity.b1\nLFQ.intensity.b2\nLFQ.intensity.b3\nLFQ.intensity.b4\nLFQ.intensity.c1\nLFQ.intensity.c2\nLFQ.intensity.c3\nLFQ.intensity.c4\nLFQ.intensity.d1\nLFQ.intensity.d2\nLFQ.intensity.d3\nLFQ.intensity.d4\nLFQ.intensity.e1\nLFQ.intensity.e2\nLFQ.intensity.e3\nLFQ.intensity.e4\n\n\n\n\nAAAAAAAAAAAAAAAGAGAGAK\nAAAAAAAAAAAAAAAGAGAGAK\nQSRFQVDLVSENAGRAAAAAAAAAAAAAAA\nAAAAAAAAGAGAGAKQTPADGEASGESEPA\nR\nA\nA\nA\nK\nQ\n18\n0\n0\n0\n0\n0\n0\n3\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n22\n0\n1595.8380\nP55011\nP55011\n93\n114\nSLC12A2\nSolute carrier family 12 member 2\nyes\nyes\n2;3\n0.00e+00\n98.407\nBy matching\n\n\n\n\n\n\nBy MS/MS\nBy MS/MS\nBy MS/MS\n\nBy MS/MS\n\nBy matching\nBy matching\n\n\n\nBy matching\n\n1\nNA\nNA\nNA\nNA\nNA\nNA\n1\n1\n1\nNA\n1\nNA\n1\n1\nNA\nNA\nNA\n1\nNA\n39754000\n\n\n0\n2115\n0\n0;1;2;3;4;5;6;7\n0;1;2;3\n2\n\n2\n5715600\n0\n0\n0\n0\n0\n0\n0\n4324900\n8047900\n0\n0\n0\n9420400\n5673000\n0\n0\n0\n5761500\n0\n\n\nAAAAAAAAAAGAAGGR\nAAAAAAAAAAGAAGGR\n______________________________\nAAAAAAAAAGAAGGRGSGPGRRRHLVPGAG\nM\nA\nA\nG\nR\nG\n12\n1\n0\n0\n0\n0\n0\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n16\n0\n1197.6214\nQ86U42\nQ86U42\n2\n17\nPABPN1\nPolyadenylate-binding protein 2\nyes\nyes\n2\n0.00e+00\n275.000\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy matching\nBy MS/MS\nBy MS/MS\nBy MS/MS\n\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy matching\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\n\nBy MS/MS\nBy MS/MS\n1\n1\n1\n1\n1\n1\n1\n1\nNA\n1\n1\n1\n1\n1\n1\n1\n1\nNA\n1\n1\n1211200000\n\n\n1\n3262\n1\n8;9;10;11;12;13;14;15;16;17;18;19;20;21;22;23;24;25\n4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19\n9\n\n15\n68748000\n59998000\n74863000\n70216000\n57211000\n63173000\n69374000\n69165000\n0\n52244000\n66990000\n62028000\n62554000\n55618000\n65050000\n63171000\n55715000\n0\n62578000\n58656000\n\n\nAAAAAAALQAK\nAAAAAAALQAK\nTILRQARNHKLRVDKAAAAAAALQAKSDEK\nRVDKAAAAAAALQAKSDEKAAVAGKKPVVG\nK\nA\nA\nA\nK\nS\n8\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n11\n0\n955.5451\nP36578\nP36578\n354\n364\nRPL4\n60S ribosomal protein L4\nyes\nyes\n2\n1.00e-07\n182.680\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\n2\n3\n4\n2\n3\n2\n2\n2\n3\n3\n3\n2\n3\n2\n3\n2\n2\n3\n3\n2\n1829100000\n\n\n2\n1762\n2\n26;27;28;29;30;31;32;33;34;35;36;37;38;39;40;41;42;43;44;45;46;47;48;49;50;51;52;53;54;55;56;57;58;59;60;61;62;63;64;65;66;67;68;69;70;71;72;73;74;75;76\n20;21;22;23;24;25;26;27;28;29;30;31;32;33;34;35;36;37;38;39;40;41;42;43;44;45;46;47;48;49;50;51;52;53;54;55;56;57\n29\n\n30\n116060000\n63444000\n99420000\n111980000\n33394000\n74449000\n79944000\n109450000\n85332000\n94299000\n110730000\n91926000\n74751000\n84026000\n86223000\n99722000\n72233000\n56151000\n97516000\n83401000\n\n\nAAAAAAGAASGLPGPVAQGLK\nAAAAAAGAASGLPGPVAQGLK\n______________________________\nGAASGLPGPVAQGLKEALVDTLTGILSPVQ\nM\nA\nA\nL\nK\nE\n9\n0\n0\n0\n0\n1\n0\n4\n0\n0\n2\n1\n0\n0\n2\n1\n0\n0\n0\n1\n0\n0\n21\n0\n1747.9581\nQ96P70\nQ96P70\n2\n22\nIPO9\nImportin-9\nyes\nyes\n2;3\n0.00e+00\n202.440\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n1789100000\n\n\n3\n3783\n3\n77;78;79;80;81;82;83;84;85;86;87;88;89;90;91;92;93;94;95;96;97;98;99;100;101;102;103;104;105;106;107;108;109;110;111;112;113;114;115;116\n58;59;60;61;62;63;64;65;66;67;68;69;70;71;72;73;74;75;76;77;78;79;80;81;82;83;84;85;86;87;88;89;90;91;92;93;94;95;96;97;98;99;100;101;102;103;104;105;106;107\n85\n\n50\n97706000\n81244000\n87682000\n86622000\n77269000\n88508000\n94294000\n96324000\n76939000\n84650000\n73322000\n86806000\n96578000\n80020000\n93344000\n82709000\n75624000\n86506000\n79024000\n76020000\n\n\nAAAAAAGAGPEMVR\nAAAAAAGAGPEMVR\n______________________________\nMAAAAAAGAGPEMVRGQVFDVGPRYTNLSY\nM\nA\nA\nV\nR\nG\n7\n1\n0\n0\n0\n0\n1\n2\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n0\n1\n0\n0\n14\n0\n1241.6187\nP28482\nP28482\n2\n15\nMAPK1\nMitogen-activated protein kinase 1\nyes\nyes\n2\n0.00e+00\n168.740\nBy MS/MS\nBy MS/MS\nBy MS/MS\nBy MS/MS\n\nBy MS/MS\nBy MS/MS\nBy MS/MS\n\nBy MS/MS\nBy MS/MS\nBy MS/MS\n\n\n\n\n\n\n\n\n1\n1\n1\n1\nNA\n1\n1\n1\nNA\n2\n1\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n72178000\n\n\n4\n1600\n4\n117;118;119;120;121;122;123;124;125;126;127\n108;109;110;111;112;113;114;115;116;117\n109\n\n10\n0\n33141000\n35535000\n0\n0\n0\n0\n0\n0\n1664500\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nAAAAAAGSGTPREEEGPAGEAAASQPQAPTSVPGAR\nAAAAAAGSGTPREEEGPAGEAAASQPQAPTSVPGAR\n______________________________\nAASQPQAPTSVPGARLSRLPLARVKALVKA\nM\nA\nA\nA\nR\nL\n12\n2\n0\n0\n0\n2\n4\n5\n0\n0\n0\n0\n0\n0\n5\n3\n2\n0\n0\n1\n0\n0\n36\n1\n3287.5767\nQ9NR33\nQ9NR33\n2\n37\nPOLE4\nDNA polymerase epsilon subunit 4\nyes\nyes\n3\n3.34e-05\n40.328\n\n\n\n\n\n\n\n\n\n\n\nBy MS/MS\n\n\n\n\n\n\n\n\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n6961000\n\n\n5\n4289\n5\n128\n118\n118\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n5891200\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\nWe can also retrieve the quantitative values for each set using assays(). Here we only show the first 5 rows and columns of the intensity matrix.\n\nassay(spikein[[1]])[1:5, 1:5]\n\n                       Intensity.a1 Intensity.a2 Intensity.a3 Intensity.a4\nAAAAAAAAAAAAAAAGAGAGAK      6378300            0            0            0\nAAAAAAAAAAGAAGGR           76718000     53670000     86511000     79070000\nAAAAAAALQAK               129520000     56753000    114890000    126100000\nAAAAAAGAASGLPGPVAQGLK     109030000     72676000    101320000     97545000\nAAAAAAGAGPEMVR                    0     29646000     41064000            0\n                       Intensity.b1\nAAAAAAAAAAAAAAAGAGAGAK            0\nAAAAAAAAAAGAAGGR           57211000\nAAAAAAALQAK                33394000\nAAAAAAGAASGLPGPVAQGLK      77269000\nAAAAAAGAGPEMVR                    0",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "01-basics.html#sec-basic_preprocess",
    "href": "01-basics.html#sec-basic_preprocess",
    "title": "1  Statistical analysis with msqrob2",
    "section": "1.4 Data preprocessing",
    "text": "1.4 Data preprocessing\nSince we have a QFeatures object, we can directly make use of QFeatures’ data preprocessing functionality6. A major advantage of QFeatures is it provides the power to build highly modular workflows, where each step is carried out by a dedicated function with a large choice of available methods and parameters. This means that users can adapt the workflow to their specific use case and their specific needs.\n\n1.4.1 Encoding missing values\nThe first preprocessing step is to correctly encode the missing values. It is important that missing values are encoded using NA. For instance, non-observed values should not be encoded with a zero because true zeros (the proteomic feature is absent from the sample) cannot be distinguished from technical zeros (the feature was missed by the instrument or could not be identified). We therefore replace any zero in the quantitative data with an NA.\n\nspikein &lt;- zeroIsNA(spikein, names(spikein))\n\nNote that msqrob2 can handle missing data without having to rely on hard-to-verify imputation assumptions, which is our general recommendation. However, msqrob2 does not prevent users from using imputation, which can be performed with impute() from the QFeatures package. Below, we show how one could perform KNN imputation7 (see ?impute for more options).\n\n# spikein &lt;- impute(\n#   spikein, method = \"knn\",\n#   i = names(spikein), name = paste0(names(spikein), \"_imput\")\n# )\n\n\n\n1.4.2 Log2 transformation\nWe typically start a MS-based proteomics data analysis by log2 transforming the intensities. We illustrate the rationale using the spike-in data. For this, we perform a short data manipulation pipeline:\n\nWe use longForm() to convert the QFeatures object into a long table, where each row contains the quantitative information about one observation, in which column, row and set it was found. Long tables are particularly useful for manipulating data with the tidyverse ecosystem, namely with ggplot2 for visualisation. longForm() also allows to include annotations, and we here include Mixture and TechRepMixture for filtering and colouring.\nlongForm() returns a DataFrame which we convert to a data.frame.\nWe filter the data to keep only the data from peptide AEMSEYLFDK.\n\n\ndat &lt;- longForm(spikein, colvars = colnames(colData(spikein))) |&gt; ## 1.\n  data.frame() |&gt; ## 2.\n  filter(rowname == \"AEMSEYLFDK\") ## 3.\n\nNext, we visualise the data using ggplot2. We will show the intensities and log2-intensities for one of the peptides, AALEELVK, in function of the known E. coli spike-in concentration. We first define a common plot from which we generate two plots, one without and the other with log2 transformation of the quantitative values.\n\n\n\n\n\nMS-data is heteroskedastic, but log transformation achieves homoskedasticity. Peptide intensities (left) or log2 intensities (right) are plotted in function of spike-in concentration.\n\n\n\n\nWe can see that the variation around the mean for each concentration slightly increases as the mean increases. This is known as heteroskedasticity. We will later see that msqrob2 assumes that variance of the error is equal across the different conditions. Upon, log2-transformation we can see that the problem of unequal variability is solved.\nAnother advantages of log2-transformation is that it provides a scale that directly relates to biological interpretation. In biology, a change induced by some condition often results in a fold change in concentration. Interestingly, the log2 fold change (logFC), which is the log2 of the ratio between two conditions, is identical to the difference between the log of each condition.\n\\[log_2FC_{b-a} = log_2b - log_2a = log_2 \\frac{b}{a}\\]\nThis simplifies the modelling since the effects are now additive and it provides a straightforward interpretation, i.e. a logFC of 1 means that the abundances are on average \\(2\\times\\) higher in \\(b\\) than in \\(a\\), a logFC of 2 means an average increase of \\(4\\times\\), for instance. Also, note that the averages calculated at the log2-scale have the interpretation of log2-transformed geometric means.\nWe perform log2-transformation with logTransform() from the QFeatures package.\n\nspikein &lt;- logTransform(\n  spikein, \"peptides\", name = \"peptides_log\", base = 2\n)\n\n\n\n1.4.3 Peptide filtering\nFiltering removes low-quality and unreliable peptides that would otherwise introduce noise and artefacts in the data. There are many possible criteria for peptide filtering:\n\nReverse sequences\nOnly identified by modification site (only modified peptides detected)\nRazor peptides: non-unique peptides assigned to the protein group with the most other peptides\nContaminants\nPeptides with few identifications\nProteins that are only identified with one or a few peptides\nFDR of identification\n…\n\nIt is important that the filtering criteria are not distorting the distribution of the test statistics in the downstream analysis for features that are non-DA. It can be shown that filtering will not induce bias results when the filtering criterion is independent of test statistic. Here, the test statistics are based on the average difference between the log2-transformed intensities (effect size) and their corresponding standard error, which is a function of the residual standard deviation. The criteria that we proposed above are all based on the results of the identification step, hence, they are independent of the downstream test statistics that will be used to prioritize DA proteins.\nWe use filterFeatures() to perform the filtering. It uses information from the rowData and a formula to generate a filter for each feature (row) in each set across the object. If the filter returns TRUE, the corresponding row is retained, otherwise it is removed. Defining a filter through a formula offers a flexible approach, allowing for any customised filter. This dataset requires an extensive PSM filtering, which is an ideal use case to demonstrate the customisation of a filtering workflow.\n\nRemove failed protein inference\nWe remove peptides that could not be mapped to a protein. We also remove peptides that cannot be uniquely mapped to a single proteins because its sequence is shared across multiple proteins. This often occurs for homologs or for proteins that share similar functional domains. Shared peptides are often mapped to protein groups, which are the set of proteins that share the given peptides. Protein groups are encoded by appending the constituting protein identifiers, separated by a \";\".\n\nspikein &lt;- filterFeatures(\n  spikein, ~ Proteins != \"\" & ## Remove failed protein inference\n    !grepl(\";\", Proteins)) ## Remove protein groups\n\n\n\nRemove reverse sequences and contaminants\nWe now remove the peptides that map to decoy sequences or to contaminants proteins. Decoy peptides, which consist of fake peptide sequences generated by reversing a real amino-acid sequence, are used during the database search to mitigating the number of random-hit PSM, hence mitigating misidentification. Contaminant proteins are proteins known to be artificially incorporated during the experiment, but that are irrelevant to the biological system under study. Typical contaminants are human or animal keratins (deposited by the experimenter) or trypsin (used for protein digestion). It is important to remove these peptides before performing statistical modelling, otherwise these proteins will be accounted for during the multiple test adjustment, which will cause an unnecessary decrease of statistical power. Note, that the column name of the contaminants in the peptides file differs according to the MaxQuant version. In our peptide.txt file decoys and contaminants are indicated with a “+” character in the column Reverse and Potential.contaminant, respectively.\n\nspikein &lt;- filterFeatures(spikein, ~ Reverse != \"+\" & ## Remove decoys\n                            Potential.contaminant != \"+\") ## Remove contaminants\n\n\n\nRemove highly missing peptides\nThe data are characterised by a high proportion of missing values as reported by nNA() from the QFeatures package. The function computes the number and the proportion of missing values across peptides, samples or for the whole data set and return a list of three tables called nNArows, nNAcols, and nNA, respectively.\n\nnNaRes &lt;- nNA(spikein, \"peptides\")\nrange(nNaRes$nNAcols$pNA)\n\n[1] 0.2196928 0.2649294\n\n\nThe samples contain between 22% and 26.5% missing values. The missingness within each peptide is more variable, with most peptides found accross all samples (nNA is 0) and other that could not be quantified in any sample (nNA is 20), as depicted by the histogram below.\n\ndata.frame(nNaRes$nNArows) |&gt; \n  ggplot() +\n  aes(x = nNA) +\n  geom_histogram(bins = 15) +\n  ggtitle(\"Number of missing values for each peptide\")\n\n\n\n\n\n\n\n\nTODO assigned:Lieven DO WE USE THE SAME STRATEGY AS IN EDGER? Observe in at least as many samples as in the smallest group or in the minimum of 1/leverage for more complex designs? minSampleSize &lt;- 1/max(hat(design))\nWe keep peptides that were observed at last 4 times out of the \\(n\n= 20\\) samples, so that we can estimate the peptide characteristics. We tolerate the following proportion of NAs: \\(\\text{pNA} = \\frac{(n - 4)}{n} = 0.8\\), so we keep peptides that are observed in at least 20% of the samples, which corresponds to one treatment condition. This is an arbitrary value that may need to be adjusted depending on the experiment and the data set.\n\nnObs &lt;- 4\nn &lt;- ncol(spikein[[\"peptides_log\"]])\n(spikein &lt;- filterNA(spikein, i = \"peptides_log\", pNA = (n - nObs) / n))\n\nAn instance of class QFeatures (type: bulk) with 2 sets:\n\n [1] peptides: SummarizedExperiment with 30661 rows and 20 columns \n [2] peptides_log: SummarizedExperiment with 27850 rows and 20 columns \n\n\nWe keep 27850 peptides upon filtering.\n\n\n\n1.4.4 Normalisation\nThe most common objective of MS-based proteomics experiments is to understand the biological changes in protein abundance between experimental conditions. However, changes in measurements between groups can be caused due to technical factors. For instance, there are systematic fluctuations from run-to-run that shift the measured intensity distribution. We can this explore as follows:\n\nWe extract the sets containing the log transformed data. This is performed using QFeatures’ 3-way subsetting8.\nWe use longForm() to convert the QFeatures object into a long table, including condition and concentration for filtering and colouring.\nWe visualise the density of the quantitative values within each sample. We colour each sample based on its spike-in condition.\n\n\nspikein[, , \"peptides_log\"] |&gt; ## 1.\n  longForm(colvars = c(\"concentration\", \"condition\")) |&gt; ## 2.\n  data.frame() |&gt; \n  ggplot() + ## 3.\n  aes(x = value,\n      colour = condition,\n      group = colname) +\n  geom_density()\n\n\n\n\nIntensity distribution for all samples before normalisation.\n\n\n\n\nEven in this clean synthetic data set (same background with a small percentage of E. coli lysate), the marginal peptide intensity distributions across samples are not well aligned. Ignoring this effect will increase the noise and reduce the statistical power of the experiment, and may also, in case of unbalanced designs, introduce confounding effects that will bias the results.\nTherefore, normalisation will transform the data to make the intensities of the different samples comparable, e.g. by centering the distributions using the median, so that the distributions better coincide and overlap.\nHere, we will use the Median of Ratios method of DESeq2, which was originally developed for RNA-seq data analysis and can also correct for differences in composition of the proteomes in the different samples:\n\nWe first create a pseudo-reference sample (row-wise mean of log2 intensities, which corresponds to the log2 transformed geometric mean).\nCalculate the log2 ratios of each sample w.r.t. the pseudo-reference\nSubsequently take the column wise median of these log2 ratios to obtain the sample based normalisation factor on the log2 scale.\nSubtract these log2-norm factors from the intensities of each corresponding column of the assay data and store the result in the new assay peptides_norm. (We adopt the sweep function to the peptides_log assay of the spikein QFeatures object with as statistic the log2 normfactor STATS=nf the default function FUN = \"-\", MARGIN = 2 to substract the column wise log2 norm factor from each entry of the corresponding assay data)\n\n\npseudoRef &lt;- assay(spikein[[\"peptides_log\"]]) |&gt; \n  rowMeans(na.rm = TRUE) #1. Calculate the row means \nnfLog &lt;- sweep(\n  assay(spikein[[\"peptides_log\"]]), \n  MARGIN = 1, \n  pseudoRef) |&gt; #2. Subtract the row means row-by-row (MARGIN = 1)\n  colMedians(na.rm = TRUE)  #3. Calculate the column median \nspikein &lt;- sweep( #4. Subtract log2 norm factor column-by-column (MARGIN = 2)\n  spikein,\n  MARGIN = 2,\n  STATS = nfLog,\n  i = \"peptides_log\",\n  name = \"peptides_norm\"\n)\n\nFormally, the function applies the following operation on each sample \\(i\\) across all PSMs \\(p\\):\n\\[\ny_{ip}^{\\text{norm}} = y_{ip} - \\hat{\\mu}_i\n\\]\nwith \\(y_ip\\) the log2-transformed intensities and \\(\\hat{\\mu}_i\\) the log2-transformed norm factor. Upon normalisation, we can see that the distribution of the \\(y_{ip}^{\\text{norm}}\\) nicely overlap (using the same code as above)\n\nspikein[, , \"peptides_norm\"] |&gt; ## 1.\n  longForm(colvars = c( \"concentration\", \"condition\")) |&gt; ## 2.\n  data.frame() |&gt; \n  ggplot() + ## 3.\n  aes(x = value,\n      colour = condition,\n      group = colname) +\n  geom_density()\n\n\n\n\nIntensity distribution for all samples after normalisation.\n\n\n\n\nBeware there exist numerous types of normalisation methods (see ?normalize) and which method to use may be data set dependent. For instance, some data set may show low overlap of distribution tails upon normalisation indicating that a simple shift is not sufficient. In micro-array literature, quantile normalisation is used to force the median and all other quantiles to be equal across samples, but in proteomics, quantile normalisation often introduces artifacts due to a difference in missing peptides across samples (c.f. Challenges).\nIt is important to understand that most normalisation procedures assume that the majority of the proteins do not change across conditions and only a small proportion of the proteins are differentially abundant. This assumption may not be valid in poorly designed spike-in studies (O’Brien et al. 2024) or for pull-down studies, for example. Dedicated normalisation strategies are then required.\n\n\n1.4.5 Summarisation\nThe objective of summarisation (also referred to as aggregation) is to summarise the peptide-level intensities into a protein expression value. We illustrate the motivation for summarisation using all peptide-level data for one of the E. coli proteins. We also focus on the lowest (a) and highest (e) spike-in conditions. The different peptides are shown on the x axis and plot their log2 normalised intensities across samples on y axis. All the points belonging to the same sample are linked through a grey line.\n\n\n\n\n\nPeptide-level data for E. coli protein P0AEE5. The data set has been subset for samples with condition a and e. Each point represents a measured peptide within a sample, and the points are connected when they belong to the same sample.\n\n\n\n\n\nWe can see that data for a protein can consist of many peptides, hence the need for summarisation.\nWe observe that different peptides have different intensities within the same sample (same line). This is because different peptides have different properties and hence differ in their ionisation efficiency, which will influence the detectability in the MS (Challenges).\nThe peptide identification are inconsistent between groups of interest. We can see the low-concentration group (condition a, red) display more missing values than the high-concentration group (condition e, blue). Moreover, which value is missing depends on the peptide characteristics. All the peptides found in the low-concentration group are the most intense peptides in the high concentration group.\nWe also often find outliers, for instance, due to misidentification or fluctuations during MS acquisition.\nThese data also suggest pseudo-replication. The peptide intensities in one same sample (dots connected by a line) are correlated, i.e. they more alike than the peptide intensities between samples (the lines do not perfectly align).\n\nThe fact that different peptides have different intensities (2.), may be inconsistently identified (3.) and/or quantified (4.), and show sample correlations (5.) can lead to bias if we use simple summarisation approaches such as summing or averaging the peptide intensities for each sample. Instead, we will resort to more advanced summarisation approaches to accommodate for these issues.\nHere, we summarise the peptide-level data into protein intensities through the robust summarisation approach (Sticker et al. 2020) which is a model approach that estimates for each protein \\(P\\) separately:\n\\[\ny_{ip} = \\beta_p^\\text{pep} + \\beta_i^\\text{samp} + \\epsilon_{ip}\n\\]\nwhere \\(y_{ip}\\) is the log-normalised peptide intensity for peptide \\(p\\) belonging to protein \\(P\\) in sample \\(i\\). \\(\\beta_p^\\text{pep}\\) is the average effect of peptide \\(p\\), which account for the fact that different peptide yield different baseline intensities (see issue 2. above). \\(\\beta_i^\\text{samp}\\) is the average effect of sample \\(i\\). In other words, it provides the estimated log2-transformed and normalised intensity of protein \\(P\\) in sample \\(i\\) corrected for the peptide effect, which will be used as the summarised protein value. \\(\\epsilon_{ip}\\) is the residual effect that cannot be explained by the average sample and peptide effects. The method is called robust summarisation because the estimation process will minimize \\(\\epsilon\\) using a robust estimator9 that will down-weigh extreme values, effectively tackling issue 4.\naggregateFeatures() streamlines summarisation. It requires the name of a rowData column to group the peptides into proteins (or protein groups), here Proteins. We provide the summarisation approach through the fun argument. Other summarisation methods are available from the MsCoreUtils package, see ?aggregateFeatures for a comprehensive list. The function will return a QFeatures object with a new set that we called proteins.\n\n(spikein &lt;- aggregateFeatures(\n  spikein, i = \"peptides_norm\", \n  name = \"proteins\",\n  fcol = \"Proteins\", \n  fun = MsCoreUtils::robustSummary,\n  na.rm = TRUE\n))\n\nAn instance of class QFeatures (type: bulk) with 4 sets:\n\n [1] peptides: SummarizedExperiment with 30661 rows and 20 columns \n [2] peptides_log: SummarizedExperiment with 27850 rows and 20 columns \n [3] peptides_norm: SummarizedExperiment with 27850 rows and 20 columns \n [4] proteins: SummarizedExperiment with 4592 rows and 20 columns \n\n\nNote that all the links between peptides and proteins are kept10. This come particularly handy when we want to extract all the data from one protein, P0AEE5 for instance. This can be performed using the 3-way indexing. Every QFeatures object contains one or more sets, each characterised by multiple rows (peptides or proteins) and multiple columns (samples). Therefore, QFeatures can subset data based on one or more of these indices, data[set_k, feature_i, sample_j]. The first entry will subset particular features. This can be the name of a peptide (e.g. DGQIQFVLLK) or the name of a protein (P0AEE5). The second entry selects the samples columns of interest. The third entry selects the sets of interest. If an entry is left blank, all the corresponding features, samples or sets will be selected. Let’s extract all the data (all samples and all sets) related to the E. coli protein (P0AEE5).\n\nspikein[\"P0AEE5\", , ]\n\nAn instance of class QFeatures (type: bulk) with 4 sets:\n\n [1] peptides: SummarizedExperiment with 16 rows and 20 columns \n [2] peptides_log: SummarizedExperiment with 16 rows and 20 columns \n [3] peptides_norm: SummarizedExperiment with 16 rows and 20 columns \n [4] proteins: SummarizedExperiment with 1 rows and 20 columns \n\n\nThe function extracted one protein and its 16 related peptides. This functionality is particularly useful for plotting and exploring the changes induces by the data processing. For instance:\n\nWe use the QFeatures subsetting functionality to keep only the data for the E. coli protein P0AEE5 and the sets before and after summarisation.\nWe use longForm() to convert the object for plotting.\nWe plot the intensities for each sample, facetting by set and colouring by experimental condition, linking dots from the same peptide or protein with a line.\n\n\nspikein[\"P0AEE5\", , c(\"peptides_norm\", \"proteins\")] |&gt; ## 1.\n  longForm(colvars = colnames(colData(spikein))) |&gt; ## 2.\n  data.frame() |&gt;\n  ggplot() + ## 3.\n  aes(x = colname, \n      y = value,\n      group = rowname) +\n  geom_line(linewidth = 0.1) +\n  geom_point(aes(colour = condition)) +\n  facet_grid(~ assay) +\n  theme(axis.text.x = element_blank())\n\n\n\n\nData for protein P0AEE5 before and after summarisation\n\n\n\n\nThe data processing is complete.\n\nplot(spikein)\n\n\n\n\nOverview of the QFeatures object and its processed sets.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "01-basics.html#sec_data_exploration",
    "href": "01-basics.html#sec_data_exploration",
    "title": "1  Statistical analysis with msqrob2",
    "section": "1.5 Data exploration",
    "text": "1.5 Data exploration\nData exploration aims to highlight the main sources of variation in the data prior to data modelling and can pinpoint to outlying or off-behaving samples. A common approach for data exploration is to perform dimension reduction, such as Multi Dimensional Scaling (MDS). We will first extract the set to explore along the sample annotations (used for plot colouring).\n\nse &lt;- getWithColData(spikein, \"proteins\")\n\nWe then use the scater package to compute and plot the PCA. For technical reasons, it requires SingleCellExperiment class object, but these can easily be generated from a SummarizedExperiment object.\n\nlibrary(\"scater\")\nse &lt;- runMDS(as(se, \"SingleCellExperiment\"), exprs_values = 1)\n\nWe can now explore the data structure while coloring for the factor of interest, here condition.\n\nplotMDS(se, colour_by = \"condition\") \n\n\n\n\nMDS visualisation of the spike-in data set. Each point represents a sample and is coloured by the spike-in condiion.\n\n\n\n\nThis plot reveals interesting information. First, we see that the samples are nicely separated according to their spike-in condition. Interestingly, the conditions are sorted by the concentration11. We also see some structure in the second dimension. This would probe us to contact the lab where the data were collected to ask if the samples were obtained in batches. It demonstrates the power of data exploration for QC.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "01-basics.html#sec-modelling",
    "href": "01-basics.html#sec-modelling",
    "title": "1  Statistical analysis with msqrob2",
    "section": "1.6 Data modelling",
    "text": "1.6 Data modelling\nWe model the preprocessed data to answer biologically relevant questions. As described above, each sample has been synthetically created to contain a constant human background where E. coli lysates were spiked in at five different concentration. Each sample preparation has been replicated four times. So, the key question is “can our model retrieve the proteins that have been spiked in across the conditions?” Moreover, since we know the expected protein abundance in each sample, we will also be able to assess how accurate the model can estimate the average fold changes between spike-in conditions.\n\n1.6.1 Sources of variation\nIn this experimental design, we can model a single source of variation: spike-in concentration12. All remaining sources of variability, e.g. pipetting errors, MS run to run variability, etc will be lumped in the residual variability (error term).\nSpike-in condition effects: we model the source of variation induced by the experimental treatment of interest as a fixed effect, which we consider non-random, i.e. the treatment effect is assumed to be the same in repeated experiments, but it is unknown and has to be estimated.\nWhen modelling a typical label-free experiment at the protein level, the model boils down to the following linear model:\n\\[\ny_i = \\mathbf{x}^T_i \\boldsymbol{\\beta} + \\epsilon_i\n\\]\nwith \\(y_i\\) the \\(\\log_2\\)-normalised and summarised protein intensities in sample \\(i\\); \\(\\mathbf{x}_i\\) a vector with the covariate pattern for the sample encoding the intercept, spike-in condition13, or other experimental factors; \\(\\boldsymbol{\\beta}\\) the vector of parameters that model the association between the covariates and the outcome; and \\(\\epsilon_i\\) the residuals reflecting variation that is not captured by the fixed effects. Note that \\(\\mathbf{x}_i\\) allows for a flexible parameterisation of the treatment beyond a single covariate, i.e. including a 1 for the intercept, continuous and categorical variables as well as their interactions. We assume the residuals to be independent and identically distributed (i.i.d) according to a normal distribution with zero mean and constant variance, i.e. \\(\\epsilon_{i} \\sim N(0,\\sigma_\\epsilon^2)\\), that can differ from protein to protein.\nIn R, this model is encoded using the following simple formula14:\n\nmodel &lt;- ~ condition\n\n\n\n1.6.2 Model estimation\nWe estimate the model with msqrob(). The function takes the QFeatures object, extracts the quantitative values from the \"proteins\" set generated during summarisation, and fits a simple linear model with condition as covariate, which are automatically retrieved from colData(spikein).\n\nspikein &lt;- msqrob(\n  spikein,  i = \"proteins\",\n  formula = model,\n  ridge = TRUE, robust = TRUE\n)\n\nWe enable M-estimation (robust = TRUE) for improved robustness against outliers. We also enable ridge regression (ridge = TRUE). Ridge regression stabilises the parameter estimation of fixed effects. However, this is only possible if there are more than two slope terms in the model, e.g. designs with more than two groups or designs involving multiple covariates.** The next chapter provides more details on robust regression and ridge regression.\nThe fitting results are available in the msqrobModels column of the rowData. More specifically, the modelling output is stored in the rowData as a statModel object, one model per row (protein). We will see in a later section how to perform statistical inference on the estimated parameters.\n\nmodels &lt;- rowData(spikein[[\"proteins\"]])[[\"msqrobModels\"]]\nmodels[1:3]\n\n$A0AVT1\nObject of class \"StatModel\"\nThe type is \"lmer\"\nThere number of elements is 5 \n\n$A0FGR8\nObject of class \"StatModel\"\nThe type is \"lmer\"\nThere number of elements is 5 \n\n$A0MZ66\nObject of class \"StatModel\"\nThe type is \"lmer\"\nThere number of elements is 5",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "01-basics.html#sec-inference",
    "href": "01-basics.html#sec-inference",
    "title": "1  Statistical analysis with msqrob2",
    "section": "1.7 Statistical inference",
    "text": "1.7 Statistical inference\nWe can now convert the biological question “does the spike-in condition affect the protein intensities?” into a statistical hypothesis. In other words, we must convert this question in a combination of the model parameters, also referred to as a contrast. To aid defining contrasts, we will visualise the experimental design using the ExploreModelMatrix package.\n\nlibrary(\"ExploreModelMatrix\")\nVisualizeDesign(\n  sampleData =  colData(spikein),\n  designFormula = model,\n  textSizeFitted = 4\n)$plotlist\n\n[[1]]\n\n\n\n\n\nVisualisation of the experimental design using the ExploreModelMatrix package.\n\n\n\n\nSpike-in condition a is the reference group. So the mean log2 intensity for samples from condition a is (Intercept). The mean log2 expression for samples from condition b is ‘(Intercept) + conditionb’. Hence, the average log2 fold change between condition b and condition a is modelled using the parameter ‘conditionb’.\nWith getCoef(), we can retrieve the estimated model parameters. We start with extracting the model output, stored as StatModel objects, from the rowData. Next, getCoef() retrieves the estimated model parameters:\n\nmodels &lt;- rowData(spikein[[\"proteins\"]])$msqrobModels\nparams &lt;- getCoef(models[[1]])\nhead(params)\n\n    (Intercept) ridgeconditionb ridgeconditionc ridgeconditiond ridgeconditione \n       23.51052         0.00000         0.00000         0.00000         0.00000 \n\n\nNote the \"ridge\" tag in front of the parameter names that indicates the parameters have been estimated using ridge penalisation. The model estimated 5 parameters to model the fixed and random effects. However, we are interested, for this data set, in the parameters that model the effect of condition.\n\nparams[grep(\"condition\", names(params))]\n\nridgeconditionb ridgeconditionc ridgeconditiond ridgeconditione \n              0               0               0               0 \n\n\nFor this protein we can see that the effects of condition are small, as expected since the protein is part of the human constant background. Note that because of the ridge penalisation they are shrunken to zero. We now explore the parameters for one of the E. coli proteins.\n\nparams &lt;- getCoef(models[[\"P0AEE5\"]])\nparams[grep(\"condition\", names(params))]\n\nridgeconditionb ridgeconditionc ridgeconditiond ridgeconditione \n      0.6612049       1.0635637       1.3121650       1.6876229 \n\n\nSince this is a benchmark study and we know the concentration of A (0.25 fmol/µL) and B (0.74 fmol/µL), the obvious answer is \\(log_2(0.74) - log_2(0.25) = 1.566\\). The average log2 difference in intensity between condition B and condition A that has been estimated by the model is 0.6612049, rather close. Now, the question is if we can conclude that the fold change between condition B and condition A is statistically significant for this protein based on the model output.\n\n1.7.1 Hypothesis testing\nAs shown above, the average difference in log2 intensity between condition b and a after correcting for the lab effect is ridgeconditionb. This combination of parameters is also called a contrast. Thus, we assess the following null hypothesis for this contrast: ridgeconditionb = 0 with our statistical test.\n\ncontrast &lt;- \"ridgeconditionb = 0\"\n\nmakeContrast() converts the hypothesis into a formal contrast matrix with parameter names as rows and hypotheses in columns15.\n\n(L &lt;- makeContrast(\n  \"ridgeconditionb = 0\",\n  \"ridgeconditionb\"\n))\n\n                ridgeconditionb\nridgeconditionb               1\n\n\nWe can now test our null hypothesis using hypothesisTest() which takes the QFeatures object with the fitted model and the contrast we just built. msqrob2 automatically applies the hypothesis testing to all proteins in the data.\n\nspikein &lt;- hypothesisTest(spikein, i = \"proteins\", contrast = L)\n\nThe results are stored in the set containing the model, here proteins. We retrieve the results from the rowData. Note, that for this spike-in study we know the ground truth, so we also add variable isEcoli to indicate if the protein is spiked (from E. coli).\n\ninference &lt;- rowData(spikein[[\"proteins\"]])$ridgeconditionb\ninference$Protein &lt;- rownames(inference)\ninference$isEcoli &lt;- inference$Protein %in% ecoli\nhead(inference)\n\n             logFC           se       df         t      pval   adjPval Protein\nA0AVT1  0.00000000 8.086020e-11 20.95446  0.000000 1.0000000 1.0000000  A0AVT1\nA0FGR8  0.06647992 3.917165e-02 17.43077  1.697144 0.1074520 0.7248094  A0FGR8\nA0MZ66 -0.04609821 3.641208e-02 19.31900 -1.266014 0.2205624 1.0000000  A0MZ66\nA1L0T0  0.00000000 1.740448e-10 20.95446  0.000000 1.0000000 1.0000000  A1L0T0\nA1X283  0.00000000 3.718563e-10  8.95446  0.000000 1.0000000 1.0000000  A1X283\nA2RRP1  0.00000000 8.224779e-11 19.95446  0.000000 1.0000000 1.0000000  A2RRP1\n       isEcoli\nA0AVT1   FALSE\nA0FGR8   FALSE\nA0MZ66   FALSE\nA1L0T0   FALSE\nA1X283   FALSE\nA2RRP1   FALSE\n\n\nNote, that missing values can occur because data modelling resulted in a fitError (the advanced vignette describes how to deal with proteins that could not be fit).\nThe results also include an adjusted p-value for each protein \\(j\\) to correct for multiple testing using the Benjamini-Hochberg False Discovery Rate (FDR) method, which represents an estimate of the minimum FDR at which the test result for protein \\(j\\) is considered significant, i.e. the expected fraction of false positives that are reported in the shortest top list of the most significant proteins that include protein \\(j\\).\n\n\n1.7.2 Volcano plots\nA volcano plot is a common visualisation that provides an overview of the hypothesis testing results, plotting the \\(-\\log_{10}\\) p-value16 as a function of the estimated log fold change. Volcano plots can be used to highlight the most interesting proteins that have large fold changes and/or are highly significant. We can use the table above directly to build a volcano plot using ggplot2 functionality. We also highlight which proteins are UPS standards, known to be differentially abundant by experimental design.\n\ninference |&gt; \n  na.exclude() |&gt;\n  ggplot(\n    aes(x = logFC,\n        y = -log10(pval),\n        color = isEcoli,\n        shape = adjPval &lt; 0.05)) +\n  geom_point() +\n  geom_vline(xintercept = log2(4.5) - log2(3), linetype = \"dashed\") +\n  scale_color_manual(\n    values = c(\"grey20\", \"firebrick\"), name = \"\",\n    labels = c(\"Human proteins\", \"Ecoli spikein\")\n  ) +\n  ggtitle(\"Statistical inference results\",\n          paste0(\"H0: \", colnames(L), \" = 0\"))\n\n\n\n\nVolcano plot of the statistical inference of the average difference between condition b and condition a.\n\n\n\n\nWe retrieve the proteins that are significantly differentially abundant based on the FDR-adjusted p-value (adjPval). Note that the majority of the differentially abundant proteins are E. coli proteins.\n\ntable(is_significant = inference$adjPval &lt; 0.05, \n      is_ecoli = inference$isEcoli)\n\n              is_ecoli\nis_significant FALSE TRUE\n         FALSE  3760  203\n         TRUE     19  443\n\n\nBecause we known the ground truth, we can also provide a list with false positives, true positives and the false discovery proprotion (FP/(FP+TP)) at a nominal 5% FDR level and observe that the FDP for this contrast is close to the 5% FDR, which is an estimate of the expected FDP if all assumptions made in the data analysis are valid.\n\ninference |&gt; \n  filter(adjPval &lt; 0.05) |&gt;\n  summarise(\n    fp = sum(!isEcoli), \n    tp = sum(isEcoli), \n    fdp = round(mean(!isEcoli) * 100, 2))\n\n  fp  tp  fdp\n1 19 443 4.11\n\n\n\n\n1.7.3 Heatmaps\nWe can explore the quantitative data of the significant proteins using a heatmap. First, we select the names of the proteins that were declared significant between condition A and condition B and extract their quantitative data.\n\nsigNames &lt;- inference$Protein[!is.na(inference$adjPval) & inference$adjPval &lt; 0.05]\nse &lt;- getWithColData(spikein, \"proteins\")\nse &lt;- se[sigNames, se$condition %in% c(\"a\", \"b\")]\n\nNext, we extract the quantitative data and scale by rows17 with assay(). We will create a heatmap using the ComplexHeatmap package, which enables heatmap annotations. We will annotate the heatmap using our model variables condition and lab.\n\nquants &lt;- t(scale(t(assay(se))))\nlibrary(\"ComplexHeatmap\")\nannotations &lt;- columnAnnotation(\n  condition = se$condition\n)\n\nWe now make the heatmap.\n\nset.seed(1234) ## annotation colours are randomly generated by default\nHeatmap(\n quants, name = \"log2 intensity\",\n cluster_rows = FALSE,\n top_annotation = annotations\n)\n\n\n\n\nHeatmap of the proteins that are significantly differentially abundant between condition b and condition a.\n\n\n\n\nWe observe that the majority of the returned proteins are indeed upregulated in the higher spike-in condition b.\n\n\n1.7.4 Fold change distributions\nAs this is a spike-in study with known ground truth, we can also plot the log2 fold change distributions against its true values, in this case 0 for the human proteins and 0.585 for the E. coli proteins.\n\nggplot(inference) +\n  aes(y = logFC,\n      x = isEcoli,\n      colour = isEcoli) +\n  geom_boxplot() +\n  geom_hline(yintercept = c(0, log2(4.5) - log2(3)), \n             colour = c(\"grey20\", \"firebrick\")) +\n  scale_color_manual(\n    values = c(\"grey20\", \"firebrick\"), name = \"\",\n    labels = c(\"Human proteins\", \"E. coli proteins\")\n  ) +\n  ggtitle(paste0(\"Hypothesis test: \", colnames(L), \" = 0\"))\n\n\n\n\nDistribution of the log2 fold changes between condition b and condition a. The red line is the expected value for spike-in proteins while the black line is the expected value for constant proteins.\n\n\n\n\nEstimated log2 fold change for human proteins are closely distributed around 0, as expected. log2 fold changes for E. coli proteins are distributed around the fold changes induced by the experimental design, indicating that msqrob2 is providing unbiased fold change estimates.\n\n\n1.7.5 Detail plots\nWe can explore the data for a protein to validate the statistical inference results. For example, let’s explore the peptide and the summarised protein intensities for the protein with the most significant difference.\n\n(targetProtein &lt;- rownames(inference)[which.min(inference$adjPval)])\n\n[1] \"P0A799\"\n\n\nTo obtain the required data, we perform a little data manipulation pipeline:\nWe use the QFeatures subsetting functionality to retrieve all data related to and focusing on the peptides_log and proteins sets that contains the peptide ion data used for model fitting. We then convert the data with longForm() for plotting. Finally, we plot the log2 normalised intensities for each sample at the protein and at the peptide level. Since multiple peptides are recorded for the protein, we link peptides across samples using a grey line. Samples are colored according to E. coli spike-in condition.\n\nspikein[targetProtein, , c(\"peptides_log\", \"proteins\")] |&gt; #1\n  longForm(colvars = colnames(colData(spikein)), #2\n           rowvars = \"Proteins\") |&gt;\n  data.frame() |&gt; \n  ggplot() +\n  aes(x = colname,\n      y = value) +\n  geom_line(aes(group = rowname), linewidth = 0.1) +\n  geom_point(aes(colour = condition)) +\n  facet_wrap(~ assay, scales = \"free\") +\n  ggtitle(targetProtein) +\n  theme_minimal() +\n  theme(axis.text.x = element_blank())\n\n\n\n\nDetail plot showing the peptide log intensities (left) and log-transformed normalised and summarised protein intensities (right). Every point is a sample, coloured by spike-in condition, and points belonging to the same feature (peptide or protein) are linked with a grey line.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "01-basics.html#going-further",
    "href": "01-basics.html#going-further",
    "title": "1  Statistical analysis with msqrob2",
    "section": "1.8 Going further",
    "text": "1.8 Going further\n\n1.8.1 Testing muliple contrasts at once\nWe showed how to perform a hypothesis test to answer the question “which proteins change in abundance between condition b and condition a?”. However, since we have 5 conditions, we can do further comparisons. msqrob2 can assess multiple hypothesis at once. Like above we must provide which hypotheses we want to compare. createPairwiseContrasts() will generate all possible comparisons between condition level. The function requires the model specification that has been estimated and the sample annotation from the data. We also specify that we estimated the model using ridge regression, which influences parameter names.\nTODO: add automatic pairwise comparisons function to msqrob2\n\n(allHypotheses &lt;- createPairwiseContrasts(\n  model, colData(spikein), \"condition\", ridge = TRUE\n))\n\n [1] \"ridgeconditionc - ridgeconditionb = 0\"\n [2] \"ridgeconditiond - ridgeconditionb = 0\"\n [3] \"ridgeconditione - ridgeconditionb = 0\"\n [4] \"ridgeconditiond - ridgeconditionc = 0\"\n [5] \"ridgeconditione - ridgeconditionc = 0\"\n [6] \"ridgeconditione - ridgeconditiond = 0\"\n [7] \"ridgeconditionb = 0\"                  \n [8] \"ridgeconditionc = 0\"                  \n [9] \"ridgeconditiond = 0\"                  \n[10] \"ridgeconditione = 0\"                  \n\n\nWe now run the same workflow as above for a single hypothesis, except that here allHypotheses is a vector of contrasts.\n\n(L &lt;- makeContrast(\n  allHypotheses,\n  parameterNames = paste0(\"ridgecondition\", c(\"b\", \"c\", \"d\", \"e\"))\n))\n\n                ridgeconditionc - ridgeconditionb\nridgeconditionb                                -1\nridgeconditionc                                 1\nridgeconditiond                                 0\nridgeconditione                                 0\n                ridgeconditiond - ridgeconditionb\nridgeconditionb                                -1\nridgeconditionc                                 0\nridgeconditiond                                 1\nridgeconditione                                 0\n                ridgeconditione - ridgeconditionb\nridgeconditionb                                -1\nridgeconditionc                                 0\nridgeconditiond                                 0\nridgeconditione                                 1\n                ridgeconditiond - ridgeconditionc\nridgeconditionb                                 0\nridgeconditionc                                -1\nridgeconditiond                                 1\nridgeconditione                                 0\n                ridgeconditione - ridgeconditionc\nridgeconditionb                                 0\nridgeconditionc                                -1\nridgeconditiond                                 0\nridgeconditione                                 1\n                ridgeconditione - ridgeconditiond ridgeconditionb\nridgeconditionb                                 0               1\nridgeconditionc                                 0               0\nridgeconditiond                                -1               0\nridgeconditione                                 1               0\n                ridgeconditionc ridgeconditiond ridgeconditione\nridgeconditionb               0               0               0\nridgeconditionc               1               0               0\nridgeconditiond               0               1               0\nridgeconditione               0               0               1\n\n\nThe contrast contains multiple hypotheses (multiple column) that involve multiple parameters (multiple rows).\nWe use again hypothesisTest() for performing the hypothesis test. We already generated results for the contrast ridgeconditionb = 0 and the function will throw an error by default, but we can overwrite the results with the argument overwrite = TRUE.\n\nspikein &lt;- hypothesisTest(spikein, i = \"proteins\", L, overwrite = TRUE)\n\nWe retrieve the inference tables from the rowData to generate the volcano plots.\n\ninferences &lt;- rowData(spikein[[\"proteins\"]])[, colnames(L)]\n\nWe here use a lapply() loop to generate additional information, and then combine all the tables in a single table.\n\ninferences &lt;- lapply(colnames(inferences), function(i) {\n  inference &lt;- inferences[[i]]\n  inference$Protein &lt;- rownames(inference)\n  inference$isEcoli &lt;- inference$Protein %in% ecoli\n  inference$Comparison &lt;- i\n  inference\n})\ninferences &lt;- do.call(rbind, inferences) ## combine in a single table\ninferences$Comparison &lt;- gsub(\"ridgecondition\",\"\", inferences$Comparison)\n\nTODO I created a function msqrobCollect() to streamline the table extraction above.\nWe plot the volcano plots with each comparison in a separate facet.\n\ninferences |&gt;\n  na.exclude() |&gt; \n  ggplot(\n    aes(x = logFC,\n        y = -log10(pval),\n        shape = adjPval &lt; 0.05,\n        color = isEcoli)) +\n  geom_point() +\n  scale_color_manual(\n    values = c(\"grey20\", \"firebrick\"), name = \"\",\n    labels = c(\"Human proteins\", \"Ecoli spikein\")\n  ) +\n  facet_wrap(~ Comparison)\n\n\n\n\nVolcano plot of the statistical inference results for all pairwise comparisons.\n\n\n\n\nSince we know the ground truth we can again evaluate the number of true positives, false positives and false discovery proportion.\n\ninferences |&gt; \n  filter(adjPval &lt; 0.05) |&gt; \n  group_by(Comparison) |&gt; \n  summarise(\n    fp = sum(!isEcoli), \n    tp = sum(isEcoli), \n    fdp = round(mean(!isEcoli)*100,2))\n\n# A tibble: 10 × 4\n   Comparison    fp    tp   fdp\n   &lt;chr&gt;      &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n 1 b             19   443  4.11\n 2 c             28   535  4.97\n 3 c - b         22   327  6.3 \n 4 d             28   581  4.6 \n 5 d - b         27   517  4.96\n 6 d - c          5   249  1.97\n 7 e             54   603  8.22\n 8 e - b         47   578  7.52\n 9 e - c         20   501  3.84\n10 e - d          5   286  1.72\n\n\nWe observe that the FDPs for the different contrasts nicely fluctuate around the nominal FDR that was set at 5%.\nWe can also assess the fold changes, but we first create a small table with the real values.\n\nrealLogFC &lt;- data.frame(\n  logFC = t(L) %*% lm(log2(concentration) ~ condition, colData(spikein))$coef[-1]\n)\nrealLogFC$Comparison &lt;- gsub(\"ridgecondition\",\"\",colnames(L))\n\nWe can now create the boxplots with the estimated log2-fold changes, adding horizontal lines with the corresponding target values.\n\ninferences |&gt;\n  na.exclude() |&gt; \n  ggplot(\n    aes(y = logFC,\n        x = isEcoli,\n        colour = isEcoli)) +\n  geom_boxplot()  +\n  scale_color_manual(\n    values = c(\"grey20\", \"firebrick\"), name = \"\",\n    labels = c(\"Human proteins\", \"E. coli proteins\")\n  ) +\n  facet_wrap(~Comparison) +\n  geom_hline(data = realLogFC, aes(yintercept = logFC), \n             colour = \"firebrick\") +\n  geom_hline(yintercept = 0)\n\n\n\n\nDistribution of the log2 fold changes for all pairwise comparisons. The red line is the expected value for spike-in proteins while the black line is the expected value for constant proteins.\n\n\n\n\nWe again observe that the log2 fold change estimates are close to the real spike-in fold changes induced by the experimental design.\n\n\n1.8.2 Model the spike-in concentration as a numeric\nSince the relative concentration of the E. coli spike-in lysate is known, we can also model the effect of the treatment using the log2-transformed spike-in concentration as a continuous covariate. We then expect the slope to be close to 1 for E. coli proteins.\n\nWe first create a variable with log2 transformed concentration in the colData.\nWe fit an msqrob model using the log2 transformed concentration as a fixed effect. Note, that we set ridge = FALSE because we only have one slope parameter in the model. We store the models in a new column with name \"concentration_model\".\nWe setup a contrast for the slope term.\nWe conduct the hypothesis test for all proteins.\n\n\nspikein$concentration_log2 &lt;- log2(spikein$concentration) #1.\nspikein &lt;- msqrob( #2.\n  spikein, i = \"proteins\",\n  formula = ~ concentration_log2,\n  ridge = FALSE,\n  robust = TRUE, \n  modelColumnName = \"concentration_model\"\n)\nL &lt;- makeContrast( #3.\n  \"concentration_log2 = 0\", parameterNames = \"concentration_log2\"\n)\nspikein &lt;- hypothesisTest( #4.\n  spikein, i = \"proteins\", L, modelColumn = \"concentration_model\",\n  overwrite = TRUE\n)\n\nWe plot the results using the volcano plot as in the previous section.\n\ninference &lt;- rowData(spikein[[\"proteins\"]])[, colnames(L)]\ninference$Protein &lt;- rownames(inference)\ninference$isEcoli &lt;- inference$Protein %in% ecoli\ninference |&gt;\n  na.exclude() |&gt;\n  ggplot(\n    aes(x = logFC,\n        y = -log10(adjPval),\n        color = isEcoli)) +\n  geom_point() +\n  geom_hline(yintercept = -log10(0.05)) +\n  geom_vline(xintercept = 1) +\n  scale_color_manual(\n    values = c(\"grey20\", \"firebrick\"), name = \"\",\n    labels = c(\"Human proteins\", \"Ecoli spikein\")\n  )\n\n\n\n\nVolcano plot of the statistical inference results when modelling the spike-in concentration as a continuous variable. logFC actually stands for the slope parameter.\n\n\n\n\nSimilarly, we plot the estimated log2 concentration slope against the expected value.\n\ninference |&gt;\n  na.exclude() |&gt;\n  ggplot(\n    aes(y = logFC,\n        x = isEcoli,\n        colour = isEcoli)) +\n  geom_boxplot()  +\n  scale_color_manual(\n    values = c(\"grey20\", \"firebrick\"), name = \"\",\n    labels = c(\"Human proteins\", \"E. coli proteins\")\n  ) + \n  geom_hline(yintercept = 0) + \n  geom_hline(yintercept = 1, color = \"firebrick\")\n\n\n\n\nDistribution of the log2 fold changes for the slope parameter. The red line is the expected value for spike-in proteins while the black line is the expected value for constant proteins.\n\n\n\n\nNote, that the slopes for the human and E. coli proteins are centered around 0 and 1, respectively.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "01-basics.html#conclusion",
    "href": "01-basics.html#conclusion",
    "title": "1  Statistical analysis with msqrob2",
    "section": "1.9 Conclusion",
    "text": "1.9 Conclusion\nIn this vignette, we have demonstrated a typical data analysis workflow for label free data using msqrob2. Because the packages relies on the QFeatures data class, we could demonstrate the implementation of a complete pre-processing workflow starting from MaxQuant’s peptide table: log2-transformation, PSM filtering, missing value management, normalisation, and summarisation. The data exploration revealed expected patterns of variation among samples, as this is a ground truth data set.\nOnce pre-processed, we use the msqrob2 package to model the (known) effect of spike-in condition. We showed how to run statistical inference on the modelling results to retrieve the significance of differentially abundant proteins. We explored statistical results through volcano plots and boxplots of the log2 fold changes and visually validated the results for one protein by plotting the input data. We have shown the inference pipeline can be streamlined when assessing multiple hypotheses. In this example, the spike-in condition can be encoded as a categorical variable or a numeric variable, and we showed how to model and interpret the results for both cases.\nThis chapter thus provides a general framework for analysing simple experimental designs for label-free proteomics experiments. Remember, this book provides an overview of different use-cases with more complex designs. In the next chapter, we will illustrate advanced concepts of proteomics data analysis, illustrated by the analysis of a TMT-labelled spike-in experiment.\n\n\n\n\nGatto, Laurent, Ruedi Aebersold, Juergen Cox, Vadim Demichev, Jason Derks, Edward Emmott, Alexander M Franks, et al. 2023. “Initial Recommendations for Performing, Benchmarking and Reporting Single-Cell Proteomics Experiments.” Nat. Methods 20 (3): 375–86.\n\n\nO’Brien, Jonathon J, Anil Raj, Aleksandr Gaun, Adam Waite, Wenzhou Li, David G Hendrickson, Niclas Olsson, and Fiona E McAllister. 2024. “A Data Analysis Framework for Combining Multiple Batches Increases the Power of Isobaric Proteomics Experiments.” Nat. Methods 21 (2): 290–300.\n\n\nShen, Xiaomeng, Shichen Shen, Jun Li, Qiang Hu, Lei Nie, Chengjian Tu, Xue Wang, et al. 2018. “IonStar Enables High-Precision, Low-Missing-Data Proteomics Quantification in Large Biological Cohorts.” Proc. Natl. Acad. Sci. U. S. A. 115 (21): E4767–76.\n\n\nSticker, Adriaan, Ludger Goeminne, Lennart Martens, and Lieven Clement. 2020. “Robust Summarization and Inference in Proteome-Wide Label-Free Quantification.” Mol. Cell. Proteomics 19 (7): 1209–19.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "01-basics.html#footnotes",
    "href": "01-basics.html#footnotes",
    "title": "1  Statistical analysis with msqrob2",
    "section": "",
    "text": "The ion selection for MS2 depends on the data recorded in MS1. Therefore, this approach is referred to as data dependent acquisition (DDA).↩︎\nMaxQuant also computes a protein table. However, we found that starting from MaxQuant’s protein table leads to a decrease in performance. We will illustrate in this tutorial how to build the protein table.↩︎\nImproving peptide identification is outside the scope of this tutorial↩︎\nRecall that only the top most intense ion peaks are send for MS2↩︎\nA QFeatures object can be seen as a special list of SummarizedExperiment objects.↩︎\nsee also the R for mass spectrometry book↩︎\nWe will however not evaluate the code in this tutorial as our general advice is to avoid imputation. To run the code, you’ll need to uncomment it first.↩︎\nWe will explain this with more details at the end of the summarisation step↩︎\nDuring robust estimation, the least squared error minimisation, that is minimising \\(\\sum_i\\mathbf{\\epsilon}^2_i\\), is iteratively reweighted using Huber weights, i.e. \\(\\sum_iw_i\\mathbf{\\epsilon}^2_i\\). This is internally performed using MASS::rlm().↩︎\nIn fact, this is also true for the previous transformation where the peptides are linked across sets.↩︎\nRecall that a to e condition imply low to high concentration.↩︎\nNote that we have the spike-in concentration encoded in two ways. concentration is encoded as a numerical value and provides the actual concentration amount in fmol/µL. condition is encoded as a factor, meaning that every concentration is regarded as an independent group. We will use the latter encoding as most common research questions consist of group-wise comparisons. The modelling of concentration as a numeric will be discussed in a dedicated section↩︎\nCategorical variables are encoded using dummy coding.↩︎\nWe don’t need to specify the intercept as R automatically adds it during model estimation. you can explicitly add it using ~ 1 + ..., you can also suppress it using ~ 0 +. When an intercept is included, one of the groups is defined as the reference group and its corresponding model parameter is absorbed in the intercept. The residuals don’t need to be specified as they are part of the model estimation process.↩︎\nNote, that we only need to specify the names of the model parameters that are involved in the contrast when using the make contrast function. The hypothesisTest function below will then subset the relevant part from the model output. Also, note that the contrast matrix in this example is trivial. However, we will later show how to asses multiple hypotheses at once and then the contrast matrix consists of multiple columns, with one column for each contrast↩︎\nNote, that upon this transformation a value of 1 represents a p-value of 0.1, 2 a p-value of 0.01, 3 a p-value of 0.001, etc.↩︎\nThe scales() function aligns the means and the centered standard deviations by column. Since we want to scale by row, we need to transpose (t())) before scaling and transpose back after scaling. Scaling the data will remove changes in feature intensities that are caused by uninteresting changes in ionisation efficiency.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "02-advanced.html",
    "href": "02-advanced.html",
    "title": "2  Advanced statistical analysis with msqrob2",
    "section": "",
    "text": "2.1 Background\nThis chapter builds upon the chapter with the basics of differential proteomics data analysis and provides more advanced concepts using msqrob2. To illustrate these advanced concepts, we will use the spike-in study published by Huang et al. (2020). We chose this data set because:\nLabelling strategies in mass spectrometry (MS)-based proteomics enhance sample throughput by enabling the acquisition of multiple samples within a single run. The labelling strategy that allows the highest multiplexing is the tandem mass tag (TMT) labelling and will be the focus of the current tutorial.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Advanced statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "02-advanced.html#background",
    "href": "02-advanced.html#background",
    "title": "2  Advanced statistical analysis with msqrob2",
    "section": "",
    "text": "2.1.1 TMT workflow\nTMT-based workflow highly overlap with label-free workflows. However, TMT-based workflows have an additional sample preparation step, where the digested peptides from each sample are labelled with a TMT reagent and samples with different TMT reagents are pooled in a single TMT mixture1. The signal processing is also slightly affected since the quantification no longer occurs in the MS1 space but at the MS2 level. It is important to understand that TMT reagent are isobaric, meaning that the same peptide with different TMT labels will have the same mass for the intact ion, as recorded during MS1. However, the TMT fragments that are released upon fragmentation during MS2, also called TMT reporter ions, have label-specific masses. The TMT fragments have an expected mass and are distributed in a low-mass range of the MS2 space. The intensity of each TMT fragment is directly proportional to the peptide quantity in the original sample before pooling. The TMT fragment intensities measured during MS2 are used as quantitative data. The higher mass range contains the peptide fragments that compose the peptide fingerprint, similarly to LFQ. This data range is therefore used for peptide identification. Interestingly, the peptide fingerprint originates from the same peptide across multiple samples. This leads to a signal boost for low abundant peptides and hence should improve data sensitivity and consistency.\n\n\n\n\n\nOverview of an TMT-based proteomics workflow.\n\n\n\n\n\n\n2.1.2 Challenges\nThe analysis of TMT-based proteomics data shares the same challenges as the data analysis challenges for LFQ. However, TMT workflows impose additional challenges:\n\nContemporary experiments often involve increasingly complex designs, where the number of samples exceeds the capacity of a single TMT mixture, resulting in a complex correlation structure that must be addressed for accurate statistical inference. We will describe in the modelling section the different sources of variation.\nWe also recommend modelling TMT data at the lowest level, that is at the peptide ion level, for optimal performance (Vandenbulcke et al. 2025). These ion-level models are more complex and include additional sources of variation instead of relying on the summarised protein values. We have shown for LFQ data that a two-step approach where data are first summarised (using a model-based method) and then modelled with msqrob2 leads to similar results, and hence provides more accessible models for non-specialised data analysts (Sticker et al. 2020).\n\n\n\n2.1.3 Experimental context\nThe data set used in this chapter is a spike-in experiment (PXD0015258) published by Huang et al. (2020). It consists of controlled mixtures with known ground truth. UPS1 peptides at concentrations of 500, 333, 250, and 62.5 fmol were spiked into 50 g of SILAC HeLa peptides, each in duplicate. These concentrations form a dilution series of 1, 0.667, 0.5, and 0.125 relative to the highest UPS1 peptide amount (500 fmol). A reference sample was created by combining the diluted UPS1 peptide samples with 50g of SILAC HeLa peptides. All dilutions and the reference sample were prepared in duplicate, resulting in a total of ten samples. These samples were then treated with TMT10-plex reagents and combined before LC-MS/MS analysis. This protocol was repeated five times, each with three technical replicates, totaling 15 MS runs.\nWe will start from the PSM data generated by Skyline and infer protein-level differences between samples. To achieve this goal, we will apply an msqrob2TMT workflow, a data processing and modelling workflow dedicated to the analysis of TMT-based proteomics datasets. We will demonstrate how the workflow can highlight the spiked-in proteins. Before delving into the analysis, let us prepare our computational environment.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Advanced statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "02-advanced.html#load-packages",
    "href": "02-advanced.html#load-packages",
    "title": "2  Advanced statistical analysis with msqrob2",
    "section": "2.2 Load packages",
    "text": "2.2 Load packages\nWe load the msqrob2 package, along with additional packages for data manipulation and visualisation.\n\nlibrary(\"msqrob2\")\nlibrary(\"dplyr\")\nlibrary(\"ggplot2\")\nlibrary(\"patchwork\")\n\nWe also configure the parallelisation framework.\n\nlibrary(\"BiocParallel\")\nregister(SerialParam())",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Advanced statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "02-advanced.html#data",
    "href": "02-advanced.html#data",
    "title": "2  Advanced statistical analysis with msqrob2",
    "section": "2.3 Data",
    "text": "2.3 Data\n\n2.3.1 File caching\nThe data have been deposited by the authors in the MSV000084264 MASSiVE repository, but we will retrieve the time stamped data from our Zenodo repository. We need 2 files: the Skyline identification and quantification table generated by the authors and the sample annotation files.\nTo facilitate management of the files, we download the required files using the BiocFileCache package. The package will set up a local database in a cache directory2. BiocFileCache() creates a connection to that database and bfcrpath() will query the database for the required URL. If that URL is not present in the database, the function will automatically download the URL target file and store it in the cache directory. If the URL is already present in the database, the function will retrieve the associated file from the local cache directory. This procedure ensures that the files are downloaded only once while providing a direct link to its source link. When these links point to permanent archives (like Zenodo) or large public databases (like PRIDE or MASSiVE), this approach promotes reproducible analyses.\nThe chunk below will take some time to complete the first time you run it as it needs to download the (large) file locally, but will fetch the local copy the following times.\n\nlibrary(\"BiocFileCache\")\nbfc &lt;- BiocFileCache()\npsmFile &lt;- bfcrpath(bfc, \"https://zenodo.org/records/14767905/files/spikein1_psms.txt?download=1\")\nannotFile &lt;- bfcrpath(bfc, \"https://zenodo.org/records/14767905/files/spikein1_annotations.csv?download=1\")\n\nNow the files are downloaded, we can load the two tables.\n\n\n2.3.2 PSM table\nAn MS experiment generates spectra. Each MS2 spectrum is used to infer the peptide identity using a search engine. When an observed spectrum is matched to a theoretical peptide spectrum, we have a peptide-to-spectrum match (PSM). The identification software compiles all the PSMs inside a table. Hence, the PSM data is the lowest possible level to perform data modelling.\nEach row in the PSM data table contains information for one PSM (the table below shows the first 6 rows). The columns contains various information about the PSM, such as the peptide sequence and charge, the quantified value, the inferred protein group, the measured and predicted retention time and precursor mass, the score of the match, … In the case of Skyline TMT data, the quantification values are provides in multiple columns (start with \"Abundance.\"), one for each TMT label. Regardless of TMT or LFQ experiments, the PSM table stacks the quantitative values from samples in different runs below each other. We must therefore split the table by run to ensure that every quantitative column contains data from a single sample. This is performed during the conversion to a QFeatures object.\n\npsms &lt;- read.delim(psmFile)\nqcols &lt;- grep(\"Abundance\", colnames(psms), value = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChecked\nConfidence\nIdentifying.Node\nPSM.Ambiguity\nAnnotated.Sequence\nModifications\nMarked.as\nX..Protein.Groups\nX..Proteins\nMaster.Protein.Accessions\nMaster.Protein.Descriptions\nProtein.Accessions\nProtein.Descriptions\nX..Missed.Cleavages\nCharge\nDeltaScore\nDeltaCn\nRank\nSearch.Engine.Rank\nm.z..Da.\nMH…Da.\nTheo..MH…Da.\nDeltaM..ppm.\nDeltam.z..Da.\nActivation.Type\nMS.Order\nIsolation.Interference….\nAverage.Reporter.S.N\nIon.Inject.Time..ms.\nRT..min.\nFirst.Scan\nSpectrum.File\nFile.ID\nAbundance..126\nAbundance..127N\nAbundance..127C\nAbundance..128N\nAbundance..128C\nAbundance..129N\nAbundance..129C\nAbundance..130N\nAbundance..130C\nAbundance..131\nQuan.Info\nIons.Score\nIdentity.Strict\nIdentity.Relaxed\nExpectation.Value\nPercolator.q.Value\nPercolator.PEP\n\n\n\n\nFalse\nHigh\nMascot (O4)\nUnambiguous\n[K].gFQQILAGEYDHLPEQAFYMVGPIEEAVAk.[A]\nN-Term(TMT6plex); K30(TMT6plex)\n\n1\n1\nP06576\nATP synthase subunit beta, mitochondrial OS=Homo sapiens GN=ATP5B PE=1 SV=3\nP06576\nATP synthase subunit beta, mitochondrial OS=Homo sapiens GN=ATP5B PE=1 SV=3\n0\n3\n1.0000\n0\n1\n1\n1270.3249\n3808.960\n3808.966\n-1.51\n-0.00192\nCID\nMS2\n47.955590\n8.7\n50.000\n212.2487\n112815\n161117_SILAC_HeLa_UPS1_TMT10_Mixture1_03.raw\nF1\n2548.326\n3231.929\n2760.839\n4111.639\n3127.254\n1874.163\n2831.423\n2298.401\n3798.876\n3739.067\nNA\n90\n28\n21\n0.0000000\n0\n0.0000140\n\n\nFalse\nHigh\nMascot (K2)\nUnambiguous\n[R].qYPWGVAEVENGEHcDFTILr.[N]\nN-Term(TMT6plex); C15(Carbamidomethyl); R21(Label:13C(6)15N(4))\n\n1\n1\nQ16181\nSeptin-7 OS=Homo sapiens GN=SEPT7 PE=1 SV=2\nQ16181\nSeptin-7 OS=Homo sapiens GN=SEPT7 PE=1 SV=2\n0\n3\n1.0000\n0\n1\n1\n920.4493\n2759.333\n2759.332\n0.31\n0.00028\nCID\nMS2\n9.377507\n8.1\n3.242\n164.7507\n87392\n161117_SILAC_HeLa_UPS1_TMT10_Mixture3_03.raw\nF5\n22861.765\n25817.946\n23349.498\n29449.609\n25995.929\n22955.769\n30578.971\n30660.488\n38728.853\n25047.280\nNA\n76\n24\n17\n0.0000001\n0\n0.0000003\n\n\nFalse\nHigh\nMascot (K2)\nUnambiguous\n[R].dkPSVEPVEEYDYEDLk.[E]\nN-Term(TMT6plex); K2(Label); K17(Label)\n\n1\n1\nQ9Y450\nHBS1-like protein OS=Homo sapiens GN=HBS1L PE=1 SV=1\nQ9Y450\nHBS1-like protein OS=Homo sapiens GN=HBS1L PE=1 SV=1\n1\n3\n0.9730\n0\n1\n1\n920.1605\n2758.467\n2758.461\n2.08\n0.00192\nCID\nMS2\n38.317050\n17.8\n13.596\n143.4534\n74786\n161117_SILAC_HeLa_UPS1_TMT10_Mixture3_03.raw\nF5\n25504.083\n27740.450\n25144.974\n25754.579\n29923.176\n34097.637\n31650.255\n27632.692\n23886.881\n35331.092\nNA\n74\n30\n23\n0.0000004\n0\n0.0000010\n\n\nFalse\nHigh\nMascot (F2)\nSelected\n[R].hEHQVMLmr.[Q]\nN-Term(TMT6plex); M8(Oxidation); R9(Label:13C(6)15N(4))\n\n1\n1\nQ15233\nNon-POU domain-containing octamer-binding protein OS=Homo sapiens GN=NONO PE=1 SV=4\nQ15233\nNon-POU domain-containing octamer-binding protein OS=Homo sapiens GN=NONO PE=1 SV=4\n0\n4\n0.5250\n0\n1\n1\n359.6898\n1435.737\n1435.738\n-0.04\n-0.00002\nCID\nMS2\n21.390040\n36.5\n50.000\n21.6426\n6458\n161117_SILAC_HeLa_UPS1_TMT10_Mixture4_02.raw\nF10\n13493.228\n14674.490\n11187.900\n12831.495\n13839.426\n12441.353\n13450.885\n14777.844\n13039.995\n12057.121\nNA\n40\n25\n18\n0.0003351\n0\n0.0001175\n\n\nFalse\nHigh\nMascot (K2)\nUnambiguous\n[R].dNLTLWTADNAGEEGGEAPQEPQS.[-]\nN-Term(TMT6plex)\n\n1\n1\nP31947\n14-3-3 protein sigma OS=Homo sapiens GN=SFN PE=1 SV=1\nP31947\n14-3-3 protein sigma OS=Homo sapiens GN=SFN PE=1 SV=1\n0\n3\n1.0000\n0\n1\n1\n920.0943\n2758.268\n2758.264\n1.53\n0.00141\nCID\nMS2\n0.000000\n16.7\n6.723\n174.1863\n92950\n161117_SILAC_HeLa_UPS1_TMT10_Mixture3_03.raw\nF5\n64582.786\n50576.417\n47126.037\n56285.129\n46257.310\n52634.885\n49716.850\n60660.574\n55830.488\n40280.577\nNA\n38\n21\n14\n0.0002153\n0\n0.0000138\n\n\nFalse\nHigh\nMascot (K2)\nUnambiguous\n[R].aLVAIGTHDLDTLSGPFTYTAk.[R]\nN-Term(TMT6plex); K22(Label)\n\n1\n1\nQ9NSD9\nPhenylalanine–tRNA ligase beta subunit OS=Homo sapiens GN=FARSB PE=1 SV=3\nQ9NSD9\nPhenylalanine–tRNA ligase beta subunit OS=Homo sapiens GN=FARSB PE=1 SV=3\n0\n3\n0.9783\n0\n1\n1\n919.8502\n2757.536\n2757.532\n1.48\n0.00136\nCID\nMS2\n30.619960\n26.7\n8.958\n176.4863\n94294\n161117_SILAC_HeLa_UPS1_TMT10_Mixture3_03.raw\nF5\n35404.709\n31905.852\n30993.941\n36854.351\n37506.001\n25703.444\n38626.598\n35447.942\n33788.409\n32031.516\nNA\n46\n29\n22\n0.0002060\n0\n0.0000720\n\n\n\n\n\nThere is a peculiarity with the dataset: the spectra have been identified with 2 nodes. In one node, the authors searched the SwissProt database for proteins with static modifications related to the metabolic labelling, in the other node they searched the Sigma_UPS protein database without these static modifications. However, some spectra were identified by both nodes leading to duplicate PSMs. We here remove these duplicated PSMs that are identification artefacts.\n\nduplicatesQuants &lt;- duplicated(psms[, qcols]) | duplicated(psms[, qcols], fromLast = TRUE)\npsms &lt;- psms[!duplicatesQuants, ]\n\nWe will also subset the data set to reduce computational costs. If you want to run the analysis on the full data set, you can skip this code chunk. The subsetting will keep all UPS proteins, known to be differentially abundant by experimental design, and we will keep 500 background proteins known to be unchanged across condition.\n\nallProteins &lt;- unique(psms$Protein.Accessions)\nupsProteins &lt;- grep(\"ups\", allProteins, value = TRUE)\nhelaProteins &lt;- grep(\"ups\", allProteins, value = TRUE, invert = TRUE)\nset.seed(1234)\nkeepProteins &lt;- c(upsProteins, sample(helaProteins, 500))\npsms &lt;- psms[psms$Protein.Accessions %in% keepProteins, ]\n\n\n\n2.3.3 Sample annotation table\nThe purpose and structure of the sample annotation table is identical across proteomics experiments (see introduction to the sample annotation table). The annotation table used in this tutorial has been generated by the authors.\n\ncoldata &lt;- read.csv(annotFile)\n\nWe perform a little cleanup:\n\nWe keep only the sample annotations that are meaningful to the experiment and that are not redundant with other annotations.\nWe extract the run identifier from the MS file name (which we store as the File.Name annotation).\nThe TMT used for labelling each sample is stored in the Channel column. We however prefer to use the less esoteric term Label for more clarity with the main text when we’ll discuss labelling effects.\n\n\n## 1.\ncoldata &lt;- coldata[, c(\"Run\", \"Channel\", \"Condition\", \"Mixture\", \"TechRepMixture\")]\n## 2.\ncoldata$File.Name &lt;- coldata$Run\ncoldata$Run &lt;- sub(\"^.*(Mix.*).raw\", \"\\\\1\", coldata$Run)\n## 3.\ncolnames(coldata)[2] &lt;- \"Label\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRun\nLabel\nCondition\nMixture\nTechRepMixture\nFile.Name\n\n\n\n\nMixture1_01\n126\nNorm\nMixture1\n1\n161117_SILAC_HeLa_UPS1_TMT10_Mixture1_01.raw\n\n\nMixture1_01\n127N\n0.667\nMixture1\n1\n161117_SILAC_HeLa_UPS1_TMT10_Mixture1_01.raw\n\n\nMixture1_01\n127C\n0.125\nMixture1\n1\n161117_SILAC_HeLa_UPS1_TMT10_Mixture1_01.raw\n\n\nMixture1_01\n128N\n0.5\nMixture1\n1\n161117_SILAC_HeLa_UPS1_TMT10_Mixture1_01.raw\n\n\nMixture1_01\n128C\n1\nMixture1\n1\n161117_SILAC_HeLa_UPS1_TMT10_Mixture1_01.raw\n\n\nMixture1_01\n129N\n0.125\nMixture1\n1\n161117_SILAC_HeLa_UPS1_TMT10_Mixture1_01.raw\n\n\n\n\n\n\n\n2.3.4 Convert to QFeatures\nWe use readQFeatures() to create a QFeatures object. Since we start from the PSM-level data, the approach is somewhat more elaborate3. First, recall that every quantitative column in the PSM table contains information for multiple runs. Therefore, the function split the table based on the run identifier, given by the runCol argument (for Skyline, that identifier is contained in Spectrum.File). So, the QFeatures object after import will contain as many sets as there are runs. Next, the function links the annotation table with the PSM data. To achieve this, the annotation table must contain a runCol column that provides the run identifier in which each sample has been acquired, and this information will be used to match the identifiers in the Spectrum.File column of the PSM table. The annotation table must also contain a quantCols column that tells the function which column in the PSM table contains the quantitative information for a given sample. In this case, the quantCols depend on\n\ncoldata$runCol &lt;- coldata$File.Name\ncoldata$quantCols &lt;- paste0(\"Abundance..\", coldata$Label)\n(spikein &lt;- readQFeatures(\n  psms, colData = coldata,\n  runCol = \"Spectrum.File\",\n  quantCols = qcols\n))\n\nAn instance of class QFeatures (type: bulk) with 15 sets:\n\n [1] 161117_SILAC_HeLa_UPS1_TMT10_Mixture1_01.raw: SummarizedExperiment with 1905 rows and 10 columns \n [2] 161117_SILAC_HeLa_UPS1_TMT10_Mixture1_02.raw: SummarizedExperiment with 1902 rows and 10 columns \n [3] 161117_SILAC_HeLa_UPS1_TMT10_Mixture1_03.raw: SummarizedExperiment with 1952 rows and 10 columns \n ...\n [13] 161117_SILAC_HeLa_UPS1_TMT10_Mixture5_01.raw: SummarizedExperiment with 1919 rows and 10 columns \n [14] 161117_SILAC_HeLa_UPS1_TMT10_Mixture5_02.raw: SummarizedExperiment with 1909 rows and 10 columns \n [15] 161117_SILAC_HeLa_UPS1_TMT10_Mixture5_03.raw: SummarizedExperiment with 1844 rows and 10 columns \n\n\nWe now have a QFeatures object with 15 sets, each containing data associated with an MS run. The name of each set is defined by the name of the corresponding file name of the run, which is unnecessarily long. We simplify the set names, although this step is optional and only meant to improve the clarity of the output.\n\n## This is optional\nnames(spikein) &lt;- sub(\"^.*(Mix.*).raw\", \"\\\\1\", names(spikein))\n(inputNames &lt;- names(spikein))\n\n [1] \"Mixture1_01\" \"Mixture1_02\" \"Mixture1_03\" \"Mixture2_01\" \"Mixture2_02\"\n [6] \"Mixture2_03\" \"Mixture3_01\" \"Mixture3_02\" \"Mixture3_03\" \"Mixture4_01\"\n[11] \"Mixture4_02\" \"Mixture4_03\" \"Mixture5_01\" \"Mixture5_02\" \"Mixture5_03\"",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Advanced statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "02-advanced.html#data-preprocessing",
    "href": "02-advanced.html#data-preprocessing",
    "title": "2  Advanced statistical analysis with msqrob2",
    "section": "2.4 Data preprocessing",
    "text": "2.4 Data preprocessing\nSimilar to the basic concepts chapter, we will use the QFeatures’ data preprocessing functionality. The data preprocessing workflow for TMT data is similar to the workflow for LFQ data, but there are subtle differences associated with the fact that we start from PSM-level data, namely the PSM filtering is mode complex and the data preprocessing will be applied for each run separately to remove part of the run effect.\n\n2.4.1 Encoding missing values\nAny zero value needs to be encoded by a missing value.\n\nspikein &lt;- zeroIsNA(spikein, inputNames)\n\n\n\n2.4.2 Log2 transformation\nSimilar to any MS-based proteomics data, TMT data are heteroskedastic, with a strong mean-variance relationship. This is illustrated by the intensities and log2-intensities for one of the peptide ions, the triply charged DLLHVLAFSK, in function of the UPS spike-in dilution factor.\n\n\n\n\n\n\n\n\n\nLog2-transformation solves the heteroskedasticity issue, but also provides a scale that directly relates to biological interpretation (see the basic concepts chapter). We perform log2-transformation with logTransform() from the QFeatures package.\n\nlogNames  &lt;- paste0(inputNames, \"_log\")\nspikein &lt;- logTransform(\n    spikein, inputNames, name = logNames, base = 2\n)\n\n\n\n2.4.3 Sample filtering\nWe first remove the reference samples. These samples were used by the MSstatsTMT authors to obtain normalisation factors (Huang et al. 2020). However, this approach ignores the uncertainty associated with the measurement with these reference samples, potentially inflating the noise in the samples of interest. Hence, msqrob2 workflows do not use reference normalisation. In practice, we found no impact on model performance (Vandenbulcke et al. 2025), hence we favor a more parsimonious approach. The information is available from the colData, under the Condition column. We remove any sample that is marked as Norm using subsetByColData().\n\nspikein &lt;- subsetByColData(spikein, spikein$Condition != \"Norm\")\n\n\n\n2.4.4 PSM filtering\nFiltering removes low-quality and unreliable PSMs that would otherwise introduce noise and artefacts in the data. Conceptually, PSM filtering is identical to peptide filtering, but we will here apply filtering criteria for which some are not readily available in the data. Therefore, we will add custom filtering variable to the rowData that will then be used with filterFeatures(). This provides an ideal use case to demonstrate the customisation of a filtering workflow.\n\nRemove ambiguous identifications\nThe background proteins originate from HeLa cells, which also contain UPS proteins. The background UPS proteins and the spiked-in UPS proteins differ in metabolic labelling, so we should be able to distinguish them. We used the PSM-level data searched with mascot, as provided by the MSstatsTMT authors who used two mascot identification nodes. In one node they searched the SwissProt database for proteins with static modifications related to the metabolic labelling, in the other node they searched the Sigma_UPS protein database without these static modifications. Ideally, this should separate the spiked-in UPS proteins and the UPS proteins from the HeLa cells, however, this is not always the case. The SwissProt search is expected to return peptide-spectrum matches (PSMs) for all proteins, including non-UPS HeLa, UPS HeLa, and spike-in UPS proteins. Conversely, the Sigma_UPS search is expected to return PSMs exclusively for spike-in UPS proteins. However, a PSM that matches a UPS protein in the SwissProt search but is not identified as such in the Sigma_UPS search could either correctly originate from a HeLa protein or represent a spiked-in UPS protein that was not recognised as such in the Sigma_UPS search. Additionally, there are ambiguous PSMs that are not matched to a UPS protein in the HeLa search but are matched to a UPS protein in the SwissProt search. To address this, we exclude these ambiguous proteins from the analysis.\nTo define the amibiguous PSMs, we retrieve the PSM annotations from the rowData and create a new colum indicating whether a PSM belongs to a UPS protein or not, based on the protein SwissProt identifiers. For this, we apply a custom filtering worklow:\n\nCollect data: combine all the rowData information in a single table. We will apply the filter on the\n\n\nrowdata &lt;- rbindRowData(spikein, logNames)\n\n\nCompute new variable: (2a) define whether the PSM’s protein group is a UPS protein and then (2b) define an ambiguous PSM as a PSM that is marked as UPS by the SwissProt identifier but not by the Sigma_UPS node (Marked.as column), and inversely.\n\n\n## 2a.\nrowdata$isUps &lt;- \"no\"\nisUpsProtein &lt;- grepl(\"ups\", rowdata$Protein.Accessions)\nrowdata$isUps[isUpsProtein] &lt;- \"yes\"\n## 2b.\nrowdata$isUps[!isUpsProtein & grepl(\"UPS\", rowdata$Marked.as)] &lt;- \"amb\"\nrowdata$isUps[isUpsProtein & !grepl(\"UPS\", rowdata$Marked.as)] &lt;- \"amb\"\n\n\nReinsert in the rowData: insert the modified table with new information back in the rowData of the different sets. This means that the single table with rowData information needs to be split by each set. split() will produce a named list of tables and each table will be iteratively inserted as rowData of the set.\n\n\nrowData(spikein) &lt;- split(rowdata, rowdata$assay)\n\n\nApply the filter: the filtering is performed by filterFeatures() using the new information from the rowData. We specify keep = TRUE because the input sets (before log-transformation) do not contain the filtering variable, so we tell the function to keep all PSMs for the sets that don’t have the variable isUps.\n\n\nspikein &lt;- filterFeatures(spikein, ~ isUps != \"amb\", keep = TRUE)\n\n\n\nRemove failed protein inference\nNext, we remove PSMs that could not be mapped to a protein or that map to multiple proteins, i.e. a protein group. For the latter, the protein identifier contains multiple identifiers separated by a ;). This information is readily available in the rowData, so there is no need for a custom filtering.\n\nspikein &lt;- filterFeatures(\n    spikein, ~ Protein.Accessions != \"\" & ## Remove failed protein inference\n        !grepl(\";\", Protein.Accessions)) ## Remove protein groups\n\n\n\nRemove inconsistent protein inference\nWe also remove peptide ions that map to a different protein depending on the run. Again, this requires a custom filtering and we apply the same filtering workflow as above.\n\n## 1. Collect data\nrowdata &lt;- rbindRowData(spikein, logNames)\n## 2. Compute new variable\nrowdata &lt;- data.frame(rowdata) |&gt;\n    group_by(Annotated.Sequence, Charge) |&gt;\n    mutate(nProtsMapped = length(unique(Protein.Accessions)))\n## 3. Reinsert in the rowData\nrowData(spikein) &lt;- split(rowdata, rowdata$assay)\n## 4. Apply the filter\nspikein &lt;- filterFeatures(spikein, ~ nProtsMapped == 1, keep = TRUE)\n\n\n\nRemove one-run wonders\nWe also remove proteins that can only be found in one run as such proteins may not be trustworthy. In this case,\n\n## 1. Collect data\nrowdata &lt;- rbindRowData(spikein, logNames)\n## 2. Compute new variable\nrowdata &lt;- data.frame(rowdata) |&gt;\n    group_by(Protein.Accessions) |&gt;\n    mutate(nRuns = length(unique(assay)))\n## 3. Reinsert in the rowData\nrowData(spikein) &lt;- split(rowdata, rowdata$assay)\n## 4. Apply the filter\nspikein &lt;- filterFeatures(spikein, ~ nRuns &gt; 1, keep = TRUE)\n\n\n\nRemove duplicated PSMs\nFinally, peptide ions that were identified with multiple PSMs in a run are collapsed to the PSM with the highest summed intensity over the TMT labels, a strategy that is also used by MSstats.\nThis filtering requires a more complex workflow because it mixes information from the rowData (to obtain ion identities) with quantitative data (to obtain PSM intensity ranks). We therefore compute the filtering variable for every set iteratively:\n\nGet the rowData for the current set.\nMake a new variable ionID.\nWe calculate the rowSums for each ion.\nMake a new variable psmRank that ranks the PSMs for each ion identifier based on the summed intensity.\nWe store the new information back in the rowData.\n\n\nfor (i in logNames) { ## for each set of interest\n    rowdata &lt;- rowData(spikein[[i]]) ## 1.\n    rowdata$ionID &lt;- paste0(rowdata$Annotated.Sequence, rowdata$Charge) ## 2.\n    rowdata$rowSums &lt;- rowSums(assay(spikein[[i]]), na.rm = TRUE) ## 3.\n    rowdata &lt;- data.frame(rowdata) |&gt;\n        group_by(ionID) |&gt;\n        mutate(psmRank = rank(-rowSums)) ## 4.\n    rowData(spikein[[i]]) &lt;- DataFrame(rowdata) ## 5.\n}\n\nFor each ion that maps to multiple PSMs, we keep the PSM with the highest summed intensity, that is that ranks first.\n\nspikein &lt;- filterFeatures(spikein, ~ psmRank == 1, keep = TRUE)\n\n\n\nRemove highly missing PSMs\nWe then remove PSMs with five or more missing values out of the ten TMT labels (&gt;= 50%). This is an arbitrary value that may need to be adjusted depending on the experiment and the data set.\n\nspikein &lt;- filterNA(spikein, logNames, pNA = 0.5)\n\n\n\nFiltering wrap-up\nWe have demonstrated the different procedures to perform feature filtering. Here is a summary (from simple to complex):\n\nIf you want to filter on missing values, use filterNA().\nIf you want to filter based on a rowData column, use filterFeatures().\nIf you want to filter based on information that needs to be built from rowData information, use the following workflow: i. collect the rowData in a table; ii. compute the new variable; iii. reinsert the updated table in the rowData; iv. apply the filter with filterFeatures().\nIf you want to filter based on rowData and quantitative information, iterate the following workflow over each set:\n\nGet the rowData for the current set; ii. Compute the filtering variable based on rowData and/or quantitative information; iii. store the new information back in the rowData. Then, the filtering can be performed by filterFeatures().\n\n\nWhen using filterFeatures(), specify keep = TRUE to select all features for which a custom variable is not available or has not been computed. By default, the function will remove all the feature of a set for which the information is not available.\nThese standard and custom filtering procedures have been demonstrated on PSM-level data, but the same procedures can be performed at any data level, e.g. also at peptide or protein level.\n\n\n\n2.4.5 Normalisation\nBefore performing normalisation, we explore the systematic shifts across the samples (using the pipeline described in the previous chapter). To facilitate interpretation, we facet the data by TMT mixture.\n\nspikein[, , logNames] |&gt;\n    longForm(colvars = c(\"Mixture\", \"TechRepMixture\")) |&gt;\n    data.frame() |&gt;\n    ggplot() +\n    aes(x = value, colour = as.factor(TechRepMixture), group = colname) +\n    geom_density() +\n    labs(title = \"Intensity distribution for each observational unit\",\n         subtitle = \"Before normalisation\",\n         colour = \"Technical replicate\") +\n    facet_grid(Mixture ~ .) +\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nSimilarly to the previous chapter, we again observe misalignments of the intensity distributions across samples. We see the intensity distributions cluster by technical replicate. Since each replicate contains all experimental conditions, we know that these difference stem from technical variability and not biological variability. We normalise the data by median centering.\n\nnormNames  &lt;- paste0(inputNames, \"_norm\")\nspikein &lt;- normalize(\n    spikein, logNames, name = normNames,\n    method = \"center.median\"\n)\n\nTODO think about using the Median of Ratio normalisation for tmt data.\nAnd we confirm that the normalisation resulted in a better alignment of the intensity distribution across samples.\n\nspikein[, , normNames] |&gt;\n    longForm(colvars = c(\"Mixture\", \"TechRepMixture\")) |&gt;\n    data.frame() |&gt;\n    ggplot() +\n    aes(x = value, colour = as.factor(TechRepMixture), group = colname) +\n    geom_density() +\n    labs(title = \"Intensity distribution for each observational unit\",\n         subtitle = \"Before normalisation\",\n         colour = \"Technical replicate\") +\n    facet_grid(Mixture ~ .) +\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nUp to now, the data from different runs were kept in separate assays. We can now join the normalised sets into an ions set using joinAssays(). Sets are joined by stacking the columns (samples) in a matrix and rows (features) are matched according to a row identifier, here the ionID from the rowData.\n\n(spikein &lt;- joinAssays(\n    spikein, normNames, fcol = \"ionID\", name = \"ions\"\n))\n\nAn instance of class QFeatures (type: bulk) with 46 sets:\n\n [1] Mixture1_01: SummarizedExperiment with 1719 rows and 8 columns \n [2] Mixture1_02: SummarizedExperiment with 1722 rows and 8 columns \n [3] Mixture1_03: SummarizedExperiment with 1776 rows and 8 columns \n ...\n [44] Mixture5_02_norm: SummarizedExperiment with 1646 rows and 8 columns \n [45] Mixture5_03_norm: SummarizedExperiment with 1578 rows and 8 columns \n [46] ions: SummarizedExperiment with 4066 rows and 120 columns \n\n\nWe have a new set contain 15 runs \\(\\times\\) 8 labelled sample = 120 data columns. Note that the 15 sets have 4066 ions in common, leading to a joined set with r nrows(spikein)[[\"ions\"]] rows.\nIf we want to use protein-level data for modelling, we will need a summarisation step. Note that this last step is optional.\n\n\n2.4.6 Summarisation\nWhile this chapter will focus on ion-level data modelling, modelling of protein-level data is possible upon summarisation. Below, we illustrate the challenges of summarising TMT data using one of the UPS proteins in Mixture 1 (separating the data for each technical replicate). We also focus on the 0.125x and the 1x spike-in conditions. We illustrate the different peptide ions on the x axis and plot the log2 normalised intensities across samples on y axis. All the points belonging to the same sample are linked through a grey line.\n\n\n\n\n\n\n\n\n\nWe see that the same challenges observed for LFQ data also apply to TMT data. Briefly:\n\nData for a protein can consist of many peptide ions.\nPeptide ions have different intensity baselines.\nThere is strong missingness across runs (compare points between replicates), but the missingness is mitigated within runs (compare points within replicates4).\nSubtle intensity shifts for the same peptide across different replicates, called spectrum effects, are caused by small run-to-run fluctuations.\nPresence of outliers. For instance, the first peptide ion doesn’t show the same change in intensity between conditions compared to majority of the peptides.\n\nTODO: use robust summary instead of median polish for consistency with previous vignette? I known median polish is faster, but still?\nHere, we summarise the ion-level data into protein intensities through the median polish approach, which alternately removes the peptide-ions and the sample medians from the data until the summaries stabilise. Removing the peptide-ion medians will solve issue 2. as it removes the ion-specific effects. Using the median instead of the mean will solve issue 5. Note that we perform summarisation for each run separately, hence the ion effect will be different for each run, effectively allowing for a spectrum effect and solving issue 4.\n\nsummNames &lt;- paste0(inputNames, \"_proteins\")\n(spikein &lt;- aggregateFeatures(\n    spikein, i = normNames,  name = summNames,\n    fcol = \"Protein.Accessions\", fun = MsCoreUtils::medianPolish,\n    na.rm = TRUE\n))\n\nAn instance of class QFeatures (type: bulk) with 61 sets:\n\n [1] Mixture1_01: SummarizedExperiment with 1719 rows and 8 columns \n [2] Mixture1_02: SummarizedExperiment with 1722 rows and 8 columns \n [3] Mixture1_03: SummarizedExperiment with 1776 rows and 8 columns \n ...\n [59] Mixture5_01_proteins: SummarizedExperiment with 307 rows and 8 columns \n [60] Mixture5_02_proteins: SummarizedExperiment with 296 rows and 8 columns \n [61] Mixture5_03_proteins: SummarizedExperiment with 299 rows and 8 columns \n\n\nWe can now join the different protein sets into a single set. We omit the fcol argument, meaning that the set rows will be matched based on the row names (generated by aggregateFeatures()).\n\nspikein &lt;- joinAssays( \n    spikein, summNames, \"proteins\"\n)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Advanced statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "02-advanced.html#data-exploration",
    "href": "02-advanced.html#data-exploration",
    "title": "2  Advanced statistical analysis with msqrob2",
    "section": "2.5 Data exploration",
    "text": "2.5 Data exploration\nWe perform data exploration using MDS, using the same pipeline as in the previous chapter.\n\nlibrary(\"scater\")\nse &lt;- getWithColData(spikein, \"ions\")\nse &lt;- runMDS(as(se, \"SingleCellExperiment\"), exprs_values = 1)\nplotMDS(se, colour_by = \"Condition\") +\n  plotMDS(se, colour_by = \"Run\") + \n  plotMDS(se, colour_by = \"Mixture\")\n\n\n\n\n\n\n\n\nThere is a strong run-to-run effect, which is partly explained by a mixture effect as the runs from the same mixture tend to be closer than runs from different mixtures. The condition effect is much more subtle to find, probably because we know only a few UPS proteins were spiked in while the majority of the background proteins are unchanged.\nAs discussed above, the median polish summarisation should remove part of the run to run effect. We repeat the data exploration, but using the protein-level data.\n\nse &lt;- getWithColData(spikein, \"proteins\")\nse &lt;- runMDS(as(se, \"SingleCellExperiment\"), exprs_values = 1)\nplotMDS(se, colour_by = \"Condition\") +\n  plotMDS(se, colour_by = \"Run\") + \n  plotMDS(se, colour_by = \"Mixture\")\n\n\n\n\n\n\n\n\nWhile the run effects are smaller (i.e. points within a run are more scattered than on the previous plots) on the protein-level MDS compared to the ion-level MDS (the samples are less clustered per run), we can see that normalisation and summarisation alone are not sufficient to correct for these unwanted effects. We will take care of these effects during the data modelling.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Advanced statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "02-advanced.html#sec-run_model",
    "href": "02-advanced.html#sec-run_model",
    "title": "2  Advanced statistical analysis with msqrob2",
    "section": "2.6 Data modelling",
    "text": "2.6 Data modelling\nProteomics data contain several sources of variation that need to be accounted for by the model. Before delving into these sources of variation, we here show how to run the model that accounts for all relevant sources of variation in the spike-in experiment, which we have shown performs best (Vandenbulcke et al. 2025).\n\nspikein &lt;- msqrobAggregate(\n    spikein,  i = \"ions\",\n    formula = ~ Condition + ## fixed effect for experimental condition\n        (1 | Label) + ## random effect for label\n        (1 | Mixture) + ## random effect for mixture\n        (1 | Run) + ## random effect for run\n        (1 | Run:Label) + ## random effect for PSMs for the same protein in a label of a run\n        (1 | Run:ionID), ## random effect for ions in the same spectrum of an MS run\n    fcol = \"Protein.Accessions\",\n    modelColumnName = \"msqrob_psms_rrilm\",\n    robust = TRUE, ridge = TRUE\n)\n\nWe will now build the model by progressively adding the different sources of variation.\n\n2.6.1 Effect of treatment of interest\nWe model the source of variation induced by the experimental treatment of interest as a fixed effect, which we consider non-random, i.e. the treatment effect is assumed to be the same in repeated experiments, but it is unknown and has to be estimated. When modelling a typical label-free experiment at the protein level, the model boils down to a linear model, again we suppress the index for protein:\n\\[\ny_i = \\mathbf{x}^T_i \\boldsymbol{\\beta} + \\epsilon_i,\n\\]\nwith \\(y_i\\) the \\(\\log_2\\)-normalised protein intensities in sample \\(i\\) out of \\(N\\) samples; \\(\\mathbf{x}_i\\) a vector with the covariate pattern for the sample in run \\(r\\) encoding the intercept, treatment, potential batch effects and confounders; \\(\\boldsymbol{\\beta}\\) the vector of parameters that model the association between the covariates and the outcome; and \\(\\epsilon_i\\) the residuals reflecting variation that is not captured by the fixed effects. Note that \\(\\mathbf{x}_i\\) allows for a flexible parameterisation of the treatment beyond a single covariate, i.e. including a 1 for the intercept, continuous and categorical variables as well as their interactions. For all models considered in this work, we assume the residuals to be independent and identically distributed (i.i.d) according to a normal distribution with zero mean and constant variance, i.e. \\(\\epsilon_{i} \\sim N(0,\\sigma_\\epsilon^2)\\), that can differ from protein to protein.\nWe could estimate this model from the data using msqrob() (described in the previous chapter), i.e. the model translates into the following code:\n\n# spikein &lt;- msqrob(\n#     spikein,  i = \"proteins\",\n#     formula = ~ Condition, ## fixed effect for experimental condition\n#     robust = TRUE, ridge = TRUE\n# )\n\nThis model, however, does not model all sources of variation in the experiment and relying on its results would lead to incorrect conclusions. We therefore did not run the modelling command and will expand the model.\n\n\n2.6.2 Effect of run\nAs label-free experiments contain only a single sample per run, run-specific effects will be absorbed in the residuals. However, the data analysis of multiplexed experiments involving multiple MS runs has to account for run-specific effects, explicitly. If all treatments are present in each run, then the model parameters can be estimated using fixed run effects. Indeed, for these designs run acts as a blocking variable as all treatment effects can be estimated within each run.\nHowever, for more complex designs this is no longer possible and the uncertainty in the estimation of the mean model parameters can involve both within and between run variability. For these designs we can resort to mixed models where the run effect is modelled using random effects, i.e. they are considered as a random sample from the population of all possible runs, which are assumed to be i.i.d normally distributed with mean 0 and constant variance, \\(u_{run} \\sim N(0,\\sigma^2_\\text{run})\\). The use of random effects thus models the correlation in the data, explicitly. Indeed, protein intensities that are measured within the same run will be more similar than protein intensities between runs.\nHence, the model is extended to:\n\\[\ny_{i} =\n\\mathbf{x}^T_{i} \\boldsymbol{\\beta} + u_r^\\text{run} + \\epsilon_{i}\n\\] with \\(y_{i}\\) the normalised \\(\\log_2\\) protein intensities measured in sample \\(i\\) that has been acquired in run \\(r\\) out of \\(R\\) runs, and \\(u_r^\\text{run}\\) the effect introduced by run \\(r\\).\nWe can also write the model in matrix form:\n\\[\n\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{Zu}^\\text{run} + \\boldsymbol{\\epsilon}\n\\] with \\[\n\\mathbf{Y}=\\left[\n  \\begin{array}{c} y_{1} \\\\\\vdots\\\\ y_{i} \\\\\\vdots\\\\ y_{N}\\end{array}\n\\right],\n\\mathbf{X}=\\left[\n  \\begin{array}{cccc}\n    1 & x_{1,1} & \\ldots & x_{1,P} \\\\\n    \\vdots & \\vdots & & \\vdots \\\\\n    1 & x_{i,1} & \\ldots & x_{i,P} \\\\\n    \\vdots & \\vdots & & \\vdots \\\\\n    1 & x_{N,1} & \\ldots & x_{N,P}\n  \\end{array}\n\\right],\n\\boldsymbol{\\beta}=\\left[\n  \\begin{array}{c} \\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_P \\end{array}\n\\right],\n\\mathbf{Z}=\\left[\n  \\begin{array}{ccc}z_{1,1}&\\ldots&z_{1, R}\\\\\\vdots&&\\vdots\\\\z_{N,1}&\\ldots&z_{N,R}\\end{array}\n\\right],\n\\mathbf{u}^\\text{run}=\\left[\n  \\begin{array}{c} u^\\text{run}_1 \\\\\\vdots\\\\ u^\\text{run}_{r} \\\\\\vdots\\\\ u^\\text{run}_{R}\\end{array}\n\\right]\n\\]\nHence, with the mixed model, the variance covariance matrix of the intensities becomes\n\\[\n\\begin{array}{rcl}\n\\boldsymbol{\\Sigma}_\\mathbf{Y} &=& \\text{var}\\left(\\mathbf{Y}\\right) \\\\\n&=& \\text{var}\\left(\\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{Zu} + \\boldsymbol{\\epsilon}\\right) \\\\\n&=& \\mathbf{Z}\\text{var}\\left(\\mathbf{u}\\right)\\mathbf{Z}^T + \\mathbf{I}\\sigma_\\epsilon^2\\\\\n&=& \\mathbf{Z}\\mathbf{Z}^T\\sigma^2_\\text{run} + \\mathbf{I}\\sigma_\\epsilon^2\n\\end{array}\n\\]\nSo, we see that the correlation of the data from the same run are correctly addressed and that the data from distinct runs are assumed to be independent. Hence, the variance-covariance matrix of \\(\\mathbf{Y}\\) has a block diagonal structure, with as variance \\(\\sigma^2_\\text{run} + \\sigma_\\epsilon^2\\) and the covariance between intensities from the same run equals \\(\\sigma^2_\\text{run}\\). Suppose every run contains three samples, then\n\\[\n\\boldsymbol{\\Sigma}_\\mathbf{Y} = \\left[\n\\begin{array}{cccccccccc}\\sigma^2_\\text{run}+\\sigma^2_\\epsilon&\\sigma^2_\\text{run}&\\sigma^2_\\text{run}&0&0&0&\\ldots&0&0&0\\\\\n\\sigma^2_\\text{run}&\\sigma^2_\\text{run}+\\sigma^2_\\epsilon&\\sigma^2_\\text{run}&0&0&0&\\ldots&0&0&0\\\\\n\\sigma^2_\\text{run}&\\sigma^2_\\text{run}&\\sigma^2_\\text{run}+\\sigma^2_\\epsilon&0&0&0&\\ldots&0&0&0\\\\\n0&0&0&\\sigma^2_\\text{run}+\\sigma^2_\\epsilon&\\sigma^2_\\text{run}&\\sigma^2_\\text{run}&\\ldots&0&0&0\\\\\n0&0&0&\\sigma^2_\\text{run}&\\sigma^2_\\text{run}+\\sigma^2_\\epsilon&\\sigma^2_\\text{run}&\\ldots&0&0&0\\\\\n0&0&0&\\sigma^2_\\text{run}&\\sigma^2_\\text{run}&\\sigma^2_\\text{run}+\\sigma^2_\\epsilon&\\ldots&0&0&0\\\\\n\\ldots & \\ldots & \\ldots & \\ldots & \\ldots & \\ldots & \\ldots & \\ldots & \\ldots & \\ldots \\\\\n0&0&0&0&0&0&\\dots&\\sigma^2_\\text{run}+\\sigma^2_\\epsilon&\\sigma^2_\\text{run}&\\sigma^2_u\\\\\n0&0&0&0&0&0&\\dots&\\sigma^2_\\text{run}&\\sigma^2_\\text{run}+\\sigma^2_\\epsilon&\\sigma^2_\\text{run}\\\\\n0&0&0&0&0&0&\\dots&\\sigma^2_\\text{run}&\\sigma^2_\\text{run}&\\sigma^2_\\text{run}+\\sigma^2_\\epsilon\\\\\n\\end{array}\\right]\n\\]\nThis translates in the following code:\n\n# spikein &lt;- msqrob(\n#     spikein,  i = \"proteins\",\n#     formula = ~ Condition + ## fixed effect for experimental condition\n#         (1 | Run), ## random effect for MS run\n#     robust = TRUE, ridge = TRUE\n# )\n\nThis model is still incomplete and is not executed as we still need to account that multiple samples are acquired within the same run thanks to TMT labelling.\n\n\n2.6.3 Effect of TMT label\nAcquiring multiple samples in a single run is possible because the peptides from each samples are labelled with chemical tags5. Peptide labelling can introduce label-specific effects that also need to be modelled. In principle, the effect of adding a chemical label to a peptide should be reproducible from experiment to experiment, and hence could be modelled using a fixed effect (given that TMT label swaps are performed so as to avoid confounding between label and treatment). However, TMT aliquotes contain impurities during production and these impurities may lead to unreproducible effects. Hence, we also include a random effect to account for labelling effects, i.e. \\(u^\\text{label}_l \\sim N(0, \\sigma^{2,\\text{label}})\\). The model thus extends to:\n\\[\ny_{rl} =\n\\mathbf{x}^T_{rl} \\boldsymbol{\\beta} +\nu_r^\\text{run} + u_l^\\text{label} + \\epsilon_{rlm}\n\\] with \\(y_{rl}\\) the normalised \\(\\log_2\\) protein intensities in run \\(r\\), labelled with TMT \\(l\\), \\(u_l^\\text{label}\\) the effect introduced by label \\(l\\). Note that the \\(rl\\) indexing is similar to the previous \\(i\\) indexing, but we now explicitly define the observational unit as the sample that has been measured in run \\(r\\) and labelled with label \\(l\\).\nSpecifying label as a random effect translates in the following code:\n\n# spikein &lt;- msqrob(\n#     spikein,  i = \"proteins\",\n#     formula = ~ Condition + ## fixed effect for experimental condition\n#         (1 | Run) + ## random effect for MS run\n#         (1 | Label), ## random effect for label\n#     robust = TRUE, ridge = TRUE\n# )\n\nThis model is still incomplete and is not executed as we still need to account that each mixture has been replicated three times.\n\n\n2.6.4 Effect of replication\nSome experiments also include technical replication where a TMT mixture can be acquired multiple times. This again will induce correlation. Indeed, protein intensities from the same mixture will be more alike than those of different mixtures. Hence, we also include a random effect to account for this pseudo-replication, i.e. \\(u^\\text{mix}_m \\sim N(0, \\sigma^{2,\\text{mix}})\\). The model thus extends to:\n\\[\ny_{rlm} =\n\\mathbf{x}^T_{rlm} \\boldsymbol{\\beta} +\nu_r^\\text{run} + u_l^\\text{label} + u_m^\\text{mix} + \\epsilon_{rlm}\n\\]\nwith \\(y_{rm}\\) the normalised \\(\\log_2\\) protein intensities in run \\(r\\) with label \\(l\\) in mixture \\(m\\), \\(u_m^\\text{mix}\\) the effect introduced by mixture \\(m\\).\nThe model translates to the following code:\n\nspikein &lt;- msqrob(\n    spikein,  i = \"proteins\",\n    formula = ~ Condition + ## fixed effect for experimental condition\n      (1 | Run) + ## random effect for MS run\n      (1 | Label) + ## random effect for label\n      (1 | Mixture), ## random effect for mixture\n    robust = TRUE, ridge = TRUE,\n    overwrite = TRUE\n)\n\nThis model provides a sensible representation of the sources of variation in the data if we were to model the data at the protein level. This time, we executed the code and will use the result in a later section. However, we found that modelling protein-level effects from ion-level data leads to improved performance (Vandenbulcke et al. 2025). This will require an additional model expansion.\n\n\n2.6.5 Ion-level modelling\nEstimating the treatment effect from ion-level data will again induce additional levels of correlation. Indeed, the intensities for the different reporter ions in a TMT run within the same spectrum (PSM) will be more similar than the intensities between PSMs. We therefore need to add a random effect term to account for the within PSM correlation structure, i.e. \\(u^\\text{PSM}_{rp} \\sim\nN(0,\\sigma^{2,\\text{PSM}})\\). Moreover, in each label of a run multiple PSM intensities are picked up for each protein. Hence, intensities from different PSMs for a protein in the same label of a run will be more alike than intensities of different PSMs for the same protein between labels of runs, and we will address this correlation with a label-specific random effect nested in run, i.e. \\(u_{rl}^{label} \\sim\nN(0,\\sigma^{2,\\text{label}})\\). The model then becomes:\n\\[\ny_{rlmp} =\n\\mathbf{x}^T_{rlmp} \\beta + u_r^\\text{run} + u_{l}^\\text{label} +\nu_m^\\text{mix}  +\nu_{rl}^\\text{label} + u_{rp}^\\text{PSM} + \\epsilon_{rlmp}\n\\] with \\(y_{rlmp}\\) the \\(\\log_2\\)-normalised PSM intensities for run \\(r\\) with label \\(l\\) in mixture \\(m\\) and peptide ion \\(p\\). Note, that the peptide ion random effect is also nested within each run since each spectrum is described by run-specific characteristics.\nmsqrobAggregate()enables the fitting of an ion-level model to obtain protein-level estimates. The function behaves similarly to msqrob() and shares most of the arguments. The notable difference is the fcol argument that tells the function how to group the ion-level data into protein-level data. Here, we will group ions by the Protein.Accessions. The results will be stored in a new protein-level set, which we call proteins_msqrob. msqrobAggregate() will fetch annotations from the colData (i.e. \"Condition\", \"Label\", \"Run\", \"Mixture\"), but contrarily to msqrob(), it can also fetch anntations from the rowData (i.e. \"ionID\").\n\nspikein &lt;- msqrobAggregate(\n    spikein,  i = \"ions\",\n    formula = ~ Condition + ## fixed effect for experimental condition\n        (1 | Label) + ## random effect for label\n        (1 | Run) + ## random effect for Run\n        (1 | Mixture) + ## random effect for mixture\n        (1 | Run:Label) + ## random effect for label nested in run\n        (1 | Run:ionID), ## random effect for ion nested in run\n    fcol = \"Protein.Accessions\",\n    name = \"proteins_msqrob\",\n    robust = TRUE, ridge = TRUE\n)\n\nSo, we built the model shown at the beginning of this section, effectively accounting for all sources of variation in TMT-based proteomics data.\n\n\n2.6.6 Why robust regression?\nThroughout this book, we estimate the model parameters using robust regression through M-estimation (robust = TRUE). This class of estimation does not need the assumption that the residuals \\(\\epsilon\\) are normally distributed. However, if the residuals are normal, the M-estimators have a high efficiency.\nIn ordinary least squares (OLS), the loss function that is minimised is:\n\\[\n\\sum\\limits_{i = 1}^n \\left(y_i - \\mathbf{x}_i^T \\boldsymbol{\\beta}\\right)^2\n\\]\nWhile the M-estimation minimises the following loss function:\n\\[\n\\sum\\limits_{i = 1}^n \\rho \\left(y_i - \\mathbf{x}_i^T \\boldsymbol{\\beta}\\right)\n\\]\nwhere \\(\\rho(z)\\) is a symmetric function with a minimum at \\(\\rho(0) =\n0\\) and increases as \\(|z|\\) increases. So the robust regression through M-estimation minimises the maximal bias of the estimators as the derivative of \\(\\rho\\) is bounded. A popular function for robust regression (and which is used by msqrob2) is the Huber function:\n\\[\n\\rho(e) = \\left\\{\n\\begin{array}{cl}\ne^2 / 2, & \\text{if}\\ |e| \\leq k  \\\\\nk (|e| - k/2), & \\text{if}\\ |e| \\gt k  \\\\\n\\end{array}\n\\right.\n\\] where \\(k\\) is a tuning constant (defaults to \\(k = 1.345\\))\nThe estimation is performed using iteratively reweighted least square, i.e. \n\\[\n\\sum\\limits_{i = 1}^n w_i\\left(y_i - \\mathbf{x}_i^T \\boldsymbol{\\beta}\\right)^2\n\\] where the weigths \\(w_i\\) for each iteration are defined for each data point using the function :\n\\[\nw(e) = \\left\\{\n\\begin{array}{cl}\n1, & \\text{if}\\ |e| \\leq k  \\\\\n\\frac{k}{|e|}, & \\text{if}\\ |e| \\gt k  \\\\\n\\end{array}\n\\right.\n\\]\nIntuitively, observations for which the fitting error (absolute residual) is smaller than the constant \\(k\\) will contribute contribute to the fitting as for the OLS, while the contribution of the remaining observations will decrease linearly as the error exceeds \\(k\\). This means that a strong outlier, i.e. an observation for which the fitting error is large, will barely contribute to the fit. Since the last iteration upon covergence is still a weighted least square estimation, we can use the same statistical testing framework as for OLS, although the tests and confidence intervals are based on asymptotic theory.\nNote, that robust regression also extends to linear mixed models, by adopting weighted maximum likelihood e.g. TODO ref https://www.tandfonline.com/doi/abs/10.1080/03610920802677216.\n\n\n2.6.7 Why ridge regression?\nmsqrob2 also allows for ridge regression (when ridge = TRUE). In ridge regression, model parameters are estimated by minimising a penalised version of the OLS loss:\n\\[\n\\sum\\limits_{i = 1}^n \\left(y_i - \\mathbf{x}_i^T \\boldsymbol{\\beta}\\right)^2 + \\lambda \\boldsymbol{\\beta}^T\\mathbf{D}\\boldsymbol{\\beta},\n\\] with \\(\\mathbf{D}\\) a diagonal matrix that include a 1 on the diagonal elements for the model parameters that are penalised and a 0 otherwise.\nNote, that in msqrob2 we leave the intercept \\(\\beta_0\\) unpenalised so the first diagonal element of \\(\\mathbf{D}\\) is set at zero and we only penalise the remaining \\(m-1\\) slope parameters \\(\\boldsymbol{\\beta}_s=[\\beta_1 \\ldots \\beta_{m-1}]^T\\). Hence, \\(\\boldsymbol{\\beta}^T\\mathbf{D}\\boldsymbol{\\beta}\\) reduces to the squared L2 norm of \\(\\boldsymbol{\\beta}_s\\), i.e. \\(||\\boldsymbol{\\beta}_s||_2^2 =\n\\sum\\limits_{j = 1}^{m-1} \\beta_j^2\\).\nDue to the penality term in the loss function, the estimates of penalised slope terms \\(\\boldsymbol{\\beta}_s\\) will be shrunken towards zero, especially for irrelevant covariates in \\(\\mathbf{X}\\). In other words, the parameters are stabilised by reducing the variance of the estimation, which prevents overfitting. Note, that the penalty term in the loss function thus implies that the estimates of \\(\\boldsymbol{\\beta}\\) will be biased towards zero. This is known as the variance-bias trade-off. In our experience, msqrob’s ridge regression mainly shrinks the log2-fold change estimates (\\(\\beta\\)) for features with low evidence for differential abundance to zero while leaving those for features with high evidence for differential abundance largely unaltered.\nInterestingly, there exists a link between Bayesian regression, ridge regression and mixed models, i.e. the ridge regression can be adopted by placing a normal prior on the slope terms that have to be penalised, i.e. \\(\\beta_j \\sim N(0,\\sigma_\\beta^2)\\) for \\(j= 1 \\ldots m-1\\). It can than be shown that the best linear unbiased predictor from the linear mixed model with the slope terms defined as random effects provides the ridge regression estimates with a ridge penalty \\(\\lambda = \\hat{\\sigma}^2_\\epsilon/\\hat{\\sigma}^2_\\beta\\)). Hence, mixed model software can be used to tune the ridge penalty in a data driven way. Note, that this comes at price of increased computational complexity. msqrob2 estimation with ridge regression will thus be slower than without ridge regression.\nAlso note, that ridge regression cannot be performed when \\(\\mathbf{X}\\) contains an intercept and a single covariate. Indeed, based on a single slope term the random effect variance \\(\\sigma^2_\\beta\\) cannot be estimated. We demonstrate this by intentionally triggering an error after subsetting only spike-in condition 1 and 0.5.\n\nspikeinSubset &lt;- subsetByColData(spikein, spikein$Condition %in% c(\"1\", \"0.5\"))\ntry(msqrobAggregate(\n  spikeinSubset,  i = \"ions\",\n  formula = ~  Condition + ## fixed effect for experimental condition\n    (1 | Label) + ## random effect for label\n    (1 | Run) + ## random effect for Run\n    (1 | Mixture) + ## random effect for mixture\n    (1 | Run:Label) + ## random effect for label nested in run\n    (1 | Run:ionID), ## random effect for ion nested in run\n  fcol = \"Protein.Accessions\",\n  name = \"proteins_msqrob\",\n  robust = TRUE, ridge = TRUE\n))\n\nError : BiocParallel errors\n  1 remote errors, element index: 1\n  406 unevaluated and other errors\n  first remote error:\nError in (function (y, rowdata = NULL, formula, coldata, doQR, robust, : The mean model must have more than two parameters for ridge regression.\n              if you really want to adopt ridge regression when your factor has only two levels\n              rerun the function with a formula where you drop the intercept. e.g. ~-1+condition\n            \n\n\nAs the error message suggests, either the ridge argument has to be set at FALSE to obtain an unpenalised fit, or the intercept can be suppressed in order to obtain a fit with two slope terms (one for each group) so as to enable the estimation of the ridge penalty.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Advanced statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "02-advanced.html#statistical-inference",
    "href": "02-advanced.html#statistical-inference",
    "title": "2  Advanced statistical analysis with msqrob2",
    "section": "2.7 Statistical inference",
    "text": "2.7 Statistical inference\nWe can now convert the biological question “does the spike-in condition affect the protein intensities?” into a statistical hypothesis. In other words, we need to translate this question in a null and alternative hypothesis on a single model parameter or a linear combination of model parameters, which is also referred to with a contrast. We plot an overview of the model parameters.\n\nlibrary(\"ExploreModelMatrix\")\nvd &lt;- VisualizeDesign(\n    sampleData =  colData(spikein),\n    designFormula = ~ Condition,\n    textSizeFitted = 4\n)\nvd$plotlist\n\n[[1]]\n\n\n\n\n\n\n\n\n\nNote that with ExploreModelMatrix we can only visualise fixed effects part of the model. This is fine as the mean protein abundances can only systematically differ from each other according to the Condition (fixed effect).\n\n2.7.1 Hypothesis testing\nThe average difference in the log2-intensity between the 1x and the 0.5x conditions is provided by the contrast ridgeCondition1 - ridgeCondition0.5. This is, however, not the only difference we could assess. As described in the previous chapter, we will generate a contrast matrix that assess all possible pairwise comparisons between spike-in conditions.\n\nallHypotheses &lt;- createPairwiseContrasts(\n  ~ Condition, colData(spikein), \"Condition\", ridge = TRUE\n)\nL &lt;- makeContrast(\n  allHypotheses,\n  parameterNames = paste0(\"ridgeCondition\", c(\"0.5\", \"0.667\", \"1\"))\n)\n\nWe test our null hypotheses using hypothesisTest() and the estimated ion-level model stored in proteins_msqrob.\n\nspikein &lt;- hypothesisTest(spikein, i = \"proteins_msqrob\", contrast = L)\ninferences &lt;- rowData(spikein[[\"proteins_msqrob\"]])[, colnames(L)]\n\nWe can retrieve the results for the comparison between the 1x and the 0.5x conditions.\n\nhead(inferences$\"ridgeCondition1 - ridgeCondition0.5\")\n\n               logFC           se         df             t        pval\nO00151 -2.549859e-02 2.153969e-02  471.97751 -1.183796e+00 0.237089769\nO00220  1.440133e-02 5.774331e-02   94.45995  2.494026e-01 0.803590901\nO00244 -3.706545e-10 5.416412e-06   84.16092 -6.843175e-05 0.999945561\nO00299 -3.154427e-02 1.172633e-02 1380.19537 -2.690038e+00 0.007230547\nO00330 -2.881986e-02 3.682363e-02  193.93129 -7.826456e-01 0.434789869\nO00399            NA           NA         NA            NA          NA\n          adjPval\nO00151 0.58896109\nO00220 1.00000000\nO00244 1.00000000\nO00299 0.03771935\nO00330 0.87236685\nO00399         NA\n\n\nThe last row is filled with missing values because data modelling resulted in a fitError (we will explore in a later section how we can deal with proteins that could not be fit).\n\n\n2.7.2 Volcano plots\nWe generate volcano plots for all pairwise comparison between conditions. First, we add new columns to the tables and join them in a single table.\n\ninferences &lt;- lapply(colnames(inferences), function(i) {\n  inference &lt;- inferences[[i]]\n  inference$Protein &lt;- rownames(inference)\n  inference$isUps &lt;- grepl(\"ups\", inference$Protein)\n  inference$Comparison &lt;- gsub(\"ridgeCondition\", \"\", i)\n  inference$Comparison &lt;- gsub(\"^([0-9.]*)$\", \"\\\\1 - 0.125\", inference$Comparison)\n  inference\n})\ninferences &lt;- do.call(rbind, inferences) ## combine in a single table\n\nThen, we plot the volcano plots with each comparison in a separate facet.\n\nggplot(inferences) +\n    aes(x = logFC,\n        y = -log10(pval),\n        color = isUps,\n        shape = adjPval &lt; 0.05) +\n    geom_point() +\n    scale_color_manual(\n      values = c(\"grey20\", \"firebrick\"), name = \"\",\n      labels = c(\"HeLA background\", \"UPS standard\")\n    ) +\n    facet_wrap(~ Comparison, scales = \"free\") +\n    ggtitle(\"Statistical inference for all pairwise comparisons\") \n\n\n\n\n\n\n\n\n\n\n2.7.3 Fold change distributions\nAs this is a spike-in study with known ground truth, we can also plot the log2 fold change distributions against the expected values, in this case 0 for the HeLa proteins and the difference of the log concentration for the spiked-in UPS standards. We first create a small table with the real values.\n\nrealLogFC &lt;- data.frame(Comparison = unique(inferences$Comparison))\nrealLogFC$logFC &lt;- paste0(\"log2(\", gsub(\"-\", \"/\", realLogFC$Comparison), \")\") |&gt; \n  sapply(function(x) eval(parse(text = x)))\n\nWe can now create the boxplots with the estimated log2-fold changes, adding horizontal lines with the corresponding target values.\n\nggplot(inferences) +\n    aes(y = logFC,\n        x = isUps,\n        colour = isUps) +\n    geom_boxplot() +\n  \n    scale_color_manual(\n        values = c(\"grey20\", \"firebrick\"), name = \"\",\n        labels = c(\"HeLA background\", \"UPS standard\")\n    ) +\n    geom_hline(data = realLogFC, aes(yintercept = logFC), \n               colour = \"firebrick\") +\n    geom_hline(yintercept = 0) +\n    facet_wrap(~ Comparison) +\n    ggtitle(\"Distribution of the log2 fold changes\")\n\n\n\n\n\n\n\n\nEstimated log2 fold change for HeLa proteins are closely distributed around 0, as expected. log2 fold changes for UPS standard proteins are biased towards zero probably due to ratio compression effects, as reported previously for labeled strategies (Savitski et al. 2011).\n\n\n2.7.4 Detail plots\nWe can explore the PSM intensities for a protein to validate the statistical inference results. For example, let’s explore the intensities for the protein with the most significant difference.\n\n(targetProtein &lt;- inferences$Protein[which.min(inferences$adjPval)])\n\n[1] \"P02788ups\"\n\n\nTo obtain the required data, we perform a data manipulation pipeline. We plot the log2 normalised intensities for each sample. Since the protein is modelled at the peptide ion level, multiple ion intensities are recorded in each sample. Each ion is linked across samples using a grey line. Samples are colored according to UPS spike-in condition. Finally, we split the plot in facets, one for each mixture, to visualise the heterogeneity induced by sample preparation.\n\nspikein[targetProtein, , \"ions\"] |&gt;\n    longForm(colvars = colnames(colData(spikein)),\n             rowvars = c(\"Protein.Accessions\", \"ionID\")) |&gt;\n    data.frame() |&gt;\n    ## We reorder the sample identifiers to improve visualisation\n    mutate(colname = factor(colname, levels = unique(colname[order(Condition)]))) |&gt; \n    ggplot() +\n    aes(x = colname,\n        y = value) +\n    geom_line(aes(group = ionID), linewidth = 0.1) +\n    geom_point(aes(colour = Condition)) +\n    facet_grid(~ Mixture, scales = \"free\") +\n    ggtitle(targetProtein) +\n    theme_minimal() +\n    theme(axis.text.x = element_blank())",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Advanced statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "02-advanced.html#protein-level-inference",
    "href": "02-advanced.html#protein-level-inference",
    "title": "2  Advanced statistical analysis with msqrob2",
    "section": "2.8 Protein-level inference",
    "text": "2.8 Protein-level inference\nWe here show how to perform a two-step approach, where the data are first summarised then modelled. We perform the same statistical workflow as above, but starting from the protein level model estimated in the section above6.\n\nspikein &lt;- hypothesisTest(spikein, i = \"proteins\", contrast = L)\ninferences &lt;- rowData(spikein[[\"proteins\"]])[, colnames(L)]\n\nWe build the volcano using the same code as above:\n\ninferences &lt;- lapply(colnames(inferences), function(i) {\n  inference &lt;- inferences[[i]]\n  inference$Protein &lt;- rownames(inference)\n  inference$isUps &lt;- grepl(\"ups\", inference$Protein)\n  inference$Comparison &lt;- gsub(\"ridgeCondition\", \"\", i)\n  inference\n})\ninferences &lt;- do.call(rbind, inferences) ## combine in a single table\nggplot(inferences) +\n    aes(x = logFC,\n        y = -log10(pval),\n        color = isUps) +\n    geom_point() +\n    geom_hline(yintercept = -log10(0.05)) +\n    scale_color_manual(\n      values = c(\"grey20\", \"firebrick\"), name = \"\",\n      labels = c(\"HeLA background\", \"UPS standard\")\n    ) +\n    facet_wrap(~ Comparison, scales = \"free\") +\n    ggtitle(\"Statistical inference for all pairwise comparisons\",\n            subtitle = \"Protein-level modelling\") \n\n\n\n\n\n\n\n\nWe plot the fold change distributions:\n\nggplot(inferences) +\n    aes(y = logFC,\n        x = isUps,\n        colour = isUps) +\n    geom_boxplot() +\n    geom_point( ## Adding the expected Log2 fold changes \n        data = group_by(inferences, Comparison, isUps) |&gt; \n          summarise(logFC = ifelse(isUps, log2(eval(parse(text = sub(\"-\", \"/\", Comparison)))), 0)),\n        shape = 10, size = 4\n    ) +\n    scale_color_manual(\n        values = c(\"grey20\", \"firebrick\"), name = \"\",\n        labels = c(\"HeLA background\", \"UPS standard\")\n    ) +\n    facet_wrap(~ Comparison) +\n    ggtitle(\"Distribution of the log2 fold changes\",\n            subtitle = \"Protein-level modelling\") \n\n\n\n\n\n\n\n\nExploring the intensities at the protein level is simplified compared to PSM-level exploration since every sample now contains a single observation, the protein intensity.\n\nspikein[targetProtein, , \"proteins\"] |&gt;\n    longForm(colvars = colnames(colData(spikein))) |&gt;\n    data.frame() |&gt;\n    ## We reorder the sample identifiers to improve visualisation\n    mutate(colname = factor(colname, levels = unique(colname[order(Condition)]))) |&gt; \n    ggplot() +\n    aes(x = colname,\n        y = value) +\n    geom_point(aes(colour = Condition)) +\n    facet_grid(~ Mixture, scales = \"free\") +\n    ggtitle(targetProtein,\n            subtitle = \"Summarised protein data\") +\n    theme_minimal() +\n    theme(axis.text.x = element_blank())\n\n\n\n\n\n\n\n\nNotice how the summarisation-based approach hides the variation associated with the measurement of different peptide ions within the same protein, as well as discrepancies between peptide identification rates across mixtures.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Advanced statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "02-advanced.html#dealing-with-fiterrors",
    "href": "02-advanced.html#dealing-with-fiterrors",
    "title": "2  Advanced statistical analysis with msqrob2",
    "section": "2.9 Dealing with fitErrors",
    "text": "2.9 Dealing with fitErrors\nMissing value patterns in the data may lead to non-estimable parameters. This is recognised by msqrob2 and will lead to fitErrors which is a type of model output where the model could not be fit. This information is available from the StatModel objects.\n\nrowData(spikein[[\"proteins_msqrob\"]])[[\"msqrobModels\"]] |&gt;\n    sapply(function(x) x@type) |&gt;\n    table()\n\n\nfitError     lmer \n      94      313 \n\n\nThere are 3 possible strategies for dealing with these fitErrors.\n\n2.9.1 Removing the random effect of sample\nThis strategy only applies for PSM-level models. Some proteins are difficult to detect and may be quantified by a single peptide ion species. In these cases, every sample contains a single observation for the protein and hence no random effect of Run:Label can be estimated. While the results for such one-hit wonders are questionable, we provide msqrobRefit() to refit a new model for a subset of proteins of interest.\nIn this case, we want to refit a model without a sample effect for one-hit-wonder proteins. This information can be retrieved from the aggregation results, using aggcounts(). This getter function provides the number of features used when performing summarisation for each protein in each sample.\n\ncounts &lt;- aggcounts(spikein[[\"proteins_msqrob\"]])\ncounts[1:5, 1:5]\n\n       161117_SILAC_HeLa_UPS1_TMT10_Mixture1_01.raw_Abundance..127N\nO00151                                                            4\nO00220                                                            1\nO00244                                                            0\nO00299                                                           15\nO00330                                                            2\n       161117_SILAC_HeLa_UPS1_TMT10_Mixture1_01.raw_Abundance..127C\nO00151                                                            4\nO00220                                                            2\nO00244                                                            0\nO00299                                                           15\nO00330                                                            2\n       161117_SILAC_HeLa_UPS1_TMT10_Mixture1_01.raw_Abundance..128N\nO00151                                                            4\nO00220                                                            2\nO00244                                                            0\nO00299                                                           15\nO00330                                                            2\n       161117_SILAC_HeLa_UPS1_TMT10_Mixture1_01.raw_Abundance..128C\nO00151                                                            4\nO00220                                                            1\nO00244                                                            0\nO00299                                                           15\nO00330                                                            2\n       161117_SILAC_HeLa_UPS1_TMT10_Mixture1_01.raw_Abundance..129N\nO00151                                                            4\nO00220                                                            2\nO00244                                                            0\nO00299                                                           15\nO00330                                                            2\n\n\nOne-hit wonder proteins are proteins for which the number of feature used for summarisation does not exceed 1 peptide ion across samples.\n\noneHitProteins &lt;- rownames(counts)[rowMax(counts) == 1]\n\nUsing msqrobRefit() is very similar to msqrobAggregate(), see here however that we adapted the formula to remove the random effect for label nested within run. We also mention which proteins must be refit using the subset argument.\nTODO: include msqrobRefit in msqrob2.\n\nspikein &lt;- msqrobRefit(\n    spikein, i = \"ions\",\n    subset = oneHitProteins,\n    formula = ~ Condition + ## fixed effect for experimental condition\n        (1 | Label) + ## fixed effect for label\n        (1 | Mixture) + ## random effect for mixture\n        (1 | Run ) + ## random effect for run\n        (1 | Run:ionID), ## random effect for PSM nested in MS run\n        ## random effect for label nested in run has been removed\n    fcol = \"Protein.Accessions\",\n    name = \"proteins_msqrob\",\n    robust = TRUE, ridge = TRUE\n)\n\nLet’s see how removing the random effect of label within run for one-hit-wonder proteins reduced the number of fitErrors.\n\nfitTypes &lt;- rowData(spikein[[\"proteins_msqrob\"]])[[\"msqrobModels\"]] |&gt;\n    sapply(function(x) x@type)\ntable(fitTypes)\n\nfitTypes\nfitError     lmer \n       1      406 \n\n\n\n\n2.9.2 Manual inspection\nOne protein is still non-estimable upon refitting and requires additional data exploration to understand why the model cannot be estimated. Let us take the protein that cannot be fitted.\n\nproteinError &lt;- names(fitTypes[fitTypes == \"fitError\"])[[1]]\n\nTo understand the problem, we plot the data for that protein using the same QFeatures pipeline described above. We here plot the data in function of the Label (x-axis), Condition (colour) and Mixture (shape).\n\nspikein[proteinError, , \"ions\"] |&gt;\n    longForm(colvars = colnames(colData(spikein)),\n               rowvars = c(\"Protein.Accessions\", \"ionID\")) |&gt;\n    data.frame() |&gt;\n    mutate(colname = factor(colname, levels = unique(colname[order(Condition)]))) |&gt; \n    ggplot() +\n    aes(x = colname,\n        y = value) +\n    geom_point(aes(colour = Condition)) +\n    facet_grid(~ Mixture, scales = \"free\") +\n    ggtitle(targetProtein) +\n    theme_minimal() +\n    theme(axis.text.x = element_blank())\n\n\n\n\n\n\n\n\nWe can immediately spot that PSM intensities are only present in mixture 3. Hence, the mixed model cannot be fitted with a random effect for mixture. However, we don’t want to rely on a result that has been measured in a single replicate and msqrob2 flags these problematic proteins instead of defining ad-hoc heuristics, avoiding potentially misleading conclusions.\n\n\n2.9.3 Imputation\nThe last popular strategy to deal with fit errors is to impute missing values so that all models can be estimated. Note, that our general advice is to avoid imputation as this typically comes at the expense of additional and often unrealistic assumptions7.\nQFeatures provides a large panel of imputation strategies through impute(). Identifying which imputation strategy is most suited for this data set is outside the scope of this book. For illustration purposes, we here arbitrarily use KNN imputation.\n\n(spikein &lt;- impute(\n    spikein, i = \"ions\", name = \"ions_imputed\",\n    method = \"knn\", colmax = 1\n))\n\nAn instance of class QFeatures (type: bulk) with 64 sets:\n\n [1] Mixture1_01: SummarizedExperiment with 1719 rows and 8 columns \n [2] Mixture1_02: SummarizedExperiment with 1722 rows and 8 columns \n [3] Mixture1_03: SummarizedExperiment with 1776 rows and 8 columns \n ...\n [62] proteins: SummarizedExperiment with 407 rows and 120 columns \n [63] proteins_msqrob: SummarizedExperiment with 407 rows and 120 columns \n [64] ions_imputed: SummarizedExperiment with 4066 rows and 120 columns \n\n\nThe function added a new set ions_imputed which we can use to fit the ion-level model.\n\nspikein &lt;- msqrobAggregate(\n    spikein,  i = \"ions_imputed\",\n    formula = ~ Condition + ## fixed effect for experimental condition\n        (1 | Label) + ## random effect for label\n        (1 | Mixture) + ## random effect for mixture\n        (1 | Run) + ## random effect for run\n        (1 | Run:Label) + ## random effect for PSMs from the same protein in a label of a run\n        (1 | Run:ionID), ## random effect for ions in the same spectrum of an MS run\n    fcol = \"Protein.Accessions\",\n    modelColumnName = \"msqrob_psm_rrilmm\",\n    name = \"proteins_msqrob_imputed\",\n    robust = TRUE, ridge = TRUE\n)\n\nWe here assess how many models have been estimated for all proteins upon imputation.\n\nrowData(spikein[[\"proteins_msqrob_imputed\"]])[[\"msqrob_psm_rrilmm\"]] |&gt;\n    sapply(function(x) x@type) |&gt;\n    table()\n\n\nfitError     lmer \n      59      348 \n\n\nAgain fitErrors were generated for one-hit-wonder proteins.\n\ncounts &lt;- aggcounts(spikein[[\"proteins_msqrob_imputed\"]])\noneHitProteins &lt;- rownames(counts)[rowMax(counts) == 1]\nspikein &lt;- msqrobRefit(\n    spikein, i = \"ions_imputed\",\n    subset = oneHitProteins,\n    formula = ~ Condition + ## fixed effect for experimental condition\n        (1 | Label) + ## random effect for label\n        (1 | Mixture) + ## random effect for mixture\n        (1 | Run ) + ## random effect for run\n        (1 | Run:ionID), ## random effect for PSM nested in MS run\n        ## random effect for label nested in run has been removed\n    fcol = \"Protein.Accessions\",\n    modelColumnName = \"msqrob_psm_rrilmm\",\n    name = \"proteins_msqrob_imputed\",\n    robust = TRUE, ridge = TRUE\n)\nrowData(spikein[[\"proteins_msqrob_imputed\"]])[[\"msqrob_psm_rrilmm\"]] |&gt;\n    sapply(function(x) x@type) |&gt;\n    table()\n\n\nlmer \n 407 \n\n\nUpon refit, no fitErrors were generated for any proteins, as expected. Be mindful that the results upon imputation will be highly depended on the suitability of the imputation approach.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Advanced statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "02-advanced.html#conclusion",
    "href": "02-advanced.html#conclusion",
    "title": "2  Advanced statistical analysis with msqrob2",
    "section": "2.10 Conclusion",
    "text": "2.10 Conclusion\nIn this chapter, we expanded upon the basic concepts with a more complex analysis. First, we started our analysis from PSM-level data, showing that our tools are amenable to read different levels of input format such as the peptides table or the PSM table. Starting from the PSM level data also enabled better control of the PSM filtering compared to starting with peptide-level data. We demonstrated how to conduct a comprehensive feature filtering workflow, with different level of customisation to enable filtering based on any criterion.\nThe complexity of the analysis is the reflection of the complexity of the experimental designs, as TMT-labelling includes the modelling of several additional sources of variation compared to LFQ experiments: effect of treatment of interest, effect of TMT labelling, effect of the MS acquisition run, and the effect of replication. We built protein-level models, but we have also shown that we can build PSM-level models if we also include a spectrum effect and an effect for TMT label nested within run.\nFinally, we have demonstrated how to deal with proteins that cannot be modelled due to missing values. For PSM-level models, we can remove the random effects for TMT label within run that cannot be estimated for one-hit-wonder proteins. We can also manually inspect how missing values can influence the model design, and refit a simplified model upon expert’s intervention. Finally, we can impute missing values, which unlocks model fitting, but imposes strong assumption on the validity of the imputation approach and the reliability of the predicted values.\n\n\n\n\nHuang, Ting, Meena Choi, Manuel Tzouros, Sabrina Golling, Nikhil Janak Pandya, Balazs Banfai, Tom Dunkley, and Olga Vitek. 2020. “MSstatsTMT: Statistical Detection of Differentially Abundant Proteins in Experiments with Isobaric Labeling and Multiple Mixtures.” Mol. Cell. Proteomics 19 (10): 1706–23.\n\n\nSavitski, Mikhail M, Gavain Sweetman, Manor Askenazi, Jarrod A Marto, Manja Lang, Nico Zinn, and Marcus Bantscheff. 2011. “Delayed Fragmentation and Optimized Isolation Width Settings for Improvement of Protein Identification and Accuracy of Isobaric Mass Tag Quantification on Orbitrap-Type Mass Spectrometers.” Anal. Chem. 83 (23): 8959–67.\n\n\nSticker, Adriaan, Ludger Goeminne, Lennart Martens, and Lieven Clement. 2020. “Robust Summarization and Inference in Proteome-Wide Label-Free Quantification.” Mol. Cell. Proteomics 19 (7): 1209–19.\n\n\nVandenbulcke, Stijn, Christophe Vanderaa, Oliver Crook, Lennart Martens, and Lieven Clement. 2025. “Msqrob2TMT: Robust Linear Mixed Models for Inferring Differential Abundant Proteins in Labeled Experiments with Arbitrarily Complex Design.” Mol. Cell. Proteomics 24 (7): 101002.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Advanced statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "02-advanced.html#footnotes",
    "href": "02-advanced.html#footnotes",
    "title": "2  Advanced statistical analysis with msqrob2",
    "section": "",
    "text": "Depending on the reagents used, 6, 10, 11 up to 18 samples can be pooled in one mixture↩︎\nYou will be prompted to create a new folder the first time you use the package.↩︎\nYou can find an illustrated step-by-step guide in the QFeatures vignette↩︎\nNote that the data points from one peptide ion in one replicate has been extracted from a single MS2 spectrum.↩︎\nRecall the section above).↩︎\nNote that the contrasts remain the same, as the fixed effect part of the model (spike-in treatment effect)is the same for the models estimated with msqrob() or msqrobAggregate(), so we do not need to build a new contrast matrix.↩︎\nIndeed, we have shown that state-of-the-art imputation methods profoundly change the distribution of the intensities in bulk proteomics, which can have a detrimental impact on the downstream analysis. Our take is to start from the ion or peptide intensity data as is and to model the data from the same protein together while correcting for ion/peptide species. These ion/peptide-level models can either be used to directly infer differential abundance at the protein level or to obtain protein-level abundance values in the summarisation step. Note, that this approach assumes random missingness upon correction for ion/peptide species.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Advanced statistical analysis with msqrob2</span>"
    ]
  },
  {
    "objectID": "03-benchmarking.html",
    "href": "03-benchmarking.html",
    "title": "3  Benchmarking workflows",
    "section": "",
    "text": "3.1 Load packages\nIn the previous chapters we have seen three different approaches to model the data:\nThere are further possible approaches to model the data:\nIn this chapter, we will attempt to understand whether these different approaches lead to difference in modelling performance. To explore these differences, we will conduct a benchmarking experiment using the E. coli spike-in experiment, containing ground truth information that will be used for an objective comparison of the workflows.\nImportant: the first sections of the chapter are meant for advanced users that are familiar with R scripting since benchmarking requires some degree of automation. However, for novice users interested in the key messages of the benchmarking and that want to implement the best practices, we refer to the take home message section for more accessible guidelines.\nWe load the msqrob2 package, along with additional packages for data manipulation and visualisation.\nlibrary(\"msqrob2\")\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"data.table\")\nlibrary(\"ggplot2\")\nlibrary(\"patchwork\")\nTODO: move some functions from utils.R to msqrob2, eg msqrobCollect, pairwise contrasts\nWe also configure the parallelisation framework.\nlibrary(\"BiocParallel\")\nregister(SerialParam())",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Benchmarking workflows</span>"
    ]
  },
  {
    "objectID": "03-benchmarking.html#data",
    "href": "03-benchmarking.html#data",
    "title": "3  Benchmarking workflows",
    "section": "3.2 Data",
    "text": "3.2 Data\nWe will reuse the data by (Shen et al. 2018) as in Chapter 1. The data were reanalysed using MaxQuant, which generates results at three levels: the evidence file containing the PSM table, the peptides file, and the protein group file.\n\n3.2.1 Data files\nWe here retrieve those three data files.\nTODO: put data on Zenodo or MsDataHub, and update code below\n\nlibrary(\"MsDataHub\")\n# myurl &lt;- \"https://github.com/statOmics/MSqRobSumPaper/raw/refs/heads/master/spikein/data/maxquant/peptides.zip\"\n# download.file(myurl,\"data/sticker2020/peptides.zip\", method = \"curl\", extra = \"-L\")\n# unzip(\"data/sticker2020/peptides.zip\", exdir = \"data/sticker2020/\")\n# myurl &lt;- \"https://github.com/statOmics/MSqRobSumPaper/raw/refs/heads/master/spikein/data/maxquant/evidence.zip\"\n# download.file(myurl,\"data/sticker2020/evidence.zip\", method = \"curl\", extra = \"-L\")\n# unzip(\"data/sticker2020/evidence.zip\", exdir = \"data/sticker2020/\")\n# myurl &lt;- \"https://github.com/statOmics/MSqRobSumPaper/raw/refs/heads/master/spikein/data/maxquant/proteinGroups.zip\"\n# download.file(myurl,\"data/sticker2020/proteinGroups.zip\", method = \"curl\", extra = \"-L\")\n# unzip(\"data/sticker2020/proteinGroups.zip\", exdir = \"data/sticker2020/\")\nevidenceFile &lt;- \"data/sticker2020/evidence.txt\"\npeptidesFile &lt;- \"data/sticker2020/peptides.txt\"\nproteinGroupsFile &lt;- \"data/sticker2020/proteinGroups.txt\"\n\nWe also load the annotation table) that has been generated by the authors. Since the evidence, peptides and protein-groups tables all contain the same samples, the annotation table will be shared across the MaxQuant data tables.\n\nannotFile &lt;- \"data/sticker2020/sticker2020_annotation.csv\"\ncoldata &lt;- read.csv(annotFile)\n\nWe retrieve all the E. coli protein identifiers to later identify which proteins are known to be differentially abundant (E. coli proteins) or constant (human) across condition.\n\nlibrary(\"BiocFileCache\")\nbfc &lt;- BiocFileCache()\necoli &lt;- bfcrpath(bfc, \"https://raw.githubusercontent.com/statOmics/MSqRobSumPaper/refs/heads/master/spikein/data/fasta/ecoli_up000000625_7_06_2018.fasta\")\necoli &lt;- readLines(ecoli)\necoli &lt;- ecoli[grepl(\"^&gt;\", ecoli)]\necoli &lt;- gsub(\"&gt;sp\\\\|(.*)\\\\|.*\", \"\\\\1\", ecoli)\n\n\n\n3.2.2 Convert to QFeatures\nWe combine each MaxQuant file with the annotation table into a QFeatures object.\n\nLoad and convert the evidence table.\n\n\nevidence &lt;- fread(evidenceFile, check.names = TRUE)\ncoldata$runCol &lt;- coldata$Raw.file\nevidence &lt;- readQFeatures(\n    evidence, colData = coldata, runCol = \"Raw.file\", \n    quantCols = \"Intensity\"\n)\n\n\nLoad and convert the peptide table.\n\n\npeptides &lt;- read.delim(peptidesFile)\ncoldata$quantCols &lt;- paste0(\"Intensity.\", coldata$Sample)\npeptides &lt;- readQFeatures(\n    peptides, colData = coldata, name = \"peptides\", \n    fnames = \"Sequence\"\n)\n\n\nLoad and convert the protein-groups table\n\n\nproteinGroups &lt;- read.delim(proteinGroupsFile)\nproteinGroups &lt;- readQFeatures(\n    proteinGroups, colData = coldata, name = \"proteinGroups\",\n    fnames = \"Protein.IDs\"\n)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Benchmarking workflows</span>"
    ]
  },
  {
    "objectID": "03-benchmarking.html#data-preprocessing",
    "href": "03-benchmarking.html#data-preprocessing",
    "title": "3  Benchmarking workflows",
    "section": "3.3 Data preprocessing",
    "text": "3.3 Data preprocessing\nTo exclude differences in data processing between the different data files, we will create a common data processing workflow in a dedicated function1.\n\n3.3.1 Preprocessing workflow\nWe will use the same QFeatures data preprocessing workflow as presented in the basic concepts chapter starting from the peptides table. However, we will account for the increased complexity in filtering when starting from PSM-level tables, where we need to exclude PSM mapping to multiple ions (as explained in the advanced concepts chapter). Conversely, the protein group table (containing LFQ normalised data) already underwent several data processing steps that will be ignored. We also need to provide the correct protein identifiers across data levels. We will use the Proteins column for the PSM-level and the peptide-level data, while we will use the Protein.IDs for the protein-group-level data.\nHere is an overview of the data processing workflow:\n\nEncode missing values with NA\nPerform log2-transformation\n(Only for PSM-level data) Remove duplicated PSMs for each ion and join the data from different runs, effectively leading to ion-level data.\n(Only for protein-level data) Rename Protein.IDs to Protein for consistent protein identifier column name.\nFilter features by removing failed protein inference and removing decoys and contaminants.\nFilter missing values, keeping features that are observed in at least 4 samples. This is the last step for the workflow starting from protein group data, because maxLFQ values are already normalised and summarised to protein values.\nPerform normalisation.\nPerform summarisation. The summarised values will only be used for protein-level modelling while the normalised data prior to normalisation will be used for ion-level and peptide-level modelling.\n\nThe workflow is implemented in a functions with one argument, object, which is the QFeatures we generated, either from the evidence file, the peptides file or the protein-groups file.\n\npreprocessing_workflow &lt;- function(object) {\n    ## 1. Encode missing values\n    i &lt;- names(object) ## store the input set names\n    object &lt;- zeroIsNA(object, i)\n    ## 2. Log transformation\n    logName &lt;- paste0(i, \"_log\") ## generate the log set names\n    object &lt;- logTransform(object, i, name = logName, base = 2)\n    ## 3. PSM filtering (only for psm-level data)\n    if (length(i) &gt; 1) {\n        for (ii in logName) {\n            rowdata &lt;- rowData(object[[ii]]) \n            rowdata$ionID &lt;- paste0(rowdata$Sequence, rowdata$Charge) \n            rowdata$rowSums &lt;- rowSums(assay(object[[ii]]), na.rm = TRUE)\n            rowdata &lt;- data.frame(rowdata) |&gt;\n                group_by(ionID) |&gt;\n                mutate(psmRank = rank(-rowSums))\n            rowData(object[[ii]]) &lt;- DataFrame(rowdata)    \n        }\n        object &lt;- filterFeatures(object, ~ psmRank == 1, keep = TRUE)\n        i &lt;- \"evidence\"\n        joinName &lt;- paste0(i, \"_log\")\n        object &lt;- joinAssays(object, logName, joinName, \"ionID\")\n        logName &lt;- joinName \n    }\n    ## 4. Match protein identifiers across data levels\n    if (i == \"proteinGroups\") { \n        ## We need to match the protein IDs in the evidence/peptide\n        ## table with the protiein IDs in the protein group table\n        rowdata &lt;- rbindRowData(object, names(object))\n        rowdata$Proteins &lt;- rowdata$Protein.IDs\n        rowData(object) &lt;- split(rowdata, rowdata$assay)\n    }\n    ## 5. Feature filtering\n    object &lt;- filterFeatures(\n        object, ~ Proteins != \"\" & ## Remove failed protein inference\n          !grepl(\";\", Proteins) & ## Remove protein groups\n          Reverse != \"+\" & ## Remove decoys\n          (Potential.contaminant != \"+\") ## Remove contaminants\n    )\n    ## 6. Missing value filtering\n    n &lt;- ncol(object[[logName]])\n    object &lt;- filterNA(object, i = logName, pNA = (n - 4) / n)\n    ## (The steps below are not for protein-group data)\n    if (i == \"proteinGroups\") return(object)\n    ## 7. Normalisation\n    normName &lt;- paste0(i, \"_norm\")\n    pseudoRef &lt;- rowMeans(assay(object[[logName]]), na.rm = TRUE)\n    nfLog &lt;- sweep(assay(object[[logName]]), MARGIN = 1, pseudoRef) |&gt; \n      colMedians(na.rm = TRUE)\n    object &lt;- sweep(\n      object, MARGIN = 2, STATS = nfLog, i = logName, name = normName\n    )\n    ## 8. Summarisation\n    summName &lt;- paste0(i, \"_proteins\")\n    aggregateFeatures(\n        object, i = normName, name = summName, fcol = \"Proteins\",\n        fun = MsCoreUtils::robustSummary\n    )\n}\n\n\n\n3.3.2 Run the workflow\nNow that we have defined a common data processing function, we apply to each input data level: the ion data, the peptide data and the protein-group data. We then combine all the data in a single QFeatures object.\n\nevidence &lt;- preprocessing_workflow(evidence)\npeptides &lt;- preprocessing_workflow(peptides)\nproteinGroups &lt;- preprocessing_workflow(proteinGroups)\nspikein &lt;- c(evidence, peptides, proteinGroups)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Benchmarking workflows</span>"
    ]
  },
  {
    "objectID": "03-benchmarking.html#data-modelling",
    "href": "03-benchmarking.html#data-modelling",
    "title": "3  Benchmarking workflows",
    "section": "3.4 Data modelling",
    "text": "3.4 Data modelling\nSimilarly to the data processing, we will use the same modelling workflow for each data level. For ion-level data (starting from the evidence file) and peptide-level data, we will both model the data before and after summarisation. In other words, we will model the data at the ion/peptide level (as described in the advanced chapter) and at the protein level (as described in the basics chapter).\n\n3.4.1 Model definition\nDepending on the input level (ion, peptide or protein), different models are required. The simplest model is the protein model where we account for the effect of Condition (spike-in amount group) using a fixed effect. For the peptide and the ion models, the data contains multiple peptides per proteins, and we expect that intensities from the same peptide are more similar than intensities from different peptides. Similarly, modelling multiple peptides per protein implies that we have multiple intensities per sample and hence that intensities from the same sample are more similar that intensities from different samples. The ion and peptide models therefore include a random effect for ion (ionID) and peptide (Sequence), and a random effect for sample (Sample). All three model definitions are stored in a list to streamline later access.\n\nmodels &lt;- list(\n    protein = ~ Condition,\n    peptide = ~ Condition + (1 | Sample) + (1 | Sequence),\n    ion = ~ Condition + (1 | Sample) + (1 | ionID)\n)\n\nWe will benchmark the performance of the modelling approaches by comparing all possible combination of 2 spike-in conditions2. All models assess the same comparisons of conditions, hence the same contrasts. We therefore build a contrast matrix that is shared across all models.\n\nallContrasts &lt;- createPairwiseContrasts(\n    models$protein, colData(spikein), var = \"Condition\", ridge = TRUE\n)\nL &lt;- makeContrast(\n    allContrasts, \n    c(\"ridgeConditionB\", \"ridgeConditionC\", \"ridgeConditionD\", \"ridgeConditionE\")\n)\n\n\n\n3.4.2 Modelling workflow\nWe will use the same msqrob2 data modelling and statistical inference workflow as presented in the basic concepts chapter. However, for ion-level and peptide-level models, we will rely on mixed models that have been introduced in the advanced chapter, including the refitting of proteins for which there is only 1 feature (ion or peptide). We implement the workflow in a function that we will call for all modelling approaches. It has 5 arguments:\n\nobject is the preprocessed QFeatures object containing the data to model.\ni is the name of the set to start (see names(spikein)).\nmodel is a formula defining the model to estimate.\nL is the contrast matrix to perform hypothesis testing.\nmodelLevel indicates whether the model should be fit at the \"ion\", \"peptide\" or \"protein\" level.\n\n\nmodelling_workflow &lt;- function(object, i, model, L, modelLevel) {\n    ## 1. Estimate the model\n    if (modelLevel == \"protein\") {\n        object &lt;- msqrob(\n            object,  i = i, formula = model,\n            ridge = TRUE, robust = TRUE\n        )\n    } else {\n        ## 1a. Estimate\n        object &lt;- msqrobAggregate(\n            object,  i = i, formula = model, \n            fcol = \"Proteins\", name = \"msqrob\",\n            robust = TRUE, ridge = TRUE\n        )\n        i &lt;- \"msqrob\"\n        ## 1b. Refit one-hit-wonders\n        counts &lt;- aggcounts(object[[\"msqrob\"]])\n        oneHitProteins &lt;- rownames(counts)[rowMax(counts) == 1]\n        object &lt;- msqrobRefit(\n          object, i = i, subset = oneHitProteins,\n          formula = ~ Condition,\n          fcol = \"Proteins\", name = \"msqrob\",\n          robust = TRUE, ridge = TRUE\n        )\n    }\n    ## 2. Hypothesis testing\n    object &lt;- hypothesisTest(object, i, contrast = L)\n    ## 3. Collect the results\n    out &lt;- msqrobCollect(object[[i]], L, combine = TRUE)\n    out\n}\n\n\n\n3.4.3 Run the workflow\nWe will now run the above function for the different approaches. To do so, we create a table containing the main modelling settings3:\n\nApproach 1 (called evidence_proteins): model the data from the evidence file using the protein level data.\nApproach 2 (called evidence_norm): model the data from the evidence file using the normalised ion data\nApproach 3 (called peptides_proteins): model the data from the peptides file using the protein level data.\nApproach 4 (called peptides_norm): model the data from the peptides file using the normalised peptide data.\nApproach 5 (called proteinGroups_log): model the data from the protein groups file using the protein level data.\n\n\n(approaches &lt;- data.frame(\n    inputLevel = c(\"evidence_proteins\", \"evidence_norm\", \"peptides_proteins\", \"peptides_norm\", \"proteinGroups_log\"),\n    modelLevel = c(\"protein\", \"ion\", \"protein\", \"peptide\", \"protein\")\n))\n\n         inputLevel modelLevel\n1 evidence_proteins    protein\n2     evidence_norm        ion\n3 peptides_proteins    protein\n4     peptides_norm    peptide\n5 proteinGroups_log    protein\n\n\nFor each row of this table, we retrieve the different arguments and run our data modelling workflow. Notice how every approach is run using the same code. Every apply iteration returns a table of statistical inference results for all pairwise comparisons. We combine all the tables in a single table for result exploration.\n\nresults &lt;- apply(approaches, 1, function(x) {\n    out &lt;- modelling_workflow(\n        spikein, i = x[[\"inputLevel\"]], model = models[[x[[\"modelLevel\"]]]],\n        L = L, modelLevel = x[[\"modelLevel\"]]\n    )\n    out$inputLevel &lt;- x[[\"inputLevel\"]]\n    out$modelLevel &lt;- x[[\"modelLevel\"]]\n    out\n})\nresults &lt;- do.call(rbind, results)\n\nWe also add whether each modelled protein is a E. Coli protein (known to be differentially abundant) or not. We also simplify the naming of the contrasts for visualisation.\n\nresults$isEcoli &lt;- results$feature %in% ecoli\nresults$contrast &lt;- gsub(\"ridgeCondition\", \"\", results$contrast)\nresults$contrast &lt;- gsub(\"^([B-E])$\", \"\\\\1 - A\", results$contrast)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Benchmarking workflows</span>"
    ]
  },
  {
    "objectID": "03-benchmarking.html#sec-performance",
    "href": "03-benchmarking.html#sec-performance",
    "title": "3  Benchmarking workflows",
    "section": "3.5 Performance benchmark",
    "text": "3.5 Performance benchmark\nWe now can compare the performance of the different modelling approaches. We will compare the approaches based on 4 objectives criteria:\n\nThe number of fitted proteins across conditions.\nThe number of true positives and false positives at a 5% FDR threshold.\nThe sensitivity against the rate of missidentification.\nThe accuracy and pricision of the log2-fold change estimatione\n\n\n3.5.1 Number of fits\nWe compare the number of proteins that could be estimated by each approach, where a model that fits more proteins is preferred. Note that the number of fits exceeds the number of measured proteins because we summed the fits over all comparisons.\n\ngroup_by(results, inputLevel) |&gt; \n    summarise(n = sum(!is.na(adjPval))) |&gt; \n    ggplot() +\n    aes(x = inputLevel, y = n, fill = inputLevel) +\n    geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\nWe can see that the approaches that fits least proteins is when starting from the protein-group file. However, all other four approaches can fit the same number of proteins.\n\n\n3.5.2 TP and FP at 5% FDR\nAn approach that fits more proteins is preferred, provided that the additional fits lead to meaningful results. Because this data set contains ground truth information, we can assess whether the modelling approaches correctly prioritised the proteins given the known differential abundant proteins. We therefore benchmark the approaches by examining the number of reported proteins that are true positive (TP) (i.e., E. Coli proteins), and false positive (FP) (i.e., human proteins) considering a 5% false discovery rate (FDR) threshold, which is typically used. We will therefore first construct the table with TPs and FPs obtained from each data modelling approach for each comparison.\n\ntpFpTable &lt;- group_by(results, inputLevel, contrast) |&gt;\n    filter(adjPval &lt; 0.05) |&gt;\n    summarise(\"True Positives\" = sum(isEcoli),\n              \"False Positives\" = sum(!isEcoli)) |&gt;\n    pivot_longer(cols = c(\"True Positives\", \"False Positives\"))\n\nWe then plot the table as a bar plot, facetting for every comparison.\n\nggplot(tpFpTable) +\n    aes(x = inputLevel,\n        y = value,\n        fill = inputLevel) +\n    geom_bar(stat = \"identity\") +\n    facet_grid(contrast ~ name, scales = \"free\") +\n    labs(x = \"\", y = \"Count\") +\n    theme(axis.text.x = element_blank(),\n          axis.ticks.x = element_blank(),\n          legend.position = \"bottom\") +\n    guides(fill = guide_legend(nrow = 3)) ## to avoid legend getting cropped\n\n\n\n\n\n\n\n\nThe plot clearly shows that starting from MaxQuant’s proteinGroups file leads to a severe decrease in performance as the number of TP is systematically lower compared to other approaches, while there is no dramatic difference with the number of FPs.\nThe four other approaches lead to comparable results. We could argue that for some specific comparisons (C-B, D-C, E-D) approaches starting from the evidence file recover slightly more TP without impact on the number of FP. Similarly modelling at the peptide/ion level leads to slight increase in performance compared to modelling at the protein level, but these difference are subtle.\n\n\n3.5.3 TPR-FDP curves\nAdditionally, we construct true positive rate (TPR)-false discovery proportion (FDP) plots. TPR represents the fraction of truly DA proteins reported by the method, calculated as \\(TPR =\n\\frac{TP}{TP+FN}\\), with FN false negatives (i.e., E. Coli proteins that were not flagged as differential abundant). FDP denotes the proportion of false positives among all proteins flagged as differential abundant, calculated as \\(FDP = \\frac{FP}{TP + FP}\\).\nSo we first compute the FDP and TPR using the custom functions below:\n\ncomputeFDP &lt;- function(pval, tp) {\n    ord &lt;- order(pval)\n    fdp &lt;- cumsum(!tp[ord]) / 1:length(tp)\n    fdp[order(ord)]\n}\ncomputeTPR &lt;- function(pval, tp, nTP = NULL) {\n    if (is.null(nTP)) nTP &lt;- sum(tp)\n    ord &lt;- order(pval)\n    tpr &lt;- cumsum(tp[ord]) / nTP\n    tpr[order(ord)]\n}\n\nBefore computing these metrics, we first remove any failed inference4. This means that we are comparing the approach based on a set of proteins that is specific to each approach. However, proteins that are fit by some approaches but not by others may be harder to estimate and hence will decrease the overall performance. So, for a fair comparison, we also created a plot that compares the approaches when considering all the proteins measured in the data set (see the appendix section). Any failed inference for a DA protein will results in a FP. Similarly, we could also compare the approaches based on a common set of proteins that has been fit by all approaches (see the following appendix section).\nWe compute the TPR and FDP for each approach (given by inputLevel) and each pairwise spike-in comparison (given by contrast).\n\nperformance &lt;- group_by(results, inputLevel, contrast) |&gt; \n    na.exclude() |&gt;\n    mutate(tpr = computeTPR(pval, isEcoli),\n           fdp = computeFDP(pval, isEcoli)) |&gt;\n    arrange(fdp)\n\nWe also highlight the observed FDP at a 5% FDR threshold. Since the FDR represent the expected FDP, i.e. the average of the FDPs obtained when the spike-in experiment were to be repeated an infinite number of times, an observed FDP that is very far away from 5% is indicative for a workflow that provides poor FDR control.\n\nworkPoints &lt;- group_by(performance, inputLevel, contrast) |&gt;\n    filter(adjPval &lt; 0.05) |&gt;\n    slice_max(adjPval) |&gt;\n    filter(!duplicated(inputLevel))\n\nWe can now generate the TPR-FDP curves. The best performing approach is characterised by the largest area under the curve. These curves provide the performance over a range of FDP values, but we limit the plot to the \\([0, 0.2]\\) range because researchers are rarely interest in the performance when the FDP exceeds 20%.\n\nggplot(performance) +\n    aes(y = fdp,\n        x = tpr,\n        colour = inputLevel) +\n    geom_line() +\n    geom_point(data = workPoints, size = 3) +\n    geom_hline(yintercept = 0.05, linetype = 2) +\n    facet_wrap(~ contrast) +\n    coord_flip(ylim = c(0, 0.2)) +\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nThe results are in line with the previous bechmark criteria, that is starting from the proteinGroups file lead to a severe backlash on performance. The other approaches show comparable performance, although for challenging comparisons where the performance is generally low (C-B, D-C, E-D) we find a subtle increase in performance for ion/peptide level models.\nOveral, we find that all approaches lead to a good FDR control. A notable exception is for challenging comparisons when starting from protein group data, where the performance is so low that FDR cannot be controlled. We also find that the other approaches tend to be conservative for the D-C and E-D comparisons.\nThe same results apply when considering all proteins in the data or when considering proteins estimated by all approaches, indicating that the conclusions do not depend on the set of proteins considered.\n\n\n3.5.4 Fold change boxplots\nNext to correctly prioritising the differentially abundant proteins, another object is to correctly estimate the log2-fold change between conditions. Since every condition contains E. Coli proteins that have been spiked in experimentally controlled amounts, we know the real log2-fold change between any two conditions. We will explore the model accuracy, i.e. how close the estimations are from the true value on average, and the model precision, i.e. how narrow the estimations are spread around the average estimation. In this data set, there are two target values. For E. Coli proteins, the expected value is the experimentally induced log2-fold change. For human proteins, the expected value is a log2-fold change of 0, as these proteins are experimentally known to be constant.\nWe explore the results using boxplots of the estimated log2-fold changes, but we first create a small table with the expected values.\n\nrealLogFC &lt;- data.frame(\n  logFC = t(L) %*% lm(log2(Concentration) ~ Condition, colData(spikein))$coef[-1]\n)\nrealLogFC$contrast &lt;- gsub(\"ridgeCondition\",\"\",colnames(L))\nrealLogFC$contrast &lt;- gsub(\"^([B-E])$\", \"\\\\1 - A\", realLogFC$contrast)\n\nWe can now create the boxplots with the estimated log2-fold changes, adding horizontal lines with the corresponding target values.\n\nggplot(results) +\n  aes(y = logFC,\n      x = isEcoli,\n      colour = isEcoli) +\n  geom_boxplot()  +\n  scale_color_manual(\n    values = c(\"grey20\", \"firebrick\"), name = \"\",\n    labels = c(\"Human proteins\", \"E. coli proteins\")\n  ) +\n  facet_grid(contrast ~ inputLevel, scales = \"free\") +\n  geom_hline(data = realLogFC, aes(yintercept = logFC), \n             colour = \"firebrick\") +\n  geom_hline(yintercept = 0) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nFor all approaches, the boxplots are roughly centred on the expected value, indicating good model accuracy. Starting from MaxQuant’s protein-group data leads to wider boxplots, hence less stable estimation and hence decreased precision. The approach starting from the evidence file seems to provide somewhat more precise estimations as it shows less outliers compared to starting from the peptides file.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Benchmarking workflows</span>"
    ]
  },
  {
    "objectID": "03-benchmarking.html#sec-take_home",
    "href": "03-benchmarking.html#sec-take_home",
    "title": "3  Benchmarking workflows",
    "section": "3.6 Take home messages",
    "text": "3.6 Take home messages\nWe found a striking drop in performance when starting from the protein-group data compared to the other approaches, suggesting that this approach leads to suboptimal results. We couldn’t find strong differences in performance between the remaining apporaches. For some comparisons, we found a slight increase in performance when starting from the evidence file compared to starting from the peptides file. Similarly, for some comparisons, we found a slight increase in performance when modelling data at the ion/peptide level compared to the protein level.\nProcessing the data from the evidence file only leads to one additional step compared to processing the data from the peptides file: we need to find a low-level feature definition that is shared across rus, which we here defined as the ion level (i.e. the combination of the peptide sequence and its charge). This additional step has little impact on the complexity of the workflow, hence we would advice to start from the evidence file. However, modelling the data at the ion/peptide level is more advanced than modelling at the protein level, as it requires the inclusion of random effects to account for the correlation structure within and between samples and within and between ions/peptides from the same protein. Moreover, the data modelling is performed at the ion/peptide level, but the statistical inference results are reported at the protein level, meaning that no direct protein summaries are available to explore and support the statistical outcome5. Therefore, we leave it to the user to decide whether the slight improvement in performance is worth the cost of more complex statistical analysis (Sticker et al. 2020).\nHence, this chapter showed how to perform benchmarking on different types of data input. Note that the same framework could be used to compare different search and quantification engines. Similarly, this framework can also be applied to compare different instruments or analytical protocols and setups. In the next chapter we demonstrate how to compare the impact of analysis steps for the same data.\nIn the remainder of this section, we provide a recap on how to perform a proteomics analysis from the evidence file6, either at the ion-level or at the protein level.\n\n3.6.1 Preprocessing the evidence file\nThe first step is to read the data. Remember that we need two pieces of data, the sample annotation table and, in this case, the PSM table obtained after reading MaxQuant’s evidence file.\nHere are the first 6 lines (first 6 samples) of the sample annotations, note we added runCol and quantCol that are required for the conversion to a QFeatures object.\n\ncoldata &lt;- read.csv(annotFile)\n\n\n\n\n\n\n\n\n\n\n\n\nRaw.file\nCondition\nSample\nConcentration\n\n\n\n\nB03_03_150304_human_ecoli_C_3ul_3um_column_95_HCD_OT_2hrs_30B_9B\nC\nc1\n6.0\n\n\nB03_08_150304_human_ecoli_C_3ul_3um_column_95_HCD_OT_2hrs_30B_9B\nC\nc2\n6.0\n\n\nB03_18_150304_human_ecoli_C_3ul_3um_column_95_HCD_OT_2hrs_30B_9B\nC\nc3\n6.0\n\n\nB03_19_150304_human_ecoli_B_3ul_3um_column_95_HCD_OT_2hrs_30B_9B\nB\nb1\n4.5\n\n\nB03_07_150304_human_ecoli_D_3ul_3um_column_95_HCD_OT_2hrs_30B_9B\nD\nd1\n7.5\n\n\nB03_14_150304_human_ecoli_D_3ul_3um_column_95_HCD_OT_2hrs_30B_9B\nD\nd2\n7.5\n\n\n\n\n\nHere are the first 6 lines (first 6 PSMs) of the PSM table. The table contains many columns, most containing information about the identified peptide and the quality of the spectrum matching.\n\nevidence &lt;- fread(evidenceFile, check.names = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequence\nLength\nModifications\nModified.sequence\nOxidation..M..Probabilities\nOxidation..M..Score.Diffs\nAcetyl..Protein.N.term.\nOxidation..M.\nMissed.cleavages\nProteins\nLeading.proteins\nLeading.razor.protein\nGene.names\nProtein.names\nType\nRaw.file\nExperiment\nMS.MS.m.z\nCharge\nm.z\nMass\nResolution\nUncalibrated…Calibrated.m.z..ppm.\nUncalibrated…Calibrated.m.z..Da.\nMass.error..ppm.\nMass.error..Da.\nUncalibrated.mass.error..ppm.\nUncalibrated.mass.error..Da.\nMax.intensity.m.z.0\nRetention.time\nRetention.length\nCalibrated.retention.time\nCalibrated.retention.time.start\nCalibrated.retention.time.finish\nRetention.time.calibration\nMatch.time.difference\nMatch.m.z.difference\nMatch.q.value\nMatch.score\nNumber.of.data.points\nNumber.of.scans\nNumber.of.isotopic.peaks\nPIF\nFraction.of.total.spectrum\nBase.peak.fraction\nPEP\nMS.MS.count\nMS.MS.scan.number\nScore\nDelta.score\nCombinatorics\nIntensity\nReverse\nPotential.contaminant\nid\nProtein.group.IDs\nPeptide.ID\nMod..peptide.ID\nMS.MS.IDs\nBest.MS.MS\nAIF.MS.MS.IDs\nOxidation..M..site.IDs\n\n\n\n\nAAAAAAAAAAAAAAAGAGAGAK\n22\nUnmodified\nAAAAAAAAAAAAAAAGAGAGAK\n\n\n0\n0\n0\nP55011\nP55011\nP55011\nSLC12A2\nSolute carrier family 12 member 2\nMULTI-SECPEP\nB03_03_150304_human_ecoli_C_3ul_3um_column_95_HCD_OT_2hrs_30B_9B\nc1\n532.9854\n3\n532.9533\n1595.838\n94394.69\n-0.5225600\n-0.0002785\n0.84218\n0.0004488\n0.31962\n0.0001703\n532.9553\n76.475\n0.19265\n76.426\n76.307\n76.500\n-0.049773\nNA\nNA\nNA\nNA\n24\n11\n3\n0\n0\n0\n0.0013949\n1\n31302\n46.133\n33.507\n1\n4268500\n\n\n0\n2115\n0\n0\n0\n0\nNA\n\n\n\nAAAAAAAAAAAAAAAGAGAGAK\n22\nUnmodified\nAAAAAAAAAAAAAAAGAGAGAK\n\n\n0\n0\n0\nP55011\nP55011\nP55011\nSLC12A2\nSolute carrier family 12 member 2\nMULTI-SECPEP\nB03_08_150304_human_ecoli_C_3ul_3um_column_95_HCD_OT_2hrs_30B_9B\nc2\n532.9863\n3\n532.9533\n1595.838\n89387.45\n0.0021322\n0.0000011\n-0.25348\n-0.0001351\n-0.25135\n-0.0001340\n533.2871\n76.225\n0.16901\n76.426\n76.314\n76.483\n0.200350\nNA\nNA\nNA\nNA\n13\n8\n2\n0\n0\n0\n0.0069352\n1\n31103\n38.377\n32.662\n1\n7099400\n\n\n1\n2115\n0\n0\n1\n1\nNA\n\n\n\nAAAAAAAAAAAAAAAGAGAGAK\n22\nUnmodified\nAAAAAAAAAAAAAAAGAGAGAK\n\n\n0\n0\n0\nP55011\nP55011\nP55011\nSLC12A2\nSolute carrier family 12 member 2\nMSMS\nB03_18_150304_human_ecoli_C_3ul_3um_column_95_HCD_OT_2hrs_30B_9B\nc4\n798.9761\n2\n798.9263\n1595.838\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n76.225\n1.00000\n76.639\n76.139\n77.139\n0.413920\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0\n0\n0\n0.0000000\n1\n31830\n98.407\n82.183\n1\nNA\n\n\n2\n2115\n0\n0\n2\n2\nNA\n\n\n\nAAAAAAAAAAAAAAAGAGAGAK\n22\nUnmodified\nAAAAAAAAAAAAAAAGAGAGAK\n\n\n0\n0\n0\nP55011\nP55011\nP55011\nSLC12A2\nSolute carrier family 12 member 2\nMSMS\nB03_19_150304_human_ecoli_B_3ul_3um_column_95_HCD_OT_2hrs_30B_9B\nb4\n798.9767\n2\n798.9263\n1595.838\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n75.981\n1.00000\n76.733\n76.233\n77.233\n0.752060\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0\n0\n0\n0.0000000\n1\n31810\n71.241\n53.805\n1\nNA\n\n\n3\n2115\n0\n0\n3\n3\nNA\n\n\n\nAAAAAAAAAAAAAAAGAGAGAK\n22\nUnmodified\nAAAAAAAAAAAAAAAGAGAGAK\n\n\n0\n0\n0\nP55011\nP55011\nP55011\nSLC12A2\nSolute carrier family 12 member 2\nMULTI-MATCH\nB03_07_150304_human_ecoli_D_3ul_3um_column_95_HCD_OT_2hrs_30B_9B\nd2\nNA\n3\n532.9533\n1595.838\n83252.61\n-0.4043600\n-0.0002155\n-0.31288\n-0.0001667\n-0.71725\n-0.0003823\n532.9532\n76.332\n0.11982\n76.533\n76.433\n76.553\n0.200930\n-0.016489\n-0.0001398\nNaN\n37.285\n10\n8\n2\nNaN\nNaN\nNaN\nNaN\n0\nNA\nNaN\nNaN\n0\n8563700\n\n\n4\n2115\n0\n0\n\nNA\nNA\n\n\n\nAAAAAAAAAAAAAAAGAGAGAK\n22\nUnmodified\nAAAAAAAAAAAAAAAGAGAGAK\n\n\n0\n0\n0\nP55011\nP55011\nP55011\nSLC12A2\nSolute carrier family 12 member 2\nMULTI-MATCH\nB03_14_150304_human_ecoli_D_3ul_3um_column_95_HCD_OT_2hrs_30B_9B\nd3\nNA\n3\n532.9533\n1595.838\n98783.58\n-0.3048300\n-0.0001625\n-0.31827\n-0.0001696\n-0.62310\n-0.0003321\n532.9531\n76.046\n0.10846\n76.498\n76.403\n76.511\n0.451640\n-0.051605\n-0.0001484\nNaN\n37.285\n7\n5\n2\nNaN\nNaN\nNaN\nNaN\n0\nNA\nNaN\nNaN\n0\n6597000\n\n\n5\n2115\n0\n0\n\nNA\nNA\n\n\n\n\n\n\nNote that Intensity column contains the quantitative values and the Raw.file column indicates in which run the sample was acquired. We use the latter to link the sample annotation with the PSM table. We therefore need to add runCol to the sample annotation that will serve as the linker. We can then convert the tables to a QFeatures object.\n\ncoldata$runCol &lt;- coldata$Raw.file\n(evidence &lt;- readQFeatures(\n    evidence, colData = coldata, runCol = \"Raw.file\", \n    quantCols = \"Intensity\"\n))\n\nAn instance of class QFeatures (type: bulk) with 20 sets:\n\n [1] B03_02_150304_human_ecoli_B_3ul_3um_column_95_HCD_OT_2hrs_30B_9B: SummarizedExperiment with 40057 rows and 1 columns \n [2] B03_03_150304_human_ecoli_C_3ul_3um_column_95_HCD_OT_2hrs_30B_9B: SummarizedExperiment with 41266 rows and 1 columns \n [3] B03_04_150304_human_ecoli_D_3ul_3um_column_95_HCD_OT_2hrs_30B_9B: SummarizedExperiment with 41396 rows and 1 columns \n ...\n [18] B03_19_150304_human_ecoli_B_3ul_3um_column_95_HCD_OT_2hrs_30B_9B: SummarizedExperiment with 39388 rows and 1 columns \n [19] B03_20_150304_human_ecoli_A_3ul_3um_column_95_HCD_OT_2hrs_30B_9B: SummarizedExperiment with 39000 rows and 1 columns \n [20] B03_21_150304_human_ecoli_A_3ul_3um_column_95_HCD_OT_2hrs_30B_9B: SummarizedExperiment with 38783 rows and 1 columns \n\n\nNote that the data from every run is contained in a separate set. We cannot yet join the sets together since we don’t have a specific feature identifier, yet7.\n\nEncoding missing values as zeros.\n\n\nevidence &lt;- zeroIsNA(evidence, names(evidence))\n\n\nLog2 transforming\n\n\ninputNames &lt;- names(evidence)\nlogNames &lt;- paste0(inputNames, \"_log\")\nevidence &lt;- logTransform(evidence, inputNames, name = logNames, base = 2)\n\n\nKeeping only the most intense PSM per ion (see here for a step-by-step explanation of the code). Upon this filtering every feature is unique to a ion identifier (peptide sequence + charge), and we hence can join sets using that identifier.\n\n\nfor (i in logNames) {\n  rowdata &lt;- rowData(evidence[[i]]) \n  rowdata$ionID &lt;- paste0(rowdata$Sequence, rowdata$Charge) \n  rowdata$value &lt;- assay(evidence[[i]])[, 1]\n  rowdata &lt;- data.frame(rowdata) |&gt;\n    group_by(ionID) |&gt;\n    mutate(psmRank = rank(-value))\n  rowData(evidence[[i]])$psmRank &lt;- rowdata$psmRank\n  rowData(evidence[[i]])$ionID &lt;- rowdata$ionID\n}\nevidence &lt;- filterFeatures(evidence, ~ psmRank == 1, keep = TRUE)\nevidence &lt;- joinAssays(evidence, logNames, \"ions_log\", \"ionID\")\n\n\nFeature filtering\n\n\nevidence &lt;- filterFeatures(\n        evidence, ~ Proteins != \"\" & ## Remove failed protein inference\n          !grepl(\";\", Proteins) & ## Remove protein groups\n          Reverse != \"+\" & ## Remove decoys\n          (Potential.contaminant != \"+\") ## Remove contaminants\n)\n\n\nMissing value filtering\n\n\nn &lt;- ncol(evidence[[\"ions_log\"]])\nevidence &lt;- filterNA(evidence, i = \"ions_log\", pNA = (n - 4) / n)\n\n\nNormalisation\n\n\npseudoRef &lt;- rowMeans(assay(evidence[[\"ions_log\"]]), na.rm = TRUE)\nnfLog &lt;- sweep(assay(evidence[[\"ions_log\"]]), MARGIN = 1, pseudoRef) |&gt; \n  colMedians(na.rm = TRUE)\nevidence &lt;- sweep(\n  evidence, MARGIN = 2, STATS = nfLog, \n  i = \"ions_log\", name = \"ions_norm\"\n)\n\n\nSummarisation\n\n\nevidence &lt;- aggregateFeatures(\n  evidence, i = \"ions_norm\", name = \"proteins\", fcol = \"Proteins\",\n  fun = MsCoreUtils::robustSummary\n)\n\n\n\n3.6.2 Modelling the preprocessed data\nWe can model the data either at the ion level or at the protein level. Regardless of the modelling approach, we can readily generate the contrast matrix to assess all pairwise comparisons between the experimental spike-in conditions.\n\nallContrasts &lt;- createPairwiseContrasts(\n    ~ Condition, colData(evidence), var = \"Condition\", ridge = TRUE\n)\nL &lt;- makeContrast(\n    allContrasts, \n    c(\"ridgeConditionB\", \"ridgeConditionC\", \"ridgeConditionD\", \"ridgeConditionE\")\n)\n\n\nModelling at the protein-level\nWe first need to define the model we want to estimate, which descirbes the sources of variation in the data. For the protein-level data, the only potential source of variation identified from the experiment is the spike-in condition of interest. We model it as a fixed effect.\n\nmodelProtein &lt;- ~ Condition\n\nThen, we estimate the model.\n\nevidence &lt;- msqrob(\n  evidence,  i = \"proteins\", formula = modelProtein,\n  ridge = TRUE, robust = TRUE\n)\n\nAnd we perform statistical inference on the estimated model parameters.\n\nevidence &lt;- hypothesisTest(evidence, \"proteins\", contrast = L)\nresultsProtein &lt;- msqrobCollect(evidence[[\"proteins\"]], L, combine = TRUE)\nresultsProtein$isEcoli &lt;- resultsProtein$feature %in% ecoli\n\nNote that this workflows closely follows the workflow described in the basics chapter. We can report the result using a volcano plot, for instance.\n\nggplot(resultsProtein) +\n    aes(x = logFC,\n        y = -log10(pval),\n        shape = adjPval &lt; 0.05,\n        color = isEcoli) +\n    geom_point() +\n    scale_color_manual(\n      values = c(\"grey20\", \"firebrick\"), name = \"\",\n      labels = c(\"HeLA background\", \"UPS standard\")\n    ) +\n    facet_wrap(~ contrast, scales = \"free\") +\n    ggtitle(\"Statistical inference for all pairwise comparisons\") \n\n\n\n\n\n\n\n\n\n\nModelling at the ion-level\nThe model definition for the ion-level data is more ellaborate than for the protein-level data. We need to account for the fact that intensities within the same sample are more correlated than intensities across samples. Similarly, we need to account for the fact that intensities for the same ion will be more similar than intensities between ions of the same proteins. On top of the condition effect that we model as a fixed effect, we will account for these sample and ion effects using a random effect.\n\nmodelIon &lt;- ~ Condition + (1 | Sample) + (1 | ionID)\n\nThen, we estimate the model using msqrobAggregate() instead of msqrob().\n\nevidence &lt;- msqrobAggregate(\n  evidence,  i = \"ions_norm\", formula = modelIon, \n  fcol = \"Proteins\", name = \"msqrob\",\n  robust = TRUE, ridge = TRUE\n)\n\nBecause some proteins are only measured by a single ion, its corresponding sample and ion effects cannot be estimated and hence the model for those proteins will not be estimated. We therefore refit a simplified model for those proteins using the refitting workflow described in the advanced chapter.\n\ncounts &lt;- aggcounts(evidence[[\"msqrob\"]])\noneHitProteins &lt;- rownames(counts)[rowMax(counts) == 1]\nevidence &lt;- msqrobRefit(\n  evidence, i = \"ions_norm\", subset = oneHitProteins,\n  formula = ~ Condition,\n  fcol = \"Proteins\", name = \"msqrob\",\n  robust = TRUE, ridge = TRUE\n)\n\nAnd we perform statistical inference on the estimated model parameters (same as above).\n\nevidence &lt;- hypothesisTest(evidence, \"msqrob\", contrast = L)\nresultsIon &lt;- msqrobCollect(evidence[[\"msqrob\"]], L, combine = TRUE)\nresultsIon$isEcoli &lt;- resultsIon$feature %in% ecoli\n\nWe can report the result using a volcano plot, for instance.\n\nggplot(resultsIon) +\n    aes(x = logFC,\n        y = -log10(pval),\n        shape = adjPval &lt; 0.05,\n        color = isEcoli) +\n    geom_point() +\n    scale_color_manual(\n      values = c(\"grey20\", \"firebrick\"), name = \"\",\n      labels = c(\"HeLA background\", \"UPS standard\")\n    ) +\n    facet_wrap(~ contrast, scales = \"free\") +\n    ggtitle(\"Statistical inference for all pairwise comparisons\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Benchmarking workflows</span>"
    ]
  },
  {
    "objectID": "03-benchmarking.html#appendix",
    "href": "03-benchmarking.html#appendix",
    "title": "3  Benchmarking workflows",
    "section": "3.7 Appendix",
    "text": "3.7 Appendix\nThis section provides a complement to the TPR-FDR curves\n\n3.7.1 TPR-FDP curves using all proteins in the data\nThis code is almost the same as for the main plot, except we removed the na.exclude() statement. This means that all proteins, even if not estimated, are included. The missing p-values will be ranked at the end (as if they were estimated at 1), meaning they will be accounted for when computing the TPR and FDP. This will inevitably lead to a decrease in the maximum TPR, especially for approaches that estimated less proteins.\n\nperformance_all &lt;- group_by(results, inputLevel, contrast) |&gt; \n    mutate(tpr = computeTPR(pval, isEcoli),\n           fdp = computeFDP(pval, isEcoli)) |&gt;\n    arrange(fdp)\nworkPoints &lt;- group_by(performance_all, inputLevel, contrast) |&gt;\n    filter(adjPval &lt; 0.05) |&gt;\n    slice_max(adjPval) |&gt;\n    filter(!duplicated(inputLevel))\nggplot(performance_all) +\n    aes(y = fdp,\n        x = tpr,\n        colour = inputLevel) +\n    geom_line() +\n    geom_point(data = workPoints, size = 3) +\n    geom_hline(yintercept = 0.05, linetype = 2) +\n    facet_wrap(~ contrast) +\n    coord_flip(ylim = c(0, 0.2)) +\n    theme(legend.position = \"bottom\") +\n    ggtitle(\"TPR-FDP curves using all proteins in the data\")\n\n\n\n\n\n\n\n\n\n\n3.7.2 TPR-FDP curves using only the proteins fit by all approaches\nThe code is almost the same as for the main plot, except we add a filtering step where we require, for each comparison, that p-values are not missing for all 5 approaches, effectively focusing on the set of proteins that have been estimated by all approaches.\n\nperformance_common &lt;- group_by(results, feature, contrast) |&gt; \n  filter(!is.na(adjPval),\n         n() == 5) |&gt; \n  group_by(inputLevel, contrast) |&gt; \n  mutate(tpr = computeTPR(pval, isEcoli),\n         fdp = computeFDP(pval, isEcoli)) |&gt;\n  arrange(fdp)\nworkPoints &lt;- group_by(performance_common, inputLevel, contrast) |&gt;\n    filter(adjPval &lt; 0.05) |&gt;\n    slice_max(adjPval) |&gt;\n    filter(!duplicated(inputLevel))\nggplot(performance_common) +\n    aes(y = fdp,\n        x = tpr,\n        colour = inputLevel) +\n    geom_line() +\n    geom_point(data = workPoints, size = 3) +\n    geom_hline(yintercept = 0.05, linetype = 2) +\n    facet_wrap(~ contrast) +\n    coord_flip(ylim = c(0, 0.2)) +\n    theme(legend.position = \"bottom\") +\n    ggtitle(\"TPR-FDP curves using only the proteins fit by all approaches\")\n\n\n\n\n\n\n\n\n\n\n\n\nShen, Xiaomeng, Shichen Shen, Jun Li, Qiang Hu, Lei Nie, Chengjian Tu, Xue Wang, et al. 2018. “IonStar Enables High-Precision, Low-Missing-Data Proteomics Quantification in Large Biological Cohorts.” Proc. Natl. Acad. Sci. U. S. A. 115 (21): E4767–76.\n\n\nSticker, Adriaan, Ludger Goeminne, Lennart Martens, and Lieven Clement. 2020. “Robust Summarization and Inference in Proteome-Wide Label-Free Quantification.” Mol. Cell. Proteomics 19 (7): 1209–19.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Benchmarking workflows</span>"
    ]
  },
  {
    "objectID": "03-benchmarking.html#footnotes",
    "href": "03-benchmarking.html#footnotes",
    "title": "3  Benchmarking workflows",
    "section": "",
    "text": "Another option would be to copy-paste the workflow code for every approach, but we refrain from doing so as this can lead to incoherent code when the workflow needs to be changed. This is a common malpractice that reduces code maintainability.↩︎\nThere are 5 conditions, so 10 unique pairwise combinations.↩︎\nNote the approach names match some of the sets in the QFeatures object.↩︎\nWhen statistical inference fails for a protein, msqrob2 will fill the (adjusted) p-value and log2-fold change with missing values. So excluding NAs will ignore any failed inference.↩︎\nAlthough these protein data are indirectly generated using a summarisation approach (c.f. msqrobAggregate()).↩︎\nWe build on the concepts introduced in the basic concepts chapter and the advanced concepts chapter↩︎\nA PSM is generated from a spectrum, which is specific to each run and there is not unambiguous way to link a spectrum across runs↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Benchmarking workflows</span>"
    ]
  },
  {
    "objectID": "04-workflow_optimisation.html",
    "href": "04-workflow_optimisation.html",
    "title": "4  Optimisation of a data analysis workflow",
    "section": "",
    "text": "4.1 Load packages\nIn the previous chapter we have seen how to benchmark the data analysis performance when starting from different types of data. This chapter presents how to assess the impact of different methods for the same sequence of steps on the same data, effectively optimising the workflow.\nTo illustrate the approach, we will again use the data set by (Shen et al. 2018), a spike-in data set with known ground truth. The optimisation focuses on two steps: we will explore different methods for normalisation and summarisation.\nImportant: the first sections of the chapter are again meant for advanced users that are familiar with R scripting. Novice users interested in the key messages and best practices can refer to the take home message section.\nWe load the msqrob2 package, along with additional packages for data manipulation and visualisation.\nlibrary(\"msqrob2\")\nlibrary(\"data.table\")\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"ggplot2\")\nlibrary(\"patchwork\")\nlibrary(\"tidyverse\")\nWe also configure the parallelisation framework.\nlibrary(\"BiocParallel\")\nregister(SerialParam())",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Optimisation of a data analysis workflow</span>"
    ]
  },
  {
    "objectID": "04-workflow_optimisation.html#data",
    "href": "04-workflow_optimisation.html#data",
    "title": "4  Optimisation of a data analysis workflow",
    "section": "4.2 Data",
    "text": "4.2 Data\nWe will reuse the data by (Shen et al. 2018) as in Chapter 1 and Chapter 3. The data were reanalysed using MaxQuant, and we will use start from the evidence file as suggested in the previous chapter.\n\n4.2.1 PSM table\nWe here retrieve the evidence file containig the PSM table.\nTODO: put data on Zenodo or MsDataHub, and update code below\n\n# myurl &lt;- \"https://github.com/statOmics/MSqRobSumPaper/raw/refs/heads/master/spikein/data/maxquant/evidence.zip\"\n# download.file(myurl,\"data/sticker2020/evidence.zip\", method = \"curl\", extra = \"-L\")\n# unzip(\"data/sticker2020/evidence.zip\", exdir = \"data/sticker2020/\")\nevidenceFile &lt;- \"data/sticker2020/evidence.txt\"\n\nWe also load the annotation table) that has been generated by the authors. Since the evidence, peptides and protein-groups tables all contain the same samples, the annotation table will be shared across the MaxQuant data tables.\n\nannotFile &lt;- \"data/sticker2020/sticker2020_annotation.csv\"\ncoldata &lt;- read.csv(annotFile)\n\nWe retrieve all the E. coli protein identifiers to later identify which proteins are known to be differentially abundant (E. coli proteins) or constant (human) across condition.\n\nlibrary(\"BiocFileCache\")\nbfc &lt;- BiocFileCache()\necoli &lt;- bfcrpath(bfc, \"https://raw.githubusercontent.com/statOmics/MSqRobSumPaper/refs/heads/master/spikein/data/fasta/ecoli_up000000625_7_06_2018.fasta\")\necoli &lt;- readLines(ecoli)\necoli &lt;- ecoli[grepl(\"^&gt;\", ecoli)]\necoli &lt;- gsub(\"&gt;sp\\\\|(.*)\\\\|.*\", \"\\\\1\", ecoli)\n\n\n\n4.2.2 Convert to QFeatures\nWe combine the evidence file with the annotation table into a QFeatures object.\n\nspikein &lt;- fread(evidenceFile, check.names = TRUE)\ncoldata$runCol &lt;- coldata$Raw.file\n(spikein &lt;- readQFeatures(\n    spikein, colData = coldata, runCol = \"Raw.file\", \n    quantCols = \"Intensity\"\n))\n\nAn instance of class QFeatures (type: bulk) with 20 sets:\n\n [1] B03_02_150304_human_ecoli_B_3ul_3um_column_95_HCD_OT_2hrs_30B_9B: SummarizedExperiment with 40057 rows and 1 columns \n [2] B03_03_150304_human_ecoli_C_3ul_3um_column_95_HCD_OT_2hrs_30B_9B: SummarizedExperiment with 41266 rows and 1 columns \n [3] B03_04_150304_human_ecoli_D_3ul_3um_column_95_HCD_OT_2hrs_30B_9B: SummarizedExperiment with 41396 rows and 1 columns \n ...\n [18] B03_19_150304_human_ecoli_B_3ul_3um_column_95_HCD_OT_2hrs_30B_9B: SummarizedExperiment with 39388 rows and 1 columns \n [19] B03_20_150304_human_ecoli_A_3ul_3um_column_95_HCD_OT_2hrs_30B_9B: SummarizedExperiment with 39000 rows and 1 columns \n [20] B03_21_150304_human_ecoli_A_3ul_3um_column_95_HCD_OT_2hrs_30B_9B: SummarizedExperiment with 38783 rows and 1 columns \n\n\nWe now have a QFeatures object with 20 sets, as many as the number of MS runs. We cannot yet join the sets together since we don’t have a specific feature identifier and the data does not fullfill to the modelling assumptions, yet. We will therefore preprocess the data first.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Optimisation of a data analysis workflow</span>"
    ]
  },
  {
    "objectID": "04-workflow_optimisation.html#data-preprocessing",
    "href": "04-workflow_optimisation.html#data-preprocessing",
    "title": "4  Optimisation of a data analysis workflow",
    "section": "4.3 Data preprocessing",
    "text": "4.3 Data preprocessing\nWe will follow the same data preprocessing workflow as in the previous chapter. We will however explore different normalisation strategies and summarisation methods.\n\nEncoding missing values as zeros.\n\n\nspikein &lt;- zeroIsNA(spikein, names(spikein))\n\n\nLog2 transforming\n\n\ninputNames &lt;- names(spikein)\nlogNames &lt;- paste0(inputNames, \"_log\")\nspikein &lt;- logTransform(spikein, inputNames, name = logNames, base = 2)\n\n\nKeeping only the most intense PSM per ion (see here for a step-by-step explanation of the code). Upon this filtering every feature is unique to a ion identifier (peptide sequence + charge), and we hence can join sets using that identifier.\n\n\nfor (i in logNames) {\n  rowdata &lt;- rowData(spikein[[i]]) \n  rowdata$ionID &lt;- paste0(rowdata$Sequence, rowdata$Charge) \n  rowdata$value &lt;- assay(spikein[[i]])[, 1]\n  rowdata &lt;- data.frame(rowdata) |&gt;\n    group_by(ionID) |&gt;\n    mutate(psmRank = rank(-value))\n  rowData(spikein[[i]])$psmRank &lt;- rowdata$psmRank\n  rowData(spikein[[i]])$ionID &lt;- rowdata$ionID\n}\nspikein &lt;- filterFeatures(spikein, ~ psmRank == 1, keep = TRUE)\nspikein &lt;- joinAssays(spikein, logNames, \"ions_log\", \"ionID\")\n\n\nFeature filtering\n\n\nspikein &lt;- filterFeatures(\n        spikein, ~ Proteins != \"\" & ## Remove failed protein inference\n          !grepl(\";\", Proteins) & ## Remove protein groups\n          Reverse != \"+\" & ## Remove decoys\n          (Potential.contaminant != \"+\") ## Remove contaminants\n)\n\n\nMissing value filtering\n\n\nn &lt;- ncol(spikein[[\"ions_log\"]])\nspikein &lt;- filterNA(spikein, i = \"ions_log\", pNA = (n - 4) / n)\n\n\n4.3.1 Explore normalisation methods\nRemember that normalisation aims to correct for systematic fluctuations across samples, as illustrated by plotting the intensity distribution for each sample. The method applies the following operation on each sample \\(i\\) across all PSMs \\(p\\):\n\\[\ny_{ip}^{\\text{norm}} = y_{ip} - \\hat{\\mu}_i\n\\]\nwith \\(\\mathbf{y}\\) the log intensities and _i$ the norm factor.\nWe previously showed that the Median of Ratios (popularized by DESeq2) method could (partly) correct for these systematic fluctuations. We abbreviate this method as the MedianOfRatios method. The norm factor used by MedianOfRatios is estimated as follows:\n\\[\n\\hat{\\mu}^\\text{MedianOfRatios}_i = \\text{median}(y_{i\\cdot} - \\frac{1}{n}\\sum\\limits_{i = 1}^ny_{i\\cdot})\n\\]\nWe create a new set called ions_norm_MedianOfRatios that contains the values normalised by MedianOfRatios.\n\npseudoRef &lt;- rowMeans(assay(spikein[[\"ions_log\"]]), na.rm = TRUE)\nnfLog &lt;- sweep(assay(spikein[[\"ions_log\"]]), MARGIN = 1, pseudoRef) |&gt; \n  colMedians(na.rm = TRUE)\nspikein &lt;- sweep(\n  spikein, MARGIN = 2, STATS = nfLog, \n  i = \"ions_log\", name = \"ions_norm_MedianOfRatios\"\n)\n\nHowever, other methods exist, median centering being the most popular. Median centering normalisation subtracts the median intensity of each sample from all its measurements. A key assumption for this method is that the majority of proteins are not differentially abundant. We abbreviate this method as the MedianCentering method. The norm factor used by MedianOfRatios is estimated as follows:\n\\[\n\\hat{\\mu}^\\text{MedianCentering}_i = \\text{median}(y_{i\\cdot})\n\\]\nWe create a new set called ions_norm_MedianCentering that contains the values normalised by MedianCentering.\n\nspikein &lt;- normalize(\n  spikein, method = \"center.median\", i = \"ions_log\", \n  name = \"ions_norm_MedianCentering\"\n)\n\nWe visually explore the impact of the normalisation methods on the intensity distribution for each sample.\n\nlongForm(\n  spikein[, , c(\"ions_norm_MedianOfRatios\", \"ions_norm_MedianCentering\")],\n  colvars = c(\"Concentration\", \"Condition\")\n) |&gt;\n  data.frame() |&gt; \n  mutate(normalisation = sub(\"ions_norm_\", \"\", assay)) |&gt;\n  ggplot() +\n  aes(x = value,\n      colour = Condition,\n      group = colname) +\n  geom_density() +\n  facet_grid(~ normalisation, scales = \"free\") +\n  labs(title = \"Intensity distribution for all samples\",\n       subtitle = \"After normalisation\")\n\n\n\n\n\n\n\n\nBoth the median centering and median or ratio normalisation achieve similar alignment of the intensity distributions. Although they appear visually similar, we will see later that they can lead to different results in statistical inference.\nNotice that the QFeatures object contains two diverging assays, one for each normalisation method.\n\nplot(spikein, interactive = TRUE)\n\n\n\n\n\n\n\n4.3.2 Explore summarisation methods\nWith the data normalised, the next step is to summarise ion-level intensities to obtain protein-level expression values. In this chapter, we will compare three summarisation methods:\n\nRobust summarisation (Sticker et al. 2020), as we described in a previous chapter.\nMedian summarisation, which calculates the median of the log-transformed intensities of all peptides belonging to a protein for each sample separately. While robust to outliers, it can be heavily influenced by inconsistent peptide identification across samples.\nMedian polish summarisation, a non-parametric iterative method that decomposes the peptide-by-sample intensity matrix into peptide effects (rows) and sample effects (columns). The resulting column effects are used as the summarised protein abundances. It is robust and much faster than model-based approaches.\n\nAll these summarisation methods are available in MsCoreUtils and can be integrated feeded to QFeatures.\n\nlibrary(\"MsCoreUtils\")\nsummMethods &lt;- c(\n  robustSummary = MsCoreUtils::robustSummary, \n  colMedians = colMedians, \n  medianPolish = MsCoreUtils::medianPolish\n)\n\nWe will therefore create a loop that iterates over the normalised data sets and over the summarisation methods.\n\nfor (i in c(\"ions_norm_MedianOfRatios\", \"ions_norm_MedianCentering\")) {\n  for (j in names(summMethods)) {\n    newSet &lt;- paste0(\"proteins_\", sub(\"ions_norm_\", \"\", i), \"_\", j)\n    spikein &lt;- aggregateFeatures(\n      spikein, i = i, \n      name = newSet,\n      fcol = \"Proteins\", \n      fun = summMethods[[j]],\n      na.rm = TRUE\n    )\n  }\n}\n\nThe data processing is now complete. The QFeatures object now contains a workflow of assays, from input PSMs to normalised and summarised proteins. The data set contains 2 sets obtained using 2 normalisation methods, and each normalised set has been summarised with 3 different methods.\n\nplot(spikein, interactive = TRUE)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Optimisation of a data analysis workflow</span>"
    ]
  },
  {
    "objectID": "04-workflow_optimisation.html#data-modelling",
    "href": "04-workflow_optimisation.html#data-modelling",
    "title": "4  Optimisation of a data analysis workflow",
    "section": "4.4 Data modelling",
    "text": "4.4 Data modelling\nThe preprocessed data for all 6 workflows1 can now be modelled to assess our research hypothesis using the same approach, as described in the basics chapter2. Remember, the central research question is to “prioritise proteins that have been spiked in across the conditions.” Since we know the ground truth, we can assess how accurately the model estimates the fold changes between spike-in conditions, and hence which preprocessing workflow leads to the best results.\nWe loop over the different assays to fit the model for the different preprocessed sets3. Recall that the model estimation results are stored in the rowData of each set.\n\nproteinSets &lt;- grep(\"proteins_\", names(spikein), value = TRUE)\nfor (i in proteinSets) {\n  spikein &lt;- msqrob(\n    spikein,  i = i, formula = ~ Condition, ridge = TRUE, robust = TRUE\n  )\n}\n\nWe enable M-estimation (robust = TRUE) for improved robustness against outliers and ridge regression (ridge = TRUE) to stabilise parameter estimates. While the stabilising effects of ridge regression are most pronounced in complex models with many parameters, we enable it here to ensure robust parameter estimation and for consistency with more advanced workflows.\nWe can create our contrasts of interest and perform hypothesis testing.\n\nallContrasts &lt;- createPairwiseContrasts(\n    ~ Condition, colData(spikein), var = \"Condition\", ridge = TRUE\n)\nL &lt;- makeContrast(\n    allContrasts, \n    c(\"ridgeConditionB\", \"ridgeConditionC\", \"ridgeConditionD\", \"ridgeConditionE\")\n)\ninferences &lt;- lapply(proteinSets, function(i) {\n  spikein &lt;- hypothesisTest(spikein, i, contrast = L)\n  inference &lt;- msqrobCollect(spikein[[i]], L)\n  inference$method &lt;- i\n  inference\n})\ninferences &lt;- do.call(rbind, inferences)\n\nWe also add the information whether a protein is differentially abundant or not, since all E. Coli proteins are known to be spiked in different concentrations.\n\ninferences &lt;- mutate(\n  inferences,\n  isEcoli = feature %in% ecoli,\n  normalisation = sub(\"(.*)_(.*)_(.*)\", \"\\\\2\", method),\n  summarisation = sub(\"(.*)_(.*)_(.*)\", \"\\\\3\", method),\n  contrast = gsub(\"ridgeCondition\", \"\", contrast),\n  contrast = gsub(\"^([B-E])$\", \"\\\\1 - A\", contrast),\n)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Optimisation of a data analysis workflow</span>"
    ]
  },
  {
    "objectID": "04-workflow_optimisation.html#performance-evaluation",
    "href": "04-workflow_optimisation.html#performance-evaluation",
    "title": "4  Optimisation of a data analysis workflow",
    "section": "4.5 Performance Evaluation",
    "text": "4.5 Performance Evaluation\nSince we have ground truth information (i.e., we know which proteins are from E. coli and should be differentially abundant), we can objectively evaluate the performance of each workflow. Similarly to the previous chapter, we will assess the number of true positives (TP, that are correctly identified E. coli proteins) and false positives (FP, that are human proteins incorrectly identified as significant), the false discovery proportion (FDP), the accuracy of the estimated log2 fold changes (LFC), and finally, the overall performance using True Positive Rate (TPR) versus False Discovery Proportion (FDP) curves.\nBefore delving into the performance plot, we will first create a colour scheme in order to compare the different workflows. We will assign a colour to each combination of normalisation and summarisation method.\n\ninferences &lt;- mutate(\n  inferences,\n  workflow = paste0(normalisation, \"_\", summarisation)\n)\ncolours &lt;- c(\n  MedianCentering_colMedians = \"#fcba03\",\n  MedianCentering_medianPolish = \"#c29310\",\n  MedianCentering_robustSummary = \"#423512\",\n  MedianOfRatios_colMedians = \"#5bb4fc\",\n  MedianOfRatios_medianPolish = \"#0b69b5\",\n  MedianOfRatios_robustSummary = \"#0f2a40\"\n)\n\n\n4.5.1 TP and FP at 5% FDR\nWe will first construct the table with TPs and FPs obtained from each data modelling approach for each comparison.\n\ntpFpTable &lt;- group_by(inferences, normalisation, workflow, contrast) |&gt;\n    filter(adjPval &lt; 0.05) |&gt;\n    summarise(\"True Positives\" = sum(isEcoli),\n              \"False Positives\" = sum(!isEcoli),\n              FDP = mean(!isEcoli)) |&gt;\n    pivot_longer(cols = c(\"True Positives\", \"False Positives\"),\n                 names_to = \"metric\", values_to = \"count\")\n\nWe then plot the table as a bar plot, facetting for every comparison.\n\nggplot(tpFpTable) +\n  aes(\n    x = normalisation, y = count,\n    fill = workflow\n  ) +\n  geom_bar(\n    stat = \"identity\", position = position_dodge(preserve = \"single\"),\n    color = \"black\"\n  ) +\n  facet_grid(contrast ~ metric, scales = \"free\") +\n  scale_fill_manual(values = colours) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\nWe see that, while it has minimal impact on the TPs, the median centering normalisation approach increases the number of FPs for some comparisons (E-A and E-B). We therefore suggest to use the Median of ratio’s normalisation method.\nMore importantly, we see that summarising using the column median leads to poor performance (irrespective of the normalisation method used) as these workflow identify less TPs. This can be easily explained as the summarisation step in this workflow does not account for the fact that different PSMs are often observed for a protein in the different samples and that their corresponding intensities largely fluctuate according to the differences in the PSM characteristics. The median polish and the robust summary summarisation show similar performance. Note, however, that median polish is computationally less demanding.\n\n\n4.5.2 TPR-FDP curves\nWe generate the TPR-FDP curves to assess the performance of the different workflows to prioritise differentially abundant proteins. Again, these curves are built using the ground truth information about which proteins are differentially abundant (spiked in) and which proteins are constant across samples. We create two functions to compute the TPR and the FDP.\n\ncomputeFDP &lt;- function(pval, tp) {\n    ord &lt;- order(pval)\n    fdp &lt;- cumsum(!tp[ord]) / 1:length(tp)\n    fdp[order(ord)]\n}\ncomputeTPR &lt;- function(pval, tp, nTP = NULL) {\n    if (is.null(nTP)) nTP &lt;- sum(tp)\n    ord &lt;- order(pval)\n    tpr &lt;- cumsum(tp[ord]) / nTP\n    tpr[order(ord)]\n}\n\nWe apply these functions and compute the corresponding metric using the statistical inference results and the ground truth information.\nWe also highlight the observed FDP at a 5% FDR threshold.\n\nworkPoints &lt;- group_by(performance, summarisation, normalisation, contrast) |&gt;\n    filter(adjPval &lt; 0.05) |&gt;\n    slice_max(adjPval)\n\nWe can now generate the plot4.\n\nggplot(performance) +\n    aes(\n        y = fdp,\n        x = tpr,\n        colour = workflow\n    ) +\n    geom_line() +\n    geom_point(data = workPoints, size = 3) +\n    geom_hline(yintercept = 0.05, linetype = 2) +\n    facet_grid(contrast ~ .) +\n    coord_flip(ylim = c(0, 0.2)) +\n    scale_colour_manual(values = colours)\n\n\n\n\n\n\n\n\nAgain, we also observe a benefit of the MedianOfRatios normalisation, which seems to improve the FDR control accross the board5 as well as the sensitivity in contrasts involving the higher spike-in conditions.\nTPR-FDP curves also clearly indicate a suboptimal performance (lower sensitivity at the same false discovery proportion) of median summarisation.\n\n\n4.5.3 Fold change boxplots\nFinally, we estimate the accuracy and precision of the log2-fold changes using boxplots. We first create a table with the ground truth information from the spike-in experiment.\n\nrealLogFC &lt;- data.frame(\n  expectedLogFC = t(L) %*% lm(log2(Concentration) ~ Condition, colData(spikein))$coef[-1]\n)\nrealLogFC$contrast &lt;- gsub(\"ridgeCondition\",\"\",colnames(L))\nrealLogFC$contrast &lt;- gsub(\"^([B-E])$\", \"\\\\1 - A\", realLogFC$contrast)\n\nWe now plot the estimated log2-fold changes, focusing on the differentially abundant proteins (E. Coli proteins). The dashed line represents the true log2-fold change for each comparison.\n\nfilter(inferences, isEcoli) |&gt; \n  ggplot() +\n  aes(\n      y = logFC,\n      x = normalisation,\n      colour = workflow\n  ) +\n  geom_boxplot()  +\n  facet_grid(contrast ~ ., scales = \"free\") +\n  geom_hline(data = realLogFC, aes(yintercept = expectedLogFC), \n             linetype = \"dashed\") +\n  scale_colour_manual(values = colours) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\nThe plots show that median summarisation produces biased fold change estimates, again because it does not account for the differences in the characteristics of the PSMs that are observed in the different samples.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Optimisation of a data analysis workflow</span>"
    ]
  },
  {
    "objectID": "04-workflow_optimisation.html#conclusion",
    "href": "04-workflow_optimisation.html#conclusion",
    "title": "4  Optimisation of a data analysis workflow",
    "section": "4.6 Conclusion",
    "text": "4.6 Conclusion\nIn this chapter, we objectively compared different normalisation and summarisation strategies using a spike-in dataset with known ground truth.\n\nNormalisation is critical: The performance evaluation clearly shows that the choice of normalisation method has a significant impact on the results. Workflows using the median-of-ratios normalisation consistently outperformed those using simple median centering. They yielded more true positives, better control of the false discovery proportion, and more accurate log2-fold change estimates, particularly for smaller fold changes.\nColumn median summarisation is suboptimal: we found that summarising peptide data to protein intensities using the column (sample) median leads to reduced sensitivity (low True Positive Rate) and specificity (low False Discovery Proportion), but also to lower accuracy (i.e. the estimated log2-fold changes are further from the true value on average) and precision (the estimations are more spread around the average estimation).\nMedian polish and robust summary provide comparable performance: the TPR-FDP curves show that the pipelines incorporating robust summarisation and median polish are consistently closer to the ideal top-left corner, with only subtle differences between the two approaches. This indicates that explicitly modelling peptide-specific effects and down-weighting outliers leads to more reliable protein-level quantification and inference. Note that median polish summarisation is computationally less demanding and that we could not find a benefit in performance for robust summarisation that justifies its additional computational overhead.\n\nBased on this comprehensive evaluation, the recommended pipeline for this type of dataset is the median-of-ratios normalisation followed by median polish summarisation. This combination provided the best performance in terms of computational complexity, accuracy, sensitivity and FDR control, demonstrating the strength of msqrob2 in identifying truly differentially abundant proteins while controlling for false discoveries.\nTODO discuss that data analysis optimisation is data set dependent, and other conclusion may be reached on other datasets?\n\n\n\n\nShen, Xiaomeng, Shichen Shen, Jun Li, Qiang Hu, Lei Nie, Chengjian Tu, Xue Wang, et al. 2018. “IonStar Enables High-Precision, Low-Missing-Data Proteomics Quantification in Large Biological Cohorts.” Proc. Natl. Acad. Sci. U. S. A. 115 (21): E4767–76.\n\n\nSticker, Adriaan, Ludger Goeminne, Lennart Martens, and Lieven Clement. 2020. “Robust Summarization and Inference in Proteome-Wide Label-Free Quantification.” Mol. Cell. Proteomics 19 (7): 1209–19.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Optimisation of a data analysis workflow</span>"
    ]
  },
  {
    "objectID": "04-workflow_optimisation.html#footnotes",
    "href": "04-workflow_optimisation.html#footnotes",
    "title": "4  Optimisation of a data analysis workflow",
    "section": "",
    "text": "There are 2 normalisaion methods * 3 summarisation methods.↩︎\nNote that while we changed the preprocessing workflow, the sources of variation and the model to estimate remain the same as in Chapter 1.↩︎\nThose sets that start with proteins_.↩︎\nNote that the code to build the TPR-FDP curves is identical to the workflow in the previous chapter on data benchmarking.↩︎\nthe dots indicating the sensitivity and FDP when using a 5% FDR cut-off are much closer to the empirical 5% FDP↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Optimisation of a data analysis workflow</span>"
    ]
  },
  {
    "objectID": "05-francisella.html",
    "href": "05-francisella.html",
    "title": "5  The francisella use case: a MaxQuant LFQ DDA dataset with technical replication",
    "section": "",
    "text": "5.1 Introduction\nIn this chapter we show how to analyse LFQ data with technical replication. In the data analysis we have to acknowledge pseudo-replication, i.e. data for multiple technical replicates from the same biological repeat are correlated and we cannot treat these as independent repeats.\nWe will build upon the mixed model framework in msqrob2 to address this correlation by introducing a random effect for each biological repeat.\nIf you never used msqrob2, we suggest to familiarise yourself with the concepts chapter first.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The francisella use case: a MaxQuant LFQ DDA dataset with technical replication</span>"
    ]
  },
  {
    "objectID": "05-francisella.html#load-packages",
    "href": "05-francisella.html#load-packages",
    "title": "5  The francisella use case: a MaxQuant LFQ DDA dataset with technical replication",
    "section": "5.2 Load packages",
    "text": "5.2 Load packages\nFirst, we load the msqrob2 package and additional packages for data manipulation and visualisation.\n\nlibrary(\"msqrob2\")\nlibrary(\"ggplot2\")\nlibrary(\"ggrepel\")\nlibrary(\"dplyr\")\n\nWe also configure the parallelisation framework.\n\nlibrary(\"BiocParallel\")\nregister(SerialParam())",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The francisella use case: a MaxQuant LFQ DDA dataset with technical replication</span>"
    ]
  },
  {
    "objectID": "05-francisella.html#load-data",
    "href": "05-francisella.html#load-data",
    "title": "5  The francisella use case: a MaxQuant LFQ DDA dataset with technical replication",
    "section": "5.3 Load data",
    "text": "5.3 Load data\n\n5.3.1 Experimental context\nA study on the facultative pathogen Francisella tularensis was conceived by (Ramond et al. 2015). F. tularensis enters the cells of its host by phagocytosis. The authors showed that F. tularensis is arginine deficient and imports arginine from the host cell via an arginine transporter, ArgP, in order to efficiently escape from the phagosome and reach the cytosolic compartment, where it can actively multiply. In their study, they compared the proteome of wild type F. tularensis (WT) to ArgP-gene deleted F. tularensis (knock-out, D8). For this exercise, we use a subset of the F. tularensis dataset where bacterial cultures were grown in biological triplicate and each biorep was run in technical triplicate on a nanoRSLC-Q Exactive PLUS instrument.\n\n\n5.3.2 Getting the data\nThe data were searched with MaxQuant version 1.4.1.2. and are available on the PRIDE repository: PXD001584. We download the peptides file1.\nTODO put on Zenodo and use BiocFileCache\n\nlibrary(\"BiocFileCache\")\nbfc &lt;- BiocFileCache()\npepFile &lt;- bfcrpath(bfc, \"https://raw.githubusercontent.com/statOmics/MSqRobSumPaper/master/Francisella/data/maxquant/peptides.txt\")\n\nAfter downloading the files, we can load the peptide table. Contrarily a PSM table, the peptide table is provided in a “wide format”, meaning that each row represents a single peptide and that each quantification column (that starts with \"Intensity\") represents a single sample.\n\npeps &lt;- read.delim(pepFile)\nquantcols &lt;- grep(\"Intensity\\\\.\", names(peps), value = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequence\nAmino.acid.before\nFirst.amino.acid\nSecond.amino.acid\nSecond.last.amino.acid\nLast.amino.acid\nAmino.acid.after\nA.Count\nR.Count\nN.Count\nD.Count\nC.Count\nQ.Count\nE.Count\nG.Count\nH.Count\nI.Count\nL.Count\nK.Count\nM.Count\nF.Count\nP.Count\nS.Count\nT.Count\nW.Count\nY.Count\nV.Count\nU.Count\nLength\nMissed.cleavages\nMass\nProteins\nGI.number\nLeading.razor.protein\nProtein.names\nUnique..Groups.\nUnique..Proteins.\nCharges\nPEP\nScore\nExperiment.1WT_20_2h_n3_1\nExperiment.1WT_20_2h_n3_2\nExperiment.1WT_20_2h_n3_3\nExperiment.1WT_20_2h_n4_1\nExperiment.1WT_20_2h_n4_2\nExperiment.1WT_20_2h_n4_3\nExperiment.1WT_20_2h_n5_1\nExperiment.1WT_20_2h_n5_2\nExperiment.1WT_20_2h_n5_3\nExperiment.3D8_20_2h_n3_1\nExperiment.3D8_20_2h_n3_2\nExperiment.3D8_20_2h_n3_3\nExperiment.3D8_20_2h_n4_1\nExperiment.3D8_20_2h_n4_2\nExperiment.3D8_20_2h_n4_3\nExperiment.3D8_20_2h_n5_1\nExperiment.3D8_20_2h_n5_2\nExperiment.3D8_20_2h_n5_3\nIntensity\nIntensity.1WT_20_2h_n3_1\nIntensity.1WT_20_2h_n3_2\nIntensity.1WT_20_2h_n3_3\nIntensity.1WT_20_2h_n4_1\nIntensity.1WT_20_2h_n4_2\nIntensity.1WT_20_2h_n4_3\nIntensity.1WT_20_2h_n5_1\nIntensity.1WT_20_2h_n5_2\nIntensity.1WT_20_2h_n5_3\nIntensity.3D8_20_2h_n3_1\nIntensity.3D8_20_2h_n3_2\nIntensity.3D8_20_2h_n3_3\nIntensity.3D8_20_2h_n4_1\nIntensity.3D8_20_2h_n4_2\nIntensity.3D8_20_2h_n4_3\nIntensity.3D8_20_2h_n5_1\nIntensity.3D8_20_2h_n5_2\nIntensity.3D8_20_2h_n5_3\nReverse\nContaminant\nid\nProtein.group.IDs\nMod..peptide.IDs\nEvidence.IDs\nMS.MS.IDs\nBest.MS.MS\nOxidation..M..site.IDs\n\n\n\n\nAAAEELDTR\nK\nA\nA\nT\nR\nK\n3\n1\n0\n1\n0\n0\n2\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n9\n0\n974.4669\nWP_003038655\ngi|118497196\ngi|118497196\nhypothetical protein [Francisella tularensis]\nyes\nyes\n1,2\n0.0001253\n59.35\nNA\nNA\n1\n1\nNA\n1\nNA\n1\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1.3295e+09\n0\n0\n9290400\n92996000\n0\n98059000\n0\n80803000\n0\n0\n95433000\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n419\n0\n0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18\n0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18\n15\n\n\n\nAAAGFVITASHNK\nR\nA\nA\nN\nK\nF\n4\n0\n1\n0\n0\n0\n0\n1\n1\n1\n0\n1\n0\n1\n0\n1\n1\n0\n0\n1\n0\n13\n0\n1285.6779\nWP_003041237\ngi|118498194\ngi|118498194\nphosphoglucosamine mutase [Francisella tularensis]\nyes\nyes\n2\n0.0000530\n45.825\nNA\n1\nNA\nNA\nNA\nNA\nNA\n1\n1\n1\n1\nNA\n1\n1\n1\n1\nNA\nNA\n1.6719e+08\n0\n20679000\n0\n0\n0\n0\n0\n17358000\n13841000\n12278000\n10712000\n0\n9500700\n11111000\n8723500\n8125200\n0\n0\n\n\n1\n1150\n1\n19;20;21;22;23;24;25;26;27;28;29;30;31;32;33\n19;20;21;22;23;24;25;26;27;28;29;30;31;32;33\n26\n\n\n\nAAANEYELALAYSIEEVAPDLHK\nK\nA\nA\nH\nK\nY\n6\n0\n1\n1\n0\n0\n4\n0\n1\n1\n3\n1\n0\n0\n1\n1\n0\n0\n2\n1\n0\n23\n0\n2516.2435\nWP_003038915\ngi|118497331\ngi|118497331\nglycine–tRNA ligase subunit beta [Francisella tularensis]\nyes\nyes\n3\n0.0000000\n84.327\n1\n1\n2\n1\n1\n1\n2\n2\n1\n1\n2\n1\n1\n1\n1\nNA\n1\n1\n5.5675e+08\n28853000\n28091000\n30436000\n19476000\n22050000\n20687000\n36588000\n28654000\n7009100\n14174000\n8548000\n7859200\n14871000\n11690000\n4470500\n0\n4048100\n3422300\n\n\n2\n513\n2\n34;35;36;37;38;39;40;41;42;43;44;45;46;47;48;49;50;51;52;53;54;55;56;57;58;59;60;61;62;63;64;65;66;67;68;69;70;71;72;73;74;75;76\n34;35;36;37;38;39;40;41;42;43;44;45;46;47;48;49;50;51;52;53;54;55;56;57;58;59;60;61;62;63;64;65;66;67;68;69;70;71;72;73;74;75;76;77;78;79\n39\n\n\n\nAAANNPQLEAFK\nK\nA\nA\nF\nK\nK\n4\n0\n2\n0\n0\n1\n1\n0\n0\n0\n1\n1\n0\n1\n1\n0\n0\n0\n0\n0\n0\n12\n0\n1272.6463\nWP_003038264\ngi|118496879\ngi|118496879\nmolecular chaperone HtpG [Francisella tularensis]\nyes\nyes\n2\n0.0000000\n108.56\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1.4830e+10\n339830000\n420390000\n393930000\n235060000\n381090000\n360270000\n255710000\n311370000\n271440000\n225140000\n289880000\n282500000\n209490000\n223610000\n219700000\n169120000\n178150000\n170400000\n\n\n3\n199\n3\n77;78;79;80;81;82;83;84;85;86;87;88;89;90;91;92;93;94;95;96;97;98;99;100;101;102;103;104;105;106;107;108;109;110;111;112;113;114;115;116;117;118;119;120;121;122;123;124\n80;81;82;83;84;85;86;87;88;89;90;91;92;93;94;95;96;97;98;99;100;101;102;103;104;105;106;107;108;109;110;111;112;113;114;115;116;117;118;119;120;121;122;123;124;125;126;127;128;129;130;131;132;133;134;135;136;137;138;139;140;141;142;143;144;145;146;147;148;149;150;151;152;153;154;155;156;157;158;159;160;161;162;163;164;165;166;167;168;169;170;171;172\n159\n\n\n\nAAASAGLVDEK\nK\nA\nA\nE\nK\nA\n4\n0\n0\n1\n0\n0\n1\n1\n0\n0\n1\n1\n0\n0\n0\n1\n0\n0\n0\n1\n0\n11\n0\n1030.5295\nWP_003035781\ngi|118497152\ngi|118497152\ndelta-aminolevulinic acid dehydratase [Francisella tularensis]\nyes\nyes\n2\n0.0000951\n67.385\n1\nNA\n1\n1\n1\nNA\n1\n1\n1\n1\n1\n1\n1\n1\nNA\n1\n1\n1\n4.8209e+09\n240280000\n0\n241890000\n222250000\n189930000\n0\n160440000\n147230000\n143340000\n135910000\n185740000\n168620000\n160240000\n158000000\n0\n92542000\n102350000\n100090000\n\n\n4\n388\n4\n125;126;127;128;129;130;131;132;133;134;135;136;137;138;139;140;141;142;143;144;145;146;147;148;149;150;151;152;153;154;155\n173;174;175;176;177;178;179;180;181;182;183;184;185;186;187;188;189;190;191;192;193;194;195;196;197;198;199;200;201;202;203\n191\n\n\n\nAAASLDLYSYPK\nK\nA\nA\nP\nK\nV\n3\n0\n0\n1\n0\n0\n0\n0\n0\n0\n2\n1\n0\n0\n1\n2\n0\n0\n2\n0\n0\n12\n0\n1297.6554\nWP_003039212\ngi|118497492\ngi|118497492\nphosphorylase [Francisella tularensis]\nyes\nyes\n2\n0.0125630\n31.675\nNA\n1\n1\nNA\n1\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\n1.3715e+08\n0\n31069000\n31448000\n0\n27721000\n28657000\n0\n0\n0\n0\n0\n0\n0\n18253000\n0\n0\n0\n0\n\n\n5\n624\n5\n156;157;158;159;160\n204;205;206;207;208\n205\n\n\n\n\n\n\nWe now extract the sample annotations. We will build a table where each row in the annotation table contains information for one sample (the table below shows the first 6 rows). This information is extracted from the sample names.\n\ncoldata &lt;- data.frame(quantCols = quantcols) |&gt; \n  filter(grepl(\"_20_\", quantCols) & grepl(\"_n\\\\d\", quantCols)) |&gt; \n  mutate(genotype  = substr(quantCols, 12, 13), \n         biorep  = paste0(genotype, \"_\", substr(quantCols, 21, 22)),\n         run = 1:length(quantcols))\n\n\n\n\n\n\nquantCols\ngenotype\nbiorep\nrun\n\n\n\n\nIntensity.1WT_20_2h_n3_1\nWT\nWT_n3\n1\n\n\nIntensity.1WT_20_2h_n3_2\nWT\nWT_n3\n2\n\n\nIntensity.1WT_20_2h_n3_3\nWT\nWT_n3\n3\n\n\nIntensity.1WT_20_2h_n4_1\nWT\nWT_n4\n4\n\n\nIntensity.1WT_20_2h_n4_2\nWT\nWT_n4\n5\n\n\nIntensity.1WT_20_2h_n4_3\nWT\nWT_n4\n6\n\n\n\n\n\n\n\n5.3.3 The QFeatures data class\nWe combine the two tables into a QFeatures object.\n\n(pe &lt;- readQFeatures(\n  peps, colData = coldata, fnames = \"Sequence\", name = \"peptides\"\n))\n\nAn instance of class QFeatures (type: bulk) with 1 set:\n\n [1] peptides: SummarizedExperiment with 10693 rows and 18 columns \n\n\nWe now have a QFeatures object with 1 set, containing r nrows(pe)[[1]] rows (peptides) and 18 columns (samples).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The francisella use case: a MaxQuant LFQ DDA dataset with technical replication</span>"
    ]
  },
  {
    "objectID": "05-francisella.html#data-preprocessing",
    "href": "05-francisella.html#data-preprocessing",
    "title": "5  The francisella use case: a MaxQuant LFQ DDA dataset with technical replication",
    "section": "5.4 Data preprocessing",
    "text": "5.4 Data preprocessing\nmsqrob2 relies on the QFeatures data structure, meaning that we can directly make use of QFeatures’ data preprocessing functionality (see also the QFeatures documentation).\n\n5.4.1 Encoding missing values\nPeptides with zero intensities should be encoded using NA.\n\npe &lt;- zeroIsNA(pe, \"peptides\")\n\nWe calculate how many non zero intensities we have per peptide and this is often useful for filtering.\n\nnaResults &lt;- nNA(pe, \"peptides\")\ndata.frame(naResults$nNArows) |&gt; \n  ggplot() +\n  aes(x = nNA) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n5.4.2 Peptide filtering\nWe filter peptides based on 3 criteria (see [PSM filtering]).\n\nRemove failed protein inference\n\nWe remove peptides that could not be uniquely mapped to a protein.\n\npe &lt;- filterFeatures(pe,\n  ~ Proteins != \"\" & ## Remove failed protein inference\n    !grepl(\";\", Proteins)) ## Remove protein groups\n\n\nRemove reverse sequences and contaminants\n\nWe now remove the contaminants and peptides that map to decoy sequences. These features bear no information of interest and will reduce the statistical power upon multiple test adjustment.\n\npe &lt;- filterFeatures(pe, ~ Reverse != \"+\" & Contaminant != \"+\")\n\n\nDrop peptides that were only identified in a single biorepeat\n\nNote, that in experiments without technical repeats we filter on the number of samples in which a peptide is picked up (this is typically performed using filterNA()). Here, we will require that a peptide is picked up in at least two biorepeats. We compute the number of biorepeats that were observed for each peptide (that is the number of biorepeats that contain at least one observed value).\n\nrowData(pe[[\"peptides\"]])$nNonZeroBiorep &lt;- apply(\n  assay(pe[[\"peptides\"]]), 1, function(intensity)\n    pe$biorep[!is.na(intensity)] |&gt; \n    unique() |&gt; \n    length()\n)\n\nWe keep peptides that are observed in at least two biorepeats.\n\n(pe &lt;- filterFeatures(pe, ~ nNonZeroBiorep &gt;= 2))\n\nAn instance of class QFeatures (type: bulk) with 1 set:\n\n [1] peptides: SummarizedExperiment with 7542 rows and 18 columns \n\n\nWe keep 7542 peptides upon filtering.\n\n\n5.4.3 Standard preprocessing workflow\nWe can now prepare the data for modelling. The workflow ensures the data complies to msqrob2’s requirements:\n\nIntensities are log-transformed.\n\n\npe &lt;- logTransform(pe, base = 2, i = \"peptides\", name = \"peptides_log\")\n\n\nNormalisation with the Median of Ratios method.\n\n\npseudoRef &lt;- assay(pe[[\"peptides_log\"]]) |&gt; \n  rowMeans(na.rm = TRUE) #1. Calculate the row means \n\nnfLog &lt;- sweep(\n  assay(pe[[\"peptides_log\"]]), \n  MARGIN = 1, \n  pseudoRef) |&gt; #2. Subtract the row means row-by-row (MARGIN = 1)\n  colMedians(na.rm = TRUE)  #3. Calculate the column median \n\npe &lt;- \n  sweep(pe, \n        MARGIN = 2, \n        STATS = nfLog , \n        i = \"peptides_log\", \n        name = \"peptides_norm\") #4. Subtract log2 norm factor column-by-column (MARGIN = 2)\n\n\nUpon the normalisation the density curves should be nicely centred. To confirm this, we will plot the intensity distributions for each biorepeat (francisella culture). longForm() seamlessly combines the quantification and annotation data into a table suitable for ggplot2 visualisation. We also subset the object with the data before and after normalisation.\n\nlongForm(pe[, , c(\"peptides_log\", \"peptides_norm\")], colvar = \"biorep\") |&gt; \n  ggplot() +\n  aes(x = value, group = colname, color = biorep) +\n  geom_density() +\n  facet_wrap(~ assay, scale = \"free\")\n\n\n\n\n\n\n\n\n\nSummarisation to protein level.\n\nWe use the robust summary approach to infer protein-level data from peptide-level data, accounting for the fact that different peptides have ionisation efficiencies hence leading to different intensity baselines.\n\npe &lt;- aggregateFeatures(\n  pe, i = \"peptides_norm\", fcol = \"Proteins\", \n  fun = MsCoreUtils::robustSummary, na.rm = TRUE, name = \"proteins\"\n)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The francisella use case: a MaxQuant LFQ DDA dataset with technical replication</span>"
    ]
  },
  {
    "objectID": "05-francisella.html#data-exploration",
    "href": "05-francisella.html#data-exploration",
    "title": "5  The francisella use case: a MaxQuant LFQ DDA dataset with technical replication",
    "section": "5.5 Data exploration",
    "text": "5.5 Data exploration\nWe will explore the main sources of variation in the data using MDS.\n\nlibrary(\"scater\")\ngetWithColData(pe, \"proteins\") |&gt; \n  as(\"SingleCellExperiment\") |&gt; \n  runMDS(exprs_values = 1) |&gt; \n  plotMDS(colour_by = \"genotype\")\n\n\n\n\n\n\n\n\nNote that the samples upon robust summarisation show a clear separation according to the genotype in the first dimension of the MDS plot.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The francisella use case: a MaxQuant LFQ DDA dataset with technical replication</span>"
    ]
  },
  {
    "objectID": "05-francisella.html#data-modelling",
    "href": "05-francisella.html#data-modelling",
    "title": "5  The francisella use case: a MaxQuant LFQ DDA dataset with technical replication",
    "section": "5.6 Data modelling",
    "text": "5.6 Data modelling\nThe preprocessed data can now be modelled to answer biologically relevant questions. As described above, samples (bacterial cultures) originate from either a wildtype (WT) or a ArgP knockout (D8). Each genotype was cultured in biological triplicate. Each biological triplicate was acquired in technical triplicate, leading to \\(2 \\times\n3 \\times 3 = 18\\) samples. In this context, we are interested in the effects of genotype on the protein abundances.\nThe table below confirms we have a balanced design for each condition and biological triplicate.\n\ntable(genotype = pe$genotype, biorep = pe$biorep)\n\n        biorep\ngenotype D8_n3 D8_n4 D8_n5 WT_n3 WT_n4 WT_n5\n      D8     3     3     3     0     0     0\n      WT     0     0     0     3     3     3\n\n\n\n5.6.1 Sources of variation\nWe will model two sources of variation:\n\nGenotype: we model the source of variation induced by the experimental group of interest as a fixed effect. Fixed effects are effect that are considered non-random, i.e. the treatment effect is assumed to be the same and reproducible across repeated experiments, but it is unknown and has to be estimated. We will include genotype as a fixed effect that models the fact that a change in genotype can induce changes in protein abundance.\nBiological replicate effect: the experiment involves biological replication as the bacterial cultures are repeated. Replicate-specific effects occurs due to uncontrollable factors, such as variation in the number of bacterium seeded, position in the incubator, transient contamination,… Two bacterial cultures will never provide exactly the same sample material. These effects are typically modelled as random effects which are considered as a random sample from the population of all possible mice and are assumed to be i.i.d normally distributed with mean 0 and constant variance, \\(u_{biorep} \\sim\nN(0,\\sigma^{2,\\text{b}})\\). The use of random effects thus models the correlation in the data, explicitly. We expect that intensities from the same bacterial culture are more alike than intensities between cultures.\n\nHence, the variance-covariance matrix of the 18 protein abundance values \\(\\mathbf{Y}=(y_{wt\\_n3,1}, y_{wt\\_n3,2}, y_{wt\\_n3,3},\ny_{wt\\_n4,1} \\ldots y_{d8\\_n5,1}, y_{d8\\_n5,2}, y_{d8\\_n5,3})^T\\) is assumed to have a block diagonal structure, with as variance \\(\\sigma_b^2 + \\sigma_\\epsilon^2\\) and the covariance between protein abundance values of technical replicates from the same biorepeat equals \\(\\sigma_b^2\\) (with _^2 the variance of the residuals). More details on mixed models can be found in the advanced chapter.\nWe model the protein level expression values using msqrob2. msqrob2 workflows rely on linear mixed models, which are models that can estimate and predict fixed and random effects, respectively. The fixed effect are estimated using robust regression to avoid that outliers distort the statistical outcome.\nNote, that we cannot use ridge regression here to further stabilize the parameter estimation of the fixed effects. Ridge regression typically performs better the more slope parameters there are in the mean model (more complex designs). Here, the fixed effect consists of the genotype: knockout (D8) vs wild type (WT). By default the first group (D8) will become the reference group and its effect will be absorbed in the intercept of the model. Hence, only a single slope term is needed to model the average difference between D8 and WT (See Section Statistical inference below).\nNow we have identified the sources of variation in the experiment, we can define a model.\n\nmodel &lt;- ~ genotype + ## (1) fixed effect for genotype\n  (1 | biorep)  ## (2) random effect for biological replicate (culture)\n\n\n\n5.6.2 Estimate the model\nWe estimate the model with msqrob() (see the modelling section). Recall that variables defined in model are automatically retrieved from the colData (i.e. \"genotype\", and \"biorep\"). Note, that msqrob2 also features ridge regression for stabilising the parameter estimation, but it is irrelevant in this context as the genotype factor only has 2 levels (WT and D8), so ridge regression . We will therefore leave the ridge regression disabled (default).\n\npe &lt;- msqrob(pe, i = \"proteins\", formula = model, robust = TRUE)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The francisella use case: a MaxQuant LFQ DDA dataset with technical replication</span>"
    ]
  },
  {
    "objectID": "05-francisella.html#statistical-inference",
    "href": "05-francisella.html#statistical-inference",
    "title": "5  The francisella use case: a MaxQuant LFQ DDA dataset with technical replication",
    "section": "5.7 Statistical inference",
    "text": "5.7 Statistical inference\nOnce the models are estimated, we can start answering biological questions by performing Statistical inference. We must convert the biological question “does the bacterial genotype affect the protein intensities?” into a statistical hypothesis. In other words, we must convert this question in a combination of the model parameters, also referred to as a contrast. To aid defining contrasts, we will visualise the experimental design using the ExploreModelMatrix package. Note that with ExploreModelMatrix we can only visualise fixed effects part of the model. This is fine as the mean protein abundances can only systematically differ from each other according to the genotype (fixed effect).\n\nlibrary(\"ExploreModelMatrix\")\nvd &lt;- VisualizeDesign(\n    sampleData =  colData(pe),\n    designFormula = ~ genotype,\n    textSizeFitted = 4\n)\nvd$plotlist\n\n[[1]]\n\n\n\n\n\n\n\n\n\nThis plot shows that the average \\(\\log_2\\) protein intensity for the D8 group is modelled by (Intercept), and the the average \\(\\log_2\\) protein intensity for the WT group is modelled by (Intercept) + genotypeWT.\n\n5.7.1 Hypothesis testing\nHence we can translate the research hypothesis that there is an effect of the genotype on the protein abundance to the average log2 fold change (\\(\\log_2 FC\\)) between the WT and D8 groups, which boils down to (Intercept) + genotypeWT - (Intercept), and equals the genotypeWT parameter. The null hypothesis of the hypothesis test for this contrast is that the average \\(\\log2 FC\\) between D8 knock-out and WT is zero, or in other words that the genotypeWT parameter is zero.\n\nhypothesis &lt;- \"genotypeWT = 0\"\n\nWe next use makeContrast() to build the contrast matrix.\n\n(L &lt;- makeContrast(hypothesis, parameterNames = \"genotypeWT\"))\n\n           genotypeWT\ngenotypeWT          1\n\n\nIn this case, the contrast matrix is trivial, but it becomes a matrix but for more complex designs. We can now test our null hypothesis:\n\npe &lt;- hypothesisTest(pe, i = \"proteins\", contrast = L)\n\nLet us retrieve the result table from the rowData. Note that the hypothesis testing results are stored in rowData columns named after the column names (here genotypeWT) of the contrast matrix L.\n\ninference &lt;- rowData(pe[[\"proteins\"]])[[colnames(L)]]\ninference$Protein &lt;- rownames(inference)\nhead(inference)\n\n                   logFC         se        df          t         pval\nWP_003013731  0.08607313 0.13622311 14.515249  0.6318541 0.5373074487\nWP_003013860 -0.24361570 0.96333877  4.863216 -0.2528868 0.8106957489\nWP_003013909 -0.29604787 0.06878765 15.007538 -4.3037941 0.0006263236\nWP_003014068  0.11520522 0.15938527 14.142659  0.7228097 0.4815800326\nWP_003014122  0.20050168 0.11484365 17.854759  1.7458665 0.0980174216\nWP_003014123  0.11735634 0.14937755 14.599255  0.7856357 0.4446451519\n                 adjPval      Protein\nWP_003013731 0.740335646 WP_003013731\nWP_003013860 0.909709125 WP_003013860\nWP_003013909 0.006914364 WP_003013909\nWP_003014068 0.695546291 WP_003014068\nWP_003014122 0.253571752 WP_003014122\nWP_003014123 0.666917832 WP_003014123\n\n\nNotice that some rows contain missing values. This is because data modelling resulted in a fitError for some proteins, probably because not enough data was available for model fitting due to missing values in the quantitative data (see how to deal with fitErrors).\n\n\n5.7.2 Volcano-plot\nVolcano plots are straightforward to generate from the inference table above. We also use ggrepel to annotate the 20 most significant proteins.\n\nggplot(inference) +\n  aes(x = logFC, y = -log10(pval), color = adjPval &lt; 0.05) +\n  geom_point() +\n  geom_text_repel(data = slice_min(inference, adjPval, n = 20),\n                  aes(label = Protein)) +\n  scale_color_manual(values = alpha(c(\"black\", \"red\"), 0.5)) + \n  ggtitle(\"Statistical inference on differences between WT and D8\",\n          paste(\"Hypothesis test:\", colnames(L), \"= 0\"))\n\n\n\n\n\n\n\n\nNote, that 195 proteins are found to be differentially abundant.\n\n\n5.7.3 Heatmap\nWe can also build a heatmap for the significant proteins which are obtained by filtering the inference table. We first retrieve the data with proteins that are differentially abundant between the WT and the D8 genotype.\n\nsigNames &lt;- inference$Protein[!is.na(inference$adjPval) & inference$adjPval &lt; 0.05]\nse &lt;- getWithColData(pe, \"proteins\")[sigNames, ]\n\nWe then plot the protein-wise standardised data as an annotated heatmap.\n\nquants &lt;- t(scale(t(assay(se))))\nlibrary(\"ComplexHeatmap\")\nannotations &lt;- columnAnnotation(\n  condition = se$genotype\n)\nset.seed(1234) ## annotation colours are randomly generated by default\nHeatmap(\n quants, name = \"log2 intensity\",\n top_annotation = annotations\n)\n\n\n\n\n\n\n\n\n\n\n5.7.4 Detail plots\nLet us visualise the most significant protein. We perform this with a little data manipulation pipeline:\n\nIdentify the target protein with largest logFC.\nWe use the QFeatures subsetting functionality to retrieve all data related to the target protein, focusing on the proteins set that contains the preprocessed data used for modelling.\nWe use longForm() to convert the object into a table suitable for plotting.\nWe remove missing values for plotting.\nPlot the data with ggplot2.\n\n\ntargetProtein &lt;- rownames(inference)[which.min(inference$adjPval)] #1\npe[targetProtein, , \"proteins\"] |&gt; #2\n  longForm(colvars = \"genotype\") |&gt;  #3\n  data.frame() |&gt;\n  filter(!is.na(value)) |&gt; #4\n  ggplot() + #5\n  aes(x = colname,\n      y = value) +\n  geom_point(aes(colour = genotype)) +\n  labs(x = \"Sample\", y = \"log2 intensity\") +\n  ggtitle(targetProtein) +\n  theme(axis.text.x = element_text(angle = 30, hjust = 1))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The francisella use case: a MaxQuant LFQ DDA dataset with technical replication</span>"
    ]
  },
  {
    "objectID": "05-francisella.html#conclusion",
    "href": "05-francisella.html#conclusion",
    "title": "5  The francisella use case: a MaxQuant LFQ DDA dataset with technical replication",
    "section": "5.8 Conclusion",
    "text": "5.8 Conclusion\nIn this chapter, we illustrated the analysis of a label-free proteomics data set with technical replication. We followed the workflow described in the previous chapters with minimal changes, with a few exceptions.\nFirst, we removed peptides that were missing across biological replicates instead of across all samples. This filtering strategy uses the experimental design to better define interesting features. Indeed, peptides that are only found in a single francisella culture batch bears no interesting biological information. The QFeatures framework is amenable for this custom filtering.\nSecond, we could not perform ridge regression because the fixed effects contained only two levels. However, it is possible to disable ridge regression within mssqrob() thanks to the argument ridge = FALSE.\nThird, this data set has a more complex experimental design since there each biological replicate has been acquired in technical triplicate. Hence, we had to model\n\nthe variation according to the treatment, effect of interest and modelled using a fixed effect\nvariation between biological repeats, random effect as the francisella cultures will change each time we repeat the experiment, and\ntechnical variability, run to run variability and other sources of technical variability which are lumped in the residual variance.\n\nNote, that we could have performed the differential abundance analysis at the protein-level using ion- or peptide-level models, i.e. by using the msqrobAggregate on the peptide_log assay with a formula peptideModel &lt;- ~ genotype + (1|biorep) + (1|run) + (1|Sequence).\n\n\n\n\nRamond, Elodie, Gael Gesbert, Ida Chiara Guerrera, Cerina Chhuon, Marion Dupuis, Mélanie Rigard, Thomas Henry, Monique Barel, and Alain Charbit. 2015. “Importance of Host Cell Arginine Uptake in Francisella Phagosomal Escape and Ribosomal Protein Amounts.” Mol. Cell. Proteomics 14 (4): 870–81.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The francisella use case: a MaxQuant LFQ DDA dataset with technical replication</span>"
    ]
  },
  {
    "objectID": "05-francisella.html#footnotes",
    "href": "05-francisella.html#footnotes",
    "title": "5  The francisella use case: a MaxQuant LFQ DDA dataset with technical replication",
    "section": "",
    "text": "The file is locally cached↩︎",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The francisella use case: a MaxQuant LFQ DDA dataset with technical replication</span>"
    ]
  },
  {
    "objectID": "06-heart.html",
    "href": "06-heart.html",
    "title": "6  Heart use case: a MaxQuant LFQ DDA dataset with a more complex design",
    "section": "",
    "text": "6.1 Introduction\nIn this chapter we show how to analyse LFQ data from an experiment with a more complex design. The data are a small subset of the public dataset PXD006675 on PRIDE.\nParticularly, the proteomes of the atrium and ventriculum in the left and the right heart region are profiled for 3 patients (identifiers 3, 4, and 8). Hence, the design consists of a factor tissue (atrium, ventriculum), region (left, right) and block (patient 3,4, and 8).\nSuppose that researchers are mainly interested in comparing the ventricular to the atrial proteome. Particularly, they would like to compare the left atrium to the left ventricle, the right atrium to the right ventricle, the average ventricular vs atrial proteome and if ventricular vs atrial proteome shifts differ between left and right heart region.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Heart use case: a MaxQuant LFQ DDA dataset with a more complex design</span>"
    ]
  },
  {
    "objectID": "06-heart.html#load-packages",
    "href": "06-heart.html#load-packages",
    "title": "6  Heart use case: a MaxQuant LFQ DDA dataset with a more complex design",
    "section": "6.2 Load packages",
    "text": "6.2 Load packages\nFirst, we load the msqrob2 package and additional packages for data manipulation and visualisation.\n\nlibrary(\"msqrob2\")\nlibrary(\"ggplot2\")\nlibrary(\"patchwork\")\nlibrary(\"ggrepel\")\nlibrary(\"dplyr\")\n\nWe also configure the parallelisation framework.\n\nlibrary(\"BiocParallel\")\nregister(SerialParam())",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Heart use case: a MaxQuant LFQ DDA dataset with a more complex design</span>"
    ]
  },
  {
    "objectID": "06-heart.html#load-data",
    "href": "06-heart.html#load-data",
    "title": "6  Heart use case: a MaxQuant LFQ DDA dataset with a more complex design",
    "section": "6.3 Load Data",
    "text": "6.3 Load Data\n\n6.3.1 Getting the data\nThe data were searched with MaxQuant version version 1.5.5.6 and are deposited on the PRIDE repository PXD006675.\nIn this chapter we use a small subset of the data that is available on TODO put on Zenodo and use BiocFileCache.\n\nlibrary(\"BiocFileCache\")\nbfc &lt;- BiocFileCache()\npepFile &lt;- bfcrpath(bfc, \"https://raw.githubusercontent.com/statOmics/PDA21/data/quantification/heart/peptides.txt\")\n\nAfter downloading the files, we can load the peptide table, which is in “wide format”. Hence, each row represents a single peptide and that each quantification column (that starts with \"Intensity\") represents a single sample.\n\npeps &lt;- read.delim(pepFile)\nquantcols &lt;- grep(\"Intensity\\\\.\", names(peps), value = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequence\nN.term.cleavage.window\nC.term.cleavage.window\nAmino.acid.before\nFirst.amino.acid\nSecond.amino.acid\nSecond.last.amino.acid\nLast.amino.acid\nAmino.acid.after\nA.Count\nR.Count\nN.Count\nD.Count\nC.Count\nQ.Count\nE.Count\nG.Count\nH.Count\nI.Count\nL.Count\nK.Count\nM.Count\nF.Count\nP.Count\nS.Count\nT.Count\nW.Count\nY.Count\nV.Count\nU.Count\nO.Count\nLength\nMissed.cleavages\nMass\nProteins\nLeading.razor.protein\nStart.position\nEnd.position\nGene.names\nProtein.names\nUnique..Groups.\nUnique..Proteins.\nCharges\nPEP\nScore\nIdentification.type.LA3\nIdentification.type.LA4\nIdentification.type.LA8\nIdentification.type.LV3\nIdentification.type.LV4\nIdentification.type.LV8\nIdentification.type.RA3\nIdentification.type.RA4\nIdentification.type.RA8\nIdentification.type.RV3\nIdentification.type.RV4\nIdentification.type.RV8\nFraction.Average\nFraction.Std..Dev.\nFraction.1\nFraction.2\nFraction.3\nFraction.4\nFraction.5\nFraction.6\nFraction.7\nFraction.8\nFraction.100\nExperiment.LA3\nExperiment.LA4\nExperiment.LA8\nExperiment.LV3\nExperiment.LV4\nExperiment.LV8\nExperiment.RA3\nExperiment.RA4\nExperiment.RA8\nExperiment.RV3\nExperiment.RV4\nExperiment.RV8\nIntensity\nIntensity.LA3\nIntensity.LA4\nIntensity.LA8\nIntensity.LV3\nIntensity.LV4\nIntensity.LV8\nIntensity.RA3\nIntensity.RA4\nIntensity.RA8\nIntensity.RV3\nIntensity.RV4\nIntensity.RV8\nReverse\nPotential.contaminant\nid\nProtein.group.IDs\nMod..peptide.IDs\nEvidence.IDs\nMS.MS.IDs\nBest.MS.MS\nOxidation..M..site.IDs\nMS.MS.Count\n\n\n\n\nAAAAAAAAAK\nAKFRKQERAAAAAAAA\nAAAAAAAKNGSSGKKS\nR\nA\nA\nA\nK\nN\n9\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n10\n0\n785.4396\nQ99453\nQ99453\n159\n168\nPHOX2B\nPaired mesoderm homeobox protein 2B\nyes\nyes\n2\n0.0000121\n170.060\nBy matching\nBy matching\n\nBy matching\nBy matching\n\n\nBy matching\nBy matching\nBy matching\nBy matching\n\n83.5\n35.9\nNA\n2\n1\n5\n1\n7\n2\n6\n113\n1\n1\nNA\n1\n1\nNA\nNA\n1\n1\n1\n1\nNA\n3.4832e+10\n288590000\n118170000\n0\n257550000\n308710000\n0\n0\n194640000\n144740000\n456330000\n107900000\n0\nNA\n\n1\n9885\n1\n9;10;11;12;13;14;15;16;17;18;19;20;21;22;23;24;25;26;27;28;29;30;31;32;33;34;35;36;37;38;39;40;41;42;43;44;45;46;47;48;49;50;51;52;53;54;55;56;57;58;59;60;61;62;63;64;65;66;67;68;69;70;71;72;73;74;75;76;77;78;79;80;81;82;83;84;85;86;87;88;89;90;91;92;93;94;95;96;97;98;99;100;101;102;103;104;105;106;107;108;109;110;111;112;113;114;115;116;117;118;119;120;121;122;123;124;125;126;127;128;129;130;131;132;133;134;135;136;137;138;139;140;141;142;143;144;145\n9;10;11;12;13;14;15;16;17;18;19;20;21;22;23;24;25;26;27;28;29;30;31;32;33;34;35;36;37;38;39;40;41;42;43;44;45;46;47;48;49;50;51;52;53;54;55;56;57;58;59;60;61;62\n18\n\n50\n\n\nAAAAAAAAEQQSSNGPVK\n________________\nQSSNGPVKKSMREKAV\nM\nA\nA\nV\nK\nK\n8\n0\n1\n0\n0\n2\n1\n1\n0\n0\n0\n1\n0\n0\n1\n2\n0\n0\n0\n1\n0\n0\n18\n0\n1640.8118\nQ16585\nQ16585\n2\n19\nSGCB\nBeta-sarcoglycan\nyes\nyes\n2\n0.0000000\n185.250\n\n\n\n\n\n\n\n\n\nBy MS/MS\nBy MS/MS\n\n4.5\n1.8\nNA\n2\nNA\nNA\n1\n3\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1\n1\nNA\n9.4024e+07\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n29925000\n0\nNA\n\n4\n7001\n4;5\n149;150;151;152;153;154\n67;68;69;70;71;72;73\n67\n\n7\n\n\nAAAAAAAAGAFAGR\nAPLLGARRAAAAAAAA\nAAGAFAGRRAACGAVL\nR\nA\nA\nG\nR\nR\n10\n1\n0\n0\n0\n0\n0\n2\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n14\n0\n1145.5942\nQ8N697\nQ8N697\n20\n33\nSLC15A4\nSolute carrier family 15 member 4\nyes\nyes\n2\n0.0003300\n119.620\n\n\n\n\n\n\n\n\n\n\n\n\n7.0\n0.0\nNA\nNA\nNA\nNA\nNA\nNA\n5\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n2.5454e+08\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNA\n\n5\n8631\n6\n155;156;157;158;159\n74;75\n74\n\n1\n\n\nAAAAAAAPEPPLGLQQLSALQPEPGGVPLHSSWTFWLDR\nAREPPGSRAAAAAAAP\nSWTFWLDRSLPGATAA\nR\nA\nA\nD\nR\nS\n8\n1\n0\n1\n0\n3\n2\n3\n1\n0\n6\n0\n0\n1\n6\n3\n1\n2\n0\n1\n0\n0\n39\n0\n4049.0799\nQ8N5X7\nQ8N5X7\n21\n59\nEIF4E3\nEukaryotic translation initiation factor 4E type 3\nyes\nyes\n3;4\n0.0000700\n57.832\nBy matching\n\n\n\n\n\nBy MS/MS\n\n\n\n\n\n2.5\n1.5\n1\n2\nNA\nNA\n1\nNA\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\n8.5505e+07\n15932000\n0\n0\n0\n0\n0\n8996400\n0\n0\n0\n0\n0\nNA\n\n9\n8622\n10\n601;602;603;604\n349;350;351\n349\n\n3\n\n\nAAAAAAGAASGLPGPVAQGLK\n________________\nGPVAQGLKEALVDTLT\nM\nA\nA\nL\nK\nE\n9\n0\n0\n0\n0\n1\n0\n4\n0\n0\n2\n1\n0\n0\n2\n1\n0\n0\n0\n1\n0\n0\n21\n0\n1747.9581\nQ96P70\nQ96P70\n2\n22\nIPO9\nImportin-9\nyes\nyes\n2\n0.0000001\n177.810\n\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.0\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n3.3872e+07\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNA\n\n12\n9760\n13\n686\n450\n450\n\n1\n\n\nAAAAAATAPPSPGPAQPGPR\nAAPARAPRAAAAAATA\nGPAQPGPRAQRAAPLA\nR\nA\nA\nP\nR\nA\n8\n1\n0\n0\n0\n1\n0\n2\n0\n0\n0\n0\n0\n0\n6\n1\n1\n0\n0\n0\n0\n0\n20\n0\n1754.9064\nQ6SPF0\nQ6SPF0\n151\n170\nSAMD1\nAtherin\nyes\nyes\n2\n0.0007018\n72.290\n\n\n\n\n\n\n\n\n\n\n\n\n7.0\n0.0\nNA\nNA\nNA\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n9.4351e+06\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNA\n\n16\n7795\n18\n720\n472\n472\n\n1\n\n\n\n\n\nWe now extract the sample annotations. We will build a table where each row in the annotation table contains information for one sample (the table below shows the first 6 rows). This information is extracted from the sample names.\n\ncoldata &lt;- data.frame(quantCols = quantcols) |&gt; \n  mutate(location  = substr(quantCols, 11, 11)) |&gt; # heart region left-right\n  mutate(tissue  = substr(quantCols, 12, 12)) |&gt; # tissue Atrium-Ventriculum\n  mutate(patient  = substr(quantCols, 13, 13)) # patient id\n\n\n\n\n\n\nquantCols\nlocation\ntissue\npatient\n\n\n\n\nIntensity.LA3\nL\nA\n3\n\n\nIntensity.LA4\nL\nA\n4\n\n\nIntensity.LA8\nL\nA\n8\n\n\nIntensity.LV3\nL\nV\n3\n\n\nIntensity.LV4\nL\nV\n4\n\n\nIntensity.LV8\nL\nV\n8\n\n\n\n\n\n\n\n6.3.2 The QFeatures data class\nWe combine the two tables into a QFeatures object.\n\n(pe &lt;- readQFeatures(\n  peps, colData = coldata, fnames = \"Sequence\", name = \"peptides\"\n))\n\nAn instance of class QFeatures (type: bulk) with 1 set:\n\n [1] peptides: SummarizedExperiment with 31319 rows and 12 columns \n\n\nWe now have a QFeatures object with 1 set, containing r nrows(pe)[[1]] rows (peptides) and 12 columns (samples).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Heart use case: a MaxQuant LFQ DDA dataset with a more complex design</span>"
    ]
  },
  {
    "objectID": "06-heart.html#data-preprocessing",
    "href": "06-heart.html#data-preprocessing",
    "title": "6  Heart use case: a MaxQuant LFQ DDA dataset with a more complex design",
    "section": "6.4 Data preprocessing",
    "text": "6.4 Data preprocessing\nmsqrob2 relies on the QFeatures data structure, meaning that we can directly make use of QFeatures’ data preprocessing functionality (see also the QFeatures documentation).\n\n6.4.1 Encoding missing values\nPeptides with zero intensities should be encoded using NA.\n\npe &lt;- zeroIsNA(pe, \"peptides\")\n\nWe calculate how many non zero intensities we have per peptide and this is often useful for filtering.\n\nnaResults &lt;- nNA(pe, \"peptides\")\ndata.frame(naResults$nNArows) |&gt; \n  ggplot() +\n  aes(x = nNA) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n6.4.2 PSM filtering\nWe filter features based on 3 criteria (see PSM filtering).\n\nRemove failed protein inference\n\nWe remove peptides that could not be uniquely mapped to a protein.\n\npe &lt;- filterFeatures(pe,\n  ~ Proteins != \"\" & ## Remove failed protein inference\n    !grepl(\";\", Proteins)) ## Remove protein groups\n\n\nRemove reverse sequences (decoys) and contaminants\n\nWe remove the contaminants and peptides that map to decoy sequences. These features bear no information of interest and will reduce the statistical power upon multiple test adjustment.\n\npe &lt;- filterFeatures(pe, ~ Reverse != \"+\" & Potential.contaminant != \"+\")\n\n\nRemove highly missing peptides.\n\nWe keep peptides that were observed at last 3 times out of the \\(n =\n12\\) samples, so we tolerate the following proportion of NAs: \\(\\text{pNA} = \\frac{(n - 3)}{n} = 0.75\\), so we keep peptides that are observed in at least 25% of the samples.\n\nnObs &lt;- 3\nn &lt;- ncol(pe[[\"peptides\"]])\n(pe &lt;- filterNA(pe, i = \"peptides\", pNA = (n - nObs) / n))\n\nAn instance of class QFeatures (type: bulk) with 1 set:\n\n [1] peptides: SummarizedExperiment with 15630 rows and 12 columns \n\n\nWe keep 15630 peptides upon filtering.\n\n\n6.4.3 Standard preprocessing workflow\nWe can now prepare the data for modelling. The workflow ensures the data complies to msqrob2’s requirements:\n\nIntensities are log-transformed.\n\n\npe &lt;- logTransform(pe, base = 2, i = \"peptides\", name = \"peptides_log\")\n\n\nNormalisation with Median of Ratios method.\n\n\npseudoRef &lt;- assay(pe[[\"peptides_log\"]]) |&gt; \n  rowMeans(na.rm = TRUE) #1. Calculate the row means \n\nnfLog &lt;- sweep(\n  assay(pe[[\"peptides_log\"]]), \n  MARGIN = 1, \n  pseudoRef) |&gt; #2. Subtract the row means row-by-row (MARGIN = 1)\n  colMedians(na.rm = TRUE)  #3. Calculate the column median \n\npe &lt;- \n  sweep(pe, \n        MARGIN = 2, \n        STATS = nfLog , \n        i = \"peptides_log\", \n        name = \"peptides_norm\") #4. Subtract log2 norm factor column-by-column (MARGIN = 2)\n\n\nUpon the normalisation the density curves should be nicely centred. To confirm this, we will plot the intensity distributions for each biorepeat (mouse). longForm() seamlessly combines the quantification and annotation data into a table suitable for ggplot2 visualisation. We also subset the object with the data before and after normalisation.\n\nlongForm(pe[, , c(\"peptides_log\", \"peptides_norm\")], colvar = \"patient\") |&gt; \n  ggplot() +\n  aes(x = value, group = colname, color = patient) +\n  geom_density() +\n  facet_wrap(~ assay, scale = \"free\")\n\n\n\n\n\n\n\n\n\nSummarisation to protein level.\n\nWe use the robust summary approach to infer protein-level data from peptide-level data, accounting for the fact that different peptides have ionisation efficiencies hence leading to different intensity baselines.\n\npe &lt;- aggregateFeatures(\n  pe, i = \"peptides_norm\", fcol = \"Proteins\", \n  fun = MsCoreUtils::medianPolish, \n  na.rm = TRUE, name = \"proteins\"\n)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Heart use case: a MaxQuant LFQ DDA dataset with a more complex design</span>"
    ]
  },
  {
    "objectID": "06-heart.html#data-exploration",
    "href": "06-heart.html#data-exploration",
    "title": "6  Heart use case: a MaxQuant LFQ DDA dataset with a more complex design",
    "section": "6.5 Data exploration",
    "text": "6.5 Data exploration\nWe will explore the main sources of variation in the data using MDS.\n\nlibrary(\"scater\")\nse &lt;- getWithColData(pe, \"proteins\") |&gt; \n  as(\"SingleCellExperiment\") |&gt; \n  runMDS(exprs_values = 1) \nplotMDS(se, colour_by = \"tissue\") +\n  plotMDS(se, colour_by = \"location\") +\n  plotMDS(se, colour_by = \"patient\")\n\n\n\n\n\n\n\n\nNote, that the samples upon robust summarisation show a clear separation according to the tissue type in the first dimension and according to location in the second dimension.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Heart use case: a MaxQuant LFQ DDA dataset with a more complex design</span>"
    ]
  },
  {
    "objectID": "06-heart.html#data-modelling",
    "href": "06-heart.html#data-modelling",
    "title": "6  Heart use case: a MaxQuant LFQ DDA dataset with a more complex design",
    "section": "6.6 Data modelling",
    "text": "6.6 Data modelling\nThe preprocessed data can now be modelled to answer biologically relevant questions. Particularly, the protein abundance can differ according to tissue type (A-V) and location (L-R). Moreover, the effect of the tissue type can differ according to the location and vice versa. Hence, there can be an interaction between tissue and location.\nThe samples are also not independent as four biopsies (LA, RA, LV and RV) were taken for each patient. Because the proteome is profiled for each tissue x location combination within each patient, the design is a randomised complete block (RCB) design.\nRCB designs can be correctly analysed by incorporating the block effect for patient either as a fixed or a random effect. The use of a fixed patient effect is here also possible because the effect of each factor combination can be estimated within block (patient).\nHere, we choose to account for the patient effect using fixed effects because mixed models are computationally more demanding and rely on asymptotic inference (i.e. statistical inference is only valid for experiments with large sample sizes).\nNow we have identified the sources of variation in the experiment that we have to account for (tissue, location and patient id), we can define a model.\n\nmodel &lt;- ~ location*tissue + ## (1) fixed effects: main effects for location and tissue type, and a tissue x location interaction\n  patient  ## (2) fixed block effect for patient\n\n\n6.6.1 Estimate the model\nWe estimate the model with msqrob(). Recall that variables defined in model are automatically retrieved from the colData (i.e. \"tissue\", \"location\", and \"patient\").\n\npe &lt;- msqrob(\n  pe, i = \"proteins\", formula = model, robust = TRUE, ridge = TRUE\n)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Heart use case: a MaxQuant LFQ DDA dataset with a more complex design</span>"
    ]
  },
  {
    "objectID": "06-heart.html#statistical-inference",
    "href": "06-heart.html#statistical-inference",
    "title": "6  Heart use case: a MaxQuant LFQ DDA dataset with a more complex design",
    "section": "6.7 Statistical inference",
    "text": "6.7 Statistical inference\nOnce the models are estimated, we can start answering biological questions by performing Statistical inference. We must translate the biological questions into a statistical hypotheses:\n\nIs there an effect of tissue type (V-A) in the left heart region?\nIs there an effect of tissue type (V-A) in the right heart region?\nIs there on average an effect of tissue type in the heart.\nDoes the effect of tissue type (V-A) differ according to the heart region (L-R)?\n\nIn other words, we must translate these questions in a linear combination of the model parameters, also referred to as a contrast. To aid defining contrasts, we will visualise the experimental design using the ExploreModelMatrix package.\n\nlibrary(\"ExploreModelMatrix\")\nvd &lt;- VisualizeDesign(\n    sampleData =  colData(pe),\n    designFormula = ~ location*tissue + patient,\n    textSizeFitted = 4\n)\nvd$plotlist\n\n$`location = L`\n\n\n\n\n\n\n\n\n\n\n$`location = R`\n\n\n\n\n\n\n\n\n\n\n6.7.1 Research question 1: is there an effect of tissue in the left heart region?\nFrom the plot we can see that the average log2 intensity for patient 3 in the left ventriculum equals `(Intercept) + tissueV’:\n\\[\n\\mu^L_{V,3} = \\beta_0 + \\beta_V\n\\] and for the left atrium (Intercept):\n\\[\n\\mu^L_{A,3} = \\beta_0\n\\] So the average \\(\\log_2 FC\\) between atrium and ventriculum for patient 3 equals to parameter tissueV\n\\[\n\\log_2 FC_{V-A}^L = \\mu^L_{V,3} -\\mu^L_{A,3} = \\beta_V\n\\] The same can be seen for patient 4:\n\\[\n\\log_2 FC_{V-A}^L= \\mu^L_{V,4} -\\mu^L_{A,4} = \\beta_0 + \\beta_V + \\beta_4 - (\\beta_0 + \\beta_4) = \\beta_V\n\\] So the parameter tissueV has the interpretation of the average \\(\\log_2 FC\\) between ventriculum and atrium after correction for the patient effect, which quantifies the effect size for the first research hypothesis.\n\n\n6.7.2 Research question 2: is there an effect of tissue in the right heart region?\nWhen we use the same rationale for the right heart region, we can see that the average \\(\\log_2 FC\\) between atrium and ventriculum upon correction for the patient effect equals tissueV + locationR:tissueV. So, it consists of the main effect for tissue and the location x tissue interaction.\nWe will illustrate this here for patient 4:\n\\[\n\\begin{array}{rcl}\n\\log_2 FC_{V-A}^R& =&\\mu^R_{V,4} -\\mu^R_{A,4} \\\\\n&=& \\beta_0 +\n\\beta_R + \\beta_V + \\beta_{R:V} + \\beta_4 - (\\beta_0 +\n\\beta_R + \\beta_4) \\\\\n&=& \\beta_V + \\beta_{R:V}\n\\end{array}\n\\]\n\n\n6.7.3 Research question 3: is there an effect of tissue on average in the heart?\nThis research question can be quantified by calculating the averaging the \\(\\log_2\\) fold change between Ventriculum and Atrium over the left and right heart regions, which equals tissueV + 0.5*locationR:tissueV\n\\[\n\\begin{array}{rcl}\n(\\log_2 FC_{V-A}^R + \\log_2 FC_{V-A}^R)/ 2 &=& (\\beta_V + \\beta_V + \\beta_{R:V})/2 \\\\\n&=& \\beta_V + 0.5\\times\\beta_{R:V}\n\\end{array}\n\\]\n\n\n6.7.4 Research question 4: does the effect of tissue differs according to the heart region?\nThis research question can be quantified by calculating the difference in the \\(\\log_2\\) fold change between Ventriculum and Atrium in the right and left heart regions, which equals locationR:tissueV\n\\[\n\\begin{array}{rcl}\n\\log_2 FC_{V-A}^R- \\log_2 FC_{V-A}^R &=& \\beta_V + \\beta_{R:V}-\\beta_V  \\\\\n&=& \\beta_{R:V}\n\\end{array}\n\\] ### Setting up the contrasts\nWe can set up the four contrasts:\n\nWe make the design matrix so that we can easily extract all parameter names from the model\nWe make the contrast matrix for the four contrasts\n\n\ndesign &lt;- model.matrix(~ location*tissue + patient, data = colData(pe))\nL &lt;- makeContrast(\n  c(\n    \"ridgetissueV = 0\",\n    \"ridgetissueV + ridgelocationR:tissueV = 0\",\n    \"ridgetissueV + 0.5*ridgelocationR:tissueV = 0\",\n    \"ridgelocationR:tissueV = 0\"\n  ),\n  parameterNames = paste0(\"ridge\", colnames(design))\n  )\n\nWe can now falsify the null hypothesis of each contrast:\n\npe &lt;- hypothesisTest(\n  object = pe, i = \"proteins\", contrast = L, overwrite = TRUE\n)\n\n\n\n6.7.5 Evaluate results for contrast \\(\\log_2 FC_{V-A}^L\\)\nLet us retrieve the result table from the rowData. Note that the hypothesis testing results are stored in rowData columns named after the column names of the contrast matrix L. The first column contains the results for contrast \\(\\log_2 FC_{V-A}^L\\).\n\ninferenceLeft &lt;- rowData(pe[[\"proteins\"]])[[colnames(L)[1]]]\ninferenceLeft$Protein &lt;- rownames(inferenceLeft)\nhead(inferenceLeft)\n\n             logFC           se        df          t      pval adjPval Protein\nA0PJW6  0.00000000 5.509988e-10 14.003000  0.0000000 1.0000000       1  A0PJW6\nA0PJZ3          NA           NA        NA         NA        NA      NA  A0PJZ3\nA0PK00          NA           NA  5.826529         NA        NA      NA  A0PK00\nA1A4S6  0.03452594 8.910408e-02 13.324734  0.3874788 0.7045204       1  A1A4S6\nA1A5D9          NA           NA        NA         NA        NA      NA  A1A5D9\nA1IGU5 -0.12078957 2.045995e-01 10.934858 -0.5903708 0.5669427       1  A1IGU5\n\n\nNotice that some rows contain missing values. This is because data modelling resulted in a fitError for some proteins, probably because not enough data was available for model fitting due to missing values in the quantitative data (see how to deal with fitErrors).\n\nVolcano plot\nVolcano plots are straightforward to generate from the inference table above. We also use ggrepel to annotate the 20 most significant proteins.\n\nggplot(inferenceLeft) +\n  aes(x = logFC, y = -log10(pval), color = adjPval &lt; 0.05) +\n  geom_point() +\n  geom_text_repel(data = slice_min(inferenceLeft, adjPval, n = 20),\n                  aes(label = Protein)) +\n  scale_color_manual(values = alpha(c(\"black\", \"red\"), 0.5)) + \n  ggtitle(\"log2 FC V-A left\",\n          paste(\"Hypothesis test:\", colnames(L)[1], \"= 0\"))\n\n\n\n\n\n\n\n\n\n\nHeatmap\nWe can also build a heatmap for the significant proteins which are obtained by filtering the inference table. We first retrieve the data with proteins that are differentially abundant between the atrium and the ventriculum in the left heart.\n\nsigNamesLeft &lt;- inferenceLeft |&gt; \n  filter(!is.na(adjPval), adjPval &lt; 0.05) |&gt; \n  pull()\nse &lt;- getWithColData(pe, \"proteins\")[sigNamesLeft, ]\n\nWe then plot the protein-wise standardised data as an annotated heatmap.\n\nquants &lt;- t(scale(t(assay(se))))\nlibrary(\"ComplexHeatmap\")\nannotations &lt;- columnAnnotation(\n  tissue = se$tissue,\n  location = se$location\n)\nset.seed(1234) ## annotation colours are randomly generated by default\nHeatmap(\n quants, name = \"log2 intensity\",\n top_annotation = annotations\n)\n\n\n\n\n\n\n\n\nThere are 91 proteins significantly differentially expressed at the 5% FDR level. Below you can find the list of significant proteins.\n\ninferenceLeft |&gt;\n  na.exclude() |&gt;\n  filter(adjPval&lt;0.05) |&gt;\n  arrange(pval)  |&gt;\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlogFC\nse\ndf\nt\npval\nadjPval\nProtein\n\n\n\n\nP08590\n8.250133\n0.4618098\n9.066700\n17.864783\n0.0000000\n0.0000501\nP08590\n\n\nP12883\n4.683827\n0.3506520\n9.108910\n13.357477\n0.0000003\n0.0003054\nP12883\n\n\nP10916\n7.126335\n0.4767443\n7.093703\n14.947920\n0.0000013\n0.0009474\nP10916\n\n\nP14854\n2.370452\n0.2234186\n9.066347\n10.609916\n0.0000021\n0.0011498\nP14854\n\n\nO94875-10\n2.631801\n0.2944480\n9.230071\n8.938084\n0.0000076\n0.0032078\nO94875-10\n\n\nQ6UWY5\n-2.820577\n0.3178826\n9.147279\n-8.873014\n0.0000086\n0.0032078\nQ6UWY5\n\n\nP51888\n-2.532542\n0.3183317\n9.246559\n-7.955671\n0.0000197\n0.0063061\nP51888\n\n\nP46821\n-1.716407\n0.2365827\n9.150270\n-7.255001\n0.0000439\n0.0103944\nP46821\n\n\nQ8N474\n-2.758038\n0.3551103\n8.190289\n-7.766709\n0.0000475\n0.0103944\nQ8N474\n\n\nP21810\n-2.518077\n0.3552103\n9.230160\n-7.088977\n0.0000504\n0.0103944\nP21810\n\n\nP02747\n-2.301603\n0.3282428\n9.364965\n-7.011892\n0.0000511\n0.0103944\nP02747\n\n\nO75368\n-1.751397\n0.2535261\n9.191185\n-6.908151\n0.0000632\n0.0117700\nO75368\n\n\nO14967\n-1.916404\n0.2835587\n9.248331\n-6.758403\n0.0000728\n0.0122440\nO14967\n\n\nP05546\n-1.563360\n0.2304074\n9.089659\n-6.785196\n0.0000767\n0.0122440\nP05546\n\n\nP29622\n-1.544848\n0.2320175\n9.113749\n-6.658327\n0.0000876\n0.0122901\nP29622\n\n\nQ9ULL5-3\n-2.771336\n0.3986314\n8.505757\n-6.952128\n0.0000879\n0.0122901\nQ9ULL5-3\n\n\nP18428\n-1.750339\n0.2688643\n9.299328\n-6.510121\n0.0000950\n0.0124912\nP18428\n\n\nP08294\n-2.135352\n0.3312298\n9.307183\n-6.446739\n0.0001021\n0.0126793\nP08294\n\n\nQ8TBQ9\n-2.126623\n0.3493479\n9.446801\n-6.087408\n0.0001491\n0.0169428\nQ8TBQ9\n\n\nP00325\n-1.696574\n0.2749298\n9.177945\n-6.170934\n0.0001515\n0.0169428\nP00325\n\n\nP15924\n1.473571\n0.2403994\n9.110066\n6.129679\n0.0001644\n0.0175054\nP15924\n\n\nQ9UBB5\n2.681925\n0.3323530\n6.082236\n8.069506\n0.0001809\n0.0183864\nQ9UBB5\n\n\nP06858\n2.005077\n0.3377476\n9.148010\n5.936613\n0.0002052\n0.0199517\nP06858\n\n\nP24844\n-1.952282\n0.3366253\n9.433933\n-5.799568\n0.0002167\n0.0201925\nP24844\n\n\nP24311\n1.966170\n0.3414895\n9.362276\n5.757630\n0.0002356\n0.0210760\nP24311\n\n\nQ5JVS0\n-2.937575\n0.3186422\n5.020511\n-9.219040\n0.0002467\n0.0210902\nQ5JVS0\n\n\nO95865\n-1.567784\n0.2751262\n9.360986\n-5.698419\n0.0002547\n0.0210902\nO95865\n\n\nP02452\n-2.032726\n0.3640935\n9.585356\n-5.582980\n0.0002720\n0.0211347\nP02452\n\n\nP13533\n-3.159311\n0.5620164\n9.431456\n-5.621385\n0.0002741\n0.0211347\nP13533\n\n\nQ9P2B2\n-1.649939\n0.2981357\n9.357789\n-5.534187\n0.0003166\n0.0229231\nQ9P2B2\n\n\nQ15113\n-1.934718\n0.3529607\n9.536113\n-5.481398\n0.0003178\n0.0229231\nQ15113\n\n\nP02743\n-1.682963\n0.3088914\n9.259904\n-5.448396\n0.0003682\n0.0257297\nP02743\n\n\nP23083\n-3.595505\n0.5864530\n7.380951\n-6.130935\n0.0003865\n0.0259912\nP23083\n\n\nP23434\n1.426496\n0.2644910\n9.231040\n5.393363\n0.0004005\n0.0259912\nP23434\n\n\nP04196\n-1.424906\n0.2661117\n9.273169\n-5.354540\n0.0004154\n0.0259912\nP04196\n\n\nQ9BW30\n-2.113450\n0.4001977\n9.534123\n-5.281013\n0.0004185\n0.0259912\nQ9BW30\n\n\nO43677\n-2.187788\n0.4161198\n9.401692\n-5.257592\n0.0004526\n0.0262839\nO43677\n\n\nQ9UKS6\n1.527078\n0.2923847\n9.488160\n5.222840\n0.0004608\n0.0262839\nQ9UKS6\n\n\nQ53GQ0\n-1.766962\n0.3426900\n9.718619\n-5.156155\n0.0004684\n0.0262839\nQ53GQ0\n\n\nP36955\n-1.684290\n0.3276053\n9.772134\n-5.141217\n0.0004702\n0.0262839\nP36955\n\n\nP05997\n-2.292742\n0.4438855\n9.559204\n-5.165165\n0.0004876\n0.0263397\nP05997\n\n\nP04209\n1.537844\n0.2981332\n9.495921\n5.158245\n0.0005029\n0.0263397\nP04209\n\n\nQ14764\n-1.154973\n0.2205762\n9.165409\n-5.236163\n0.0005065\n0.0263397\nQ14764\n\n\nO95631\n-3.641005\n0.4782087\n5.133102\n-7.613842\n0.0005523\n0.0280667\nO95631\n\n\nP51884\n-1.625915\n0.3221562\n9.576049\n-5.046979\n0.0005730\n0.0283194\nP51884\n\n\nP08582\n-1.400068\n0.2752535\n9.355058\n-5.086468\n0.0005826\n0.0283194\nP08582\n\n\nQ16647\n-1.821645\n0.3658315\n9.742336\n-4.979465\n0.0005991\n0.0285012\nQ16647\n\n\nP19429\n2.446925\n0.4900303\n9.586884\n4.993416\n0.0006163\n0.0287104\nP19429\n\n\nQ6YN16\n1.372126\n0.2728193\n9.276732\n5.029431\n0.0006473\n0.0289927\nQ6YN16\n\n\nP01699\n-3.706945\n0.5955534\n6.325570\n-6.224371\n0.0006483\n0.0289927\nP01699\n\n\nQ9UNW9\n3.556427\n0.7181405\n9.536696\n4.952272\n0.0006641\n0.0291146\nQ9UNW9\n\n\nP14923\n1.046597\n0.2091414\n9.171357\n5.004255\n0.0006940\n0.0293444\nP14923\n\n\nP04083\n-1.155807\n0.2326322\n9.318065\n-4.968389\n0.0006956\n0.0293444\nP04083\n\n\nQ96LL9\n-1.832427\n0.3733546\n9.526194\n-4.908006\n0.0007099\n0.0293942\nQ96LL9\n\n\nO95980\n-1.644847\n0.3372152\n9.498408\n-4.877737\n0.0007478\n0.0304004\nO95980\n\n\nQ00G26\n1.468999\n0.2999726\n9.271814\n4.897112\n0.0007803\n0.0311574\nQ00G26\n\n\nQ13011\n1.343312\n0.2779008\n9.478440\n4.833782\n0.0008015\n0.0314398\nQ13011\n\n\nQ9BX66-5\n1.645228\n0.3003872\n7.236228\n5.477024\n0.0008305\n0.0320157\nQ9BX66-5\n\n\nQ9UBG0\n-1.737280\n0.3711535\n9.768266\n-4.680758\n0.0009230\n0.0346124\nQ9UBG0\n\n\nQ9NVN8\n-5.198643\n0.7881637\n5.337400\n-6.595893\n0.0009338\n0.0346124\nQ9NVN8\n\n\nP12110\n-1.294302\n0.2752573\n9.536991\n-4.702153\n0.0009541\n0.0346124\nP12110\n\n\nP17540\n1.186827\n0.2524879\n9.408560\n4.700530\n0.0009922\n0.0346124\nP17540\n\n\nQ8WZ42-6\n1.025527\n0.2181058\n9.391830\n4.701968\n0.0009949\n0.0346124\nQ8WZ42-6\n\n\nQ9UL18\n-1.765694\n0.3684251\n8.951891\n-4.792544\n0.0009988\n0.0346124\nQ9UL18\n\n\nA6NDG6\n1.268609\n0.2689144\n9.276465\n4.717521\n0.0010062\n0.0346124\nA6NDG6\n\n\nQ9Y4W6\n1.073065\n0.2294084\n9.235088\n4.677530\n0.0010787\n0.0365449\nQ9Y4W6\n\n\nP24298\n1.544611\n0.3397789\n9.384519\n4.545929\n0.0012525\n0.0418012\nP24298\n\n\nP46063\n-1.073446\n0.2365976\n9.340311\n-4.537009\n0.0012845\n0.0422366\nP46063\n\n\nP36021\n-2.202548\n0.4760910\n8.828176\n-4.626317\n0.0013081\n0.0423886\nP36021\n\n\nQ5NDL2\n-1.747813\n0.3912896\n9.517072\n-4.466802\n0.0013600\n0.0429751\nQ5NDL2\n\n\nQ13636\n-2.478227\n0.4646276\n6.499442\n-5.333792\n0.0013751\n0.0429751\nQ13636\n\n\nP02775\n-1.516837\n0.3394756\n9.442684\n-4.468178\n0.0013838\n0.0429751\nP02775\n\n\nQ9BXN1\n-1.948674\n0.4430265\n9.779246\n-4.398551\n0.0014117\n0.0432408\nQ9BXN1\n\n\nQ9NZ01\n-1.568868\n0.3603847\n9.896186\n-4.353317\n0.0014718\n0.0436957\nQ9NZ01\n\n\nQ92736-2\n-2.605932\n0.5910197\n9.526607\n-4.409213\n0.0014794\n0.0436957\nQ92736-2\n\n\nO60760\n-2.498746\n0.5569448\n9.077881\n-4.486523\n0.0014858\n0.0436957\nO60760\n\n\nQ06828\n-3.276730\n0.7507098\n9.730028\n-4.364843\n0.0015047\n0.0436957\nQ06828\n\n\nO75629\n1.543697\n0.3542839\n9.693237\n4.357233\n0.0015361\n0.0437116\nO75629\n\n\nQ9HBL0\n1.646254\n0.3543908\n8.180895\n4.645306\n0.0015594\n0.0437116\nQ9HBL0\n\n\nO00180\n-3.220740\n0.7131678\n8.732659\n-4.516103\n0.0015702\n0.0437116\nO00180\n\n\nP06727\n-1.098656\n0.2488030\n9.225409\n-4.415767\n0.0015835\n0.0437116\nP06727\n\n\nQ8WZA9\n-1.005633\n0.2319000\n9.553531\n-4.336494\n0.0016406\n0.0447356\nQ8WZA9\n\n\nP02776\n-1.337487\n0.3054296\n9.240633\n-4.379034\n0.0016652\n0.0448599\nP02776\n\n\nQ9UGT4\n-1.651943\n0.3842304\n9.601092\n-4.299354\n0.0017164\n0.0456878\nQ9UGT4\n\n\nP07451\n-1.114780\n0.2610269\n9.585814\n-4.270745\n0.0017998\n0.0465444\nP07451\n\n\nQ96H79\n-2.280431\n0.4560710\n6.634593\n-5.000166\n0.0018317\n0.0465444\nQ96H79\n\n\nP02671\n-1.686681\n0.3221285\n6.105609\n-5.236051\n0.0018443\n0.0465444\nP02671\n\n\nQ86VU5\n1.516645\n0.3572766\n9.638787\n4.245018\n0.0018493\n0.0465444\nQ86VU5\n\n\nQ5JPH6\n3.579987\n0.7035217\n6.397711\n5.088666\n0.0018571\n0.0465444\nQ5JPH6\n\n\nP35754\n1.382605\n0.3285348\n9.831307\n4.208396\n0.0018734\n0.0465444\nP35754\n\n\nQ9BXV9\n1.608759\n0.3856887\n9.805041\n4.171135\n0.0019979\n0.0490914\nQ9BXV9\n\n\n\n\n\n\n\n\n6.7.6 Evaluate results for contrast \\(\\log_2 FC_{V-A}^R\\)\nLet us retrieve the result table from the rowData. The second column contains the results for contrast \\(\\log_2 FC_{V-A}^R\\).\n\ninferenceRight &lt;- rowData(pe[[\"proteins\"]])[[colnames(L)[2]]]\ninferenceRight$Protein &lt;- rownames(inferenceRight)\nhead(inferenceRight)\n\n             logFC           se        df          t       pval   adjPval\nA0PJW6  0.00000000 5.509988e-10 14.003000  0.0000000 1.00000000 1.0000000\nA0PJZ3          NA           NA        NA         NA         NA        NA\nA0PK00          NA           NA  5.826529         NA         NA        NA\nA1A4S6  0.04979859 8.881359e-02 13.324734  0.5607091 0.58430170 1.0000000\nA1A5D9          NA           NA        NA         NA         NA        NA\nA1IGU5 -0.40996946 2.015378e-01 10.934858 -2.0342065 0.06691788 0.3697382\n       Protein\nA0PJW6  A0PJW6\nA0PJZ3  A0PJZ3\nA0PK00  A0PK00\nA1A4S6  A1A4S6\nA1A5D9  A1A5D9\nA1IGU5  A1IGU5\n\n\n\nVolcano plot\nVolcano plots are straightforward to generate from the inference table above. We also use ggrepel to annotate the 20 most significant proteins.\n\nggplot(inferenceRight) +\n  aes(x = logFC, y = -log10(pval), color = adjPval &lt; 0.05) +\n  geom_point() +\n  geom_text_repel(data = slice_min(inferenceRight, adjPval, n = 20),\n                  aes(label = Protein)) +\n  scale_color_manual(values = alpha(c(\"black\", \"red\"), 0.5)) + \n  ggtitle(\"log2 FC V-A Right\",\n          paste(\"Hypothesis test:\", colnames(L)[2], \"= 0\"))\n\n\n\n\n\n\n\n\n\n\nHeatmap\nWe can also build a heatmap for the significant proteins which are obtained by filtering the inference table1.\n\nsigNamesRight &lt;- inferenceRight |&gt; \n  filter(!is.na(adjPval), adjPval &lt; 0.05) |&gt; \n  pull()\nse &lt;- getWithColData(pe, \"proteins\")[sigNamesRight, ]\nquants &lt;- t(scale(t(assay(se))))\nset.seed(1234) ## annotation colours are randomly generated by default\nHeatmap(\n quants, name = \"log2 intensity\",\n top_annotation = annotations\n)\n\n\n\n\n\n\n\n\nThere are 59 proteins significantly differentially expressed at the 5% FDR level.\nBelow you can find the list of significant proteins.\n\ninferenceRight |&gt;\n  na.exclude() |&gt;\n  filter(adjPval&lt;0.05) |&gt;\n  arrange(pval)  |&gt;\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlogFC\nse\ndf\nt\npval\nadjPval\nProtein\n\n\n\n\nP08590\n5.493574\n0.4626211\n9.066700\n11.874888\n0.0000008\n0.0015317\nP08590\n\n\nP06858\n3.674709\n0.3338983\n9.148010\n11.005474\n0.0000014\n0.0015317\nP06858\n\n\nP48163\n-2.616881\n0.3097355\n9.233764\n-8.448762\n0.0000121\n0.0088573\nP48163\n\n\nP02776\n-2.374280\n0.2974779\n9.240633\n-7.981367\n0.0000193\n0.0091147\nP02776\n\n\nQ9ULD0\n-3.097487\n0.3131518\n7.104538\n-9.891328\n0.0000208\n0.0091147\nQ9ULD0\n\n\nQ00G26\n2.200504\n0.2999726\n9.271814\n7.335685\n0.0000375\n0.0136795\nQ00G26\n\n\nP54652\n-2.287138\n0.3255640\n9.325197\n-7.025158\n0.0000515\n0.0137287\nP54652\n\n\nQ6UWY5\n-2.154394\n0.3049324\n9.147279\n-7.065153\n0.0000542\n0.0137287\nQ6UWY5\n\n\nP11586\n2.100538\n0.3026749\n9.333226\n6.939915\n0.0000565\n0.0137287\nP11586\n\n\nP21810\n-2.331556\n0.3429892\n9.230160\n-6.797753\n0.0000702\n0.0153595\nP21810\n\n\nQ04760\n2.281002\n0.3674889\n9.441126\n6.206996\n0.0001286\n0.0208338\nQ04760\n\n\nP23434\n1.656292\n0.2644910\n9.231040\n6.262189\n0.0001323\n0.0208338\nP23434\n\n\nP24298\n2.252174\n0.3642189\n9.384519\n6.183572\n0.0001358\n0.0208338\nP24298\n\n\nP60468\n-2.014787\n0.3022799\n8.191586\n-6.665302\n0.0001422\n0.0208338\nP60468\n\n\nP05546\n-1.388646\n0.2220578\n9.089659\n-6.253532\n0.0001428\n0.0208338\nP05546\n\n\nQ6YN16\n1.728901\n0.2895814\n9.276732\n5.970346\n0.0001861\n0.0237989\nQ6YN16\n\n\nP13533\n-3.148481\n0.5388200\n9.431456\n-5.843288\n0.0002050\n0.0237989\nP13533\n\n\nQ69YU5\n3.065356\n0.5307692\n9.579396\n5.775308\n0.0002110\n0.0237989\nQ69YU5\n\n\nA6NDG6\n1.557838\n0.2665039\n9.276465\n5.845460\n0.0002180\n0.0237989\nA6NDG6\n\n\nP04004\n-1.609110\n0.2765621\n9.270800\n-5.818258\n0.0002263\n0.0237989\nP04004\n\n\nP28066\n-1.685066\n0.2929535\n9.457629\n-5.751991\n0.0002284\n0.0237989\nP28066\n\n\nP12883\n1.989033\n0.3417758\n9.108910\n5.819703\n0.0002417\n0.0240397\nP12883\n\n\nO43677\n-2.375819\n0.4202739\n9.401692\n-5.653026\n0.0002660\n0.0253014\nO43677\n\n\nP23786\n1.210900\n0.2128018\n9.134748\n5.690270\n0.0002820\n0.0257048\nP23786\n\n\nP10916\n3.113228\n0.4767443\n7.093703\n6.530185\n0.0003069\n0.0268623\nP10916\n\n\nP35625\n-3.190450\n0.5540567\n8.562007\n-5.758346\n0.0003299\n0.0277622\nP35625\n\n\nP30711\n-1.692001\n0.3157636\n9.492387\n-5.358443\n0.0003818\n0.0295584\nP30711\n\n\nP14854\n1.259547\n0.2300868\n9.066347\n5.474224\n0.0003831\n0.0295584\nP14854\n\n\nP29622\n-1.296379\n0.2383018\n9.113749\n-5.440070\n0.0003935\n0.0295584\nP29622\n\n\nQ15327\n-1.566469\n0.2941564\n9.451901\n-5.325292\n0.0004053\n0.0295584\nQ15327\n\n\nQ9NRG4\n2.572149\n0.4631363\n8.484155\n5.553763\n0.0004377\n0.0308916\nQ9NRG4\n\n\nO75368\n-1.320075\n0.2537600\n9.191185\n-5.202062\n0.0005256\n0.0344087\nO75368\n\n\nQ5NDL2\n-2.083671\n0.4071966\n9.517072\n-5.117114\n0.0005290\n0.0344087\nQ5NDL2\n\n\nP01031\n-1.205507\n0.2348255\n9.289894\n-5.133627\n0.0005579\n0.0344087\nP01031\n\n\nQ6PCB0\n-1.734824\n0.3399387\n9.378729\n-5.103342\n0.0005646\n0.0344087\nQ6PCB0\n\n\nP61925\n2.051193\n0.3786314\n8.266540\n5.417388\n0.0005661\n0.0344087\nP61925\n\n\nA6NMZ7\n-2.357794\n0.4729659\n9.707078\n-4.985124\n0.0006007\n0.0348990\nA6NMZ7\n\n\nQ5JPH6\n3.345723\n0.5352998\n6.397711\n6.250186\n0.0006061\n0.0348990\nQ5JPH6\n\n\nQ9P2B2\n-1.483082\n0.2953969\n9.357789\n-5.020641\n0.0006381\n0.0358009\nQ9P2B2\n\n\nQ9HAT2\n2.033947\n0.4116210\n9.296680\n4.941310\n0.0007275\n0.0385182\nQ9HAT2\n\n\nQ9UGT4\n-1.864637\n0.3842304\n9.601092\n-4.852913\n0.0007514\n0.0385182\nQ9UGT4\n\n\nP23142\n-2.130549\n0.4396656\n9.545973\n-4.845840\n0.0007718\n0.0385182\nP23142\n\n\nP08294\n-1.614308\n0.3320461\n9.307183\n-4.861700\n0.0008114\n0.0385182\nP08294\n\n\nQ14764\n-1.079085\n0.2205762\n9.165409\n-4.892120\n0.0008127\n0.0385182\nQ14764\n\n\nP35052\n-1.566974\n0.3100259\n8.489597\n-5.054332\n0.0008208\n0.0385182\nP35052\n\n\nP51888\n-1.505290\n0.3098730\n9.246559\n-4.857764\n0.0008314\n0.0385182\nP51888\n\n\nQ9HCB6\n-1.756881\n0.3660009\n9.478445\n-4.800210\n0.0008413\n0.0385182\nQ9HCB6\n\n\nP02775\n-1.630806\n0.3394307\n9.442684\n-4.804531\n0.0008450\n0.0385182\nP02775\n\n\nQ8N142\n1.394024\n0.2921992\n9.488674\n4.770801\n0.0008753\n0.0390833\nQ8N142\n\n\nQ9Y4W6\n1.102812\n0.2294084\n9.235088\n4.807199\n0.0008963\n0.0392226\nQ9Y4W6\n\n\nP48681\n-1.101098\n0.2312917\n9.238145\n-4.760646\n0.0009568\n0.0410483\nP48681\n\n\nP46821\n-1.120872\n0.2355359\n9.150270\n-4.758817\n0.0009851\n0.0412685\nP46821\n\n\nQ9Y6X5\n-1.159408\n0.2466137\n9.378833\n-4.701313\n0.0009996\n0.0412685\nQ9Y6X5\n\n\nQ9BSD7\n2.569845\n0.5189540\n7.936523\n4.951970\n0.0011446\n0.0463795\nQ9BSD7\n\n\nQ06828\n-3.298913\n0.7287820\n9.730028\n-4.526612\n0.0011758\n0.0467768\nQ06828\n\n\nP51970\n1.071905\n0.2350925\n9.453305\n4.559505\n0.0012049\n0.0470148\nP51970\n\n\nQ6UWS5\n1.979951\n0.3609481\n6.427167\n5.485418\n0.0012248\n0.0470148\nQ6UWS5\n\n\nP10109\n1.211344\n0.2678468\n9.462988\n4.522524\n0.0012695\n0.0478898\nP10109\n\n\nQ9NRX4\n1.605283\n0.3585462\n9.576287\n4.477201\n0.0013185\n0.0488954\nQ9NRX4\n\n\n\n\n\n\n\n\n6.7.7 Evaluate results average contrast \\(\\log_2 FC_{V-A}\\)\nLet us retrieve the result table from the rowData. The second column contains the results for contrast \\(\\log_2 FC_{V-A}\\).\n\ninferenceAvg &lt;- rowData(pe[[\"proteins\"]])[[colnames(L)[3]]]\ninferenceAvg$Protein &lt;- rownames(inferenceAvg)\nhead(inferenceAvg)\n\n             logFC           se        df          t       pval   adjPval\nA0PJW6  0.00000000 3.896150e-10 14.003000  0.0000000 1.00000000 1.0000000\nA0PJZ3          NA           NA        NA         NA         NA        NA\nA0PK00          NA           NA  5.826529         NA         NA        NA\nA1A4S6  0.04216227 6.290247e-02 13.324734  0.6702799 0.51412912 1.0000000\nA1A5D9          NA           NA        NA         NA         NA        NA\nA1IGU5 -0.26537952 1.435953e-01 10.934858 -1.8481073 0.09179013 0.3358475\n       Protein\nA0PJW6  A0PJW6\nA0PJZ3  A0PJZ3\nA0PK00  A0PK00\nA1A4S6  A1A4S6\nA1A5D9  A1A5D9\nA1IGU5  A1IGU5\n\n\n\nVolcano plot\nVolcano plots are straightforward to generate from the inference table above. We also use ggrepel to annotate the 20 most significant proteins.\n\nggplot(inferenceAvg) +\n  aes(x = logFC, y = -log10(pval), color = adjPval &lt; 0.05) +\n  geom_point() +\n  geom_text_repel(data = slice_min(inferenceAvg, adjPval, n = 20),\n                  aes(label = Protein)) +\n  scale_color_manual(values = alpha(c(\"black\", \"red\"), 0.5)) + \n  ggtitle(\"log2 FC V-A Right\",\n          paste(\"Hypothesis test:\", colnames(L)[2], \"= 0\"))\n\n\n\n\n\n\n\n\n\n\nHeatmap\nWe can also build a heatmap for the significant proteins which are obtained by filtering the inference table.\n\nsigNamesAvg &lt;- inferenceAvg |&gt; \n  filter(!is.na(adjPval), adjPval &lt; 0.05) |&gt; \n  pull()\nse &lt;- getWithColData(pe, \"proteins\")[sigNamesAvg, ]\nquants &lt;- t(scale(t(assay(se))))\nset.seed(1234) ## annotation colours are randomly generated by default\nHeatmap(\n quants, name = \"log2 intensity\",\n top_annotation = annotations\n)\n\n\n\n\n\n\n\n\nThere are 264 proteins significantly differentially expressed at the 5% FDR level.\nBelow you can find the list of significant proteins.\n\ninferenceAvg |&gt;\n  na.exclude() |&gt;\n  filter(adjPval&lt;0.05) |&gt;\n  arrange(pval)  |&gt;\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlogFC\nse\ndf\nt\npval\nadjPval\nProtein\n\n\n\n\nP08590\n6.8718531\n0.3268358\n9.066700\n21.025398\n0.0000000\n0.0000115\nP08590\n\n\nP12883\n3.3364301\n0.2448303\n9.108910\n13.627520\n0.0000002\n0.0002510\nP12883\n\n\nP06858\n2.8398932\n0.2374666\n9.148010\n11.959126\n0.0000007\n0.0004333\nP06858\n\n\nP10916\n5.1197819\n0.3298586\n7.093703\n15.521141\n0.0000010\n0.0004333\nP10916\n\n\nQ6UWY5\n-2.4874855\n0.2202460\n9.147279\n-11.294126\n0.0000011\n0.0004333\nQ6UWY5\n\n\nP14854\n1.8149997\n0.1603557\n9.066347\n11.318585\n0.0000012\n0.0004333\nP14854\n\n\nP21810\n-2.4248168\n0.2462386\n9.230160\n-9.847427\n0.0000034\n0.0010530\nP21810\n\n\nP05546\n-1.4760026\n0.1599979\n9.089659\n-9.225140\n0.0000065\n0.0014784\nP05546\n\n\nP51888\n-2.0189161\n0.2221104\n9.246559\n-9.089697\n0.0000065\n0.0014784\nP51888\n\n\nO94875-10\n1.9967297\n0.2201929\n9.230071\n9.068093\n0.0000068\n0.0014784\nO94875-10\n\n\nP02776\n-1.8558833\n0.2131785\n9.240633\n-8.705771\n0.0000094\n0.0017739\nP02776\n\n\nQ00G26\n1.8347517\n0.2121126\n9.271814\n8.649893\n0.0000097\n0.0017739\nQ00G26\n\n\nO75368\n-1.5357360\n0.1791590\n9.191185\n-8.571914\n0.0000111\n0.0017804\nO75368\n\n\nP29622\n-1.4206134\n0.1659883\n9.113749\n-8.558513\n0.0000119\n0.0017804\nP29622\n\n\nP46821\n-1.4186399\n0.1668418\n9.150270\n-8.502903\n0.0000122\n0.0017804\nP46821\n\n\nP13533\n-3.1538958\n0.3885644\n9.431456\n-8.116790\n0.0000149\n0.0019214\nP13533\n\n\nP23434\n1.5413943\n0.1870234\n9.231040\n8.241720\n0.0000149\n0.0019214\nP23434\n\n\nP48163\n-1.7231690\n0.2140965\n9.233764\n-8.048562\n0.0000181\n0.0021010\nP48163\n\n\nP08294\n-1.8748304\n0.2345078\n9.307183\n-7.994747\n0.0000182\n0.0021010\nP08294\n\n\nQ8N474\n-2.2252733\n0.2593043\n8.190289\n-8.581705\n0.0000227\n0.0022887\nQ8N474\n\n\nQ6YN16\n1.5505133\n0.1989270\n9.276732\n7.794385\n0.0000229\n0.0022887\nQ6YN16\n\n\nO43677\n-2.2818039\n0.2956909\n9.401692\n-7.716855\n0.0000230\n0.0022887\nO43677\n\n\nP54652\n-1.7712555\n0.2302085\n9.325197\n-7.694137\n0.0000247\n0.0023452\nP54652\n\n\nP24298\n1.8983921\n0.2490507\n9.384519\n7.622512\n0.0000257\n0.0023452\nP24298\n\n\nP18428\n-1.4437423\n0.1912298\n9.299328\n-7.549776\n0.0000293\n0.0025615\nP18428\n\n\nQ9P2B2\n-1.5665103\n0.2098477\n9.357789\n-7.464987\n0.0000310\n0.0026079\nQ9P2B2\n\n\nA6NDG6\n1.4132236\n0.1893082\n9.276465\n7.465199\n0.0000325\n0.0026334\nA6NDG6\n\n\nP15924\n1.1865540\n0.1629059\n9.110066\n7.283678\n0.0000436\n0.0034053\nP15924\n\n\nQ14764\n-1.1170292\n0.1559709\n9.165409\n-7.161778\n0.0000482\n0.0036399\nQ14764\n\n\nP04004\n-1.3605995\n0.1939297\n9.270800\n-7.015941\n0.0000536\n0.0039063\nP04004\n\n\nP24844\n-1.6335444\n0.2377501\n9.433933\n-6.870845\n0.0000580\n0.0040359\nP24844\n\n\nP11586\n1.4562651\n0.2117089\n9.333226\n6.878620\n0.0000606\n0.0040359\nP11586\n\n\nQ5NDL2\n-1.9157423\n0.2823635\n9.517072\n-6.784667\n0.0000615\n0.0040359\nQ5NDL2\n\n\nP60468\n-1.4985317\n0.2011269\n8.191586\n-7.450677\n0.0000642\n0.0040359\nP60468\n\n\nQ69YU5\n2.4754644\n0.3685265\n9.579396\n6.717195\n0.0000646\n0.0040359\nQ69YU5\n\n\nQ9BW30\n-1.9177197\n0.2869707\n9.534123\n-6.682633\n0.0000688\n0.0041828\nQ9BW30\n\n\nQ15113\n-1.6629972\n0.2516710\n9.536113\n-6.607821\n0.0000752\n0.0043619\nQ15113\n\n\nP04196\n-1.2482839\n0.1860851\n9.273169\n-6.708133\n0.0000762\n0.0043619\nP04196\n\n\nQ9Y4W6\n1.0879384\n0.1622163\n9.235088\n6.706716\n0.0000778\n0.0043619\nQ9Y4W6\n\n\nP19429\n2.2476195\n0.3448005\n9.586884\n6.518608\n0.0000818\n0.0043619\nP19429\n\n\nP02747\n-1.4838172\n0.2247118\n9.364965\n-6.603201\n0.0000823\n0.0043619\nP02747\n\n\nP02775\n-1.5738214\n0.2400296\n9.442684\n-6.556779\n0.0000837\n0.0043619\nP02775\n\n\nQ9UGT4\n-1.7582895\n0.2716919\n9.601092\n-6.471630\n0.0000861\n0.0043791\nQ9UGT4\n\n\nP02743\n-1.4372727\n0.2184192\n9.259904\n-6.580340\n0.0000891\n0.0044302\nP02743\n\n\nQ9NRG4\n2.4292862\n0.3537262\n8.484155\n6.867703\n0.0000974\n0.0047344\nQ9NRG4\n\n\nQ06828\n-3.2878219\n0.5231368\n9.730028\n-6.284823\n0.0001024\n0.0048709\nQ06828\n\n\nP01031\n-1.0556049\n0.1655342\n9.289894\n-6.376960\n0.0001120\n0.0052117\nP01031\n\n\nQ9HCB6\n-1.5477618\n0.2477605\n9.478445\n-6.247007\n0.0001203\n0.0054690\nQ9HCB6\n\n\nP05997\n-1.9099570\n0.3080473\n9.559204\n-6.200206\n0.0001230\n0.0054690\nP05997\n\n\nP02452\n-1.6021991\n0.2593204\n9.585356\n-6.178453\n0.0001250\n0.0054690\nP02452\n\n\nP48681\n-1.0102767\n0.1617208\n9.238145\n-6.247042\n0.0001343\n0.0057622\nP48681\n\n\nO14967\n-1.2432881\n0.2005888\n9.248331\n-6.198193\n0.0001419\n0.0059021\nO14967\n\n\nO00180\n-3.4637187\n0.5425840\n8.732659\n-6.383747\n0.0001457\n0.0059021\nO00180\n\n\nP23142\n-1.8311086\n0.3022843\n9.545973\n-6.057572\n0.0001483\n0.0059021\nP23142\n\n\nQ9HAT2\n1.7914105\n0.2921487\n9.296680\n6.131845\n0.0001507\n0.0059021\nQ9HAT2\n\n\nP10109\n1.1498726\n0.1893963\n9.462988\n6.071252\n0.0001511\n0.0059021\nP10109\n\n\nQ13011\n1.1833804\n0.1965056\n9.478440\n6.022121\n0.0001597\n0.0061310\nQ13011\n\n\nQ8N142\n1.2230990\n0.2045058\n9.488674\n5.980754\n0.0001677\n0.0063249\nQ8N142\n\n\nQ9UNW9\n3.0434487\n0.5128825\n9.536696\n5.934007\n0.0001745\n0.0063613\nQ9UNW9\n\n\nQ9NRX4\n1.5004765\n0.2535304\n9.576287\n5.918329\n0.0001752\n0.0063613\nQ9NRX4\n\n\nA6NMZ7\n-1.9793762\n0.3373225\n9.707078\n-5.867904\n0.0001773\n0.0063613\nA6NMZ7\n\n\nP23786\n0.9013183\n0.1492546\n9.134748\n6.038796\n0.0001818\n0.0064157\nP23786\n\n\nQ04760\n1.5360653\n0.2602426\n9.441126\n5.902435\n0.0001892\n0.0064537\nQ04760\n\n\nQ15327\n-1.2106705\n0.2054754\n9.451901\n-5.892044\n0.0001909\n0.0064537\nQ15327\n\n\nP17540\n1.0681187\n0.1809634\n9.408560\n5.902403\n0.0001918\n0.0064537\nP17540\n\n\nO95865\n-1.1476181\n0.1943037\n9.360986\n-5.906311\n0.0001947\n0.0064537\nO95865\n\n\nQ5JPH6\n3.4628551\n0.4565052\n6.397711\n7.585577\n0.0002001\n0.0065352\nQ5JPH6\n\n\nP51884\n-1.3320008\n0.2297628\n9.576049\n-5.797287\n0.0002052\n0.0066034\nP51884\n\n\nP04083\n-0.9538541\n0.1644374\n9.318065\n-5.800712\n0.0002269\n0.0071964\nP04083\n\n\nP30711\n-1.3399014\n0.2344998\n9.492387\n-5.713869\n0.0002368\n0.0073379\nP30711\n\n\nQ7L4S7\n-1.7163672\n0.2582743\n7.332929\n-6.645522\n0.0002381\n0.0073379\nQ7L4S7\n\n\nO95980\n-1.3087089\n0.2312413\n9.498408\n-5.659495\n0.0002539\n0.0077157\nO95980\n\n\nP00325\n-1.1271284\n0.1975885\n9.177945\n-5.704422\n0.0002721\n0.0081541\nP00325\n\n\nQ9UKS6\n1.1555353\n0.2067472\n9.488160\n5.589122\n0.0002799\n0.0081958\nQ9UKS6\n\n\nP28066\n-1.1657717\n0.2083507\n9.457629\n-5.595237\n0.0002809\n0.0081958\nP28066\n\n\nQ9ULD0\n-1.6081853\n0.2436750\n7.104538\n-6.599713\n0.0002855\n0.0082204\nQ9ULD0\n\n\nQ86VU5\n1.3909551\n0.2522544\n9.638787\n5.514095\n0.0002927\n0.0083166\nQ86VU5\n\n\nP14923\n0.8397640\n0.1494538\n9.171357\n5.618887\n0.0003046\n0.0085450\nP14923\n\n\nQ6PCB0\n-1.3159366\n0.2380883\n9.378729\n-5.527094\n0.0003170\n0.0087809\nQ6PCB0\n\n\nP24311\n1.3296314\n0.2409955\n9.362276\n5.517246\n0.0003232\n0.0088407\nP24311\n\n\nQ9HBL0\n1.3884913\n0.2368572\n8.180895\n5.862145\n0.0003467\n0.0092101\nQ9HBL0\n\n\nQ9BXV9\n1.4577749\n0.2727782\n9.805041\n5.344177\n0.0003488\n0.0092101\nQ9BXV9\n\n\nQ9ULL5-3\n-1.7449314\n0.3044597\n8.505757\n-5.731239\n0.0003494\n0.0092101\nQ9ULL5-3\n\n\nP61925\n1.5601183\n0.2689974\n8.266540\n5.799751\n0.0003583\n0.0093340\nP61925\n\n\nP23083\n-2.6793814\n0.4331242\n7.380951\n-6.186173\n0.0003652\n0.0094013\nP23083\n\n\nO75489\n0.9977662\n0.1872393\n9.598971\n5.328829\n0.0003829\n0.0096301\nO75489\n\n\nP63316\n0.9567764\n0.1785086\n9.478611\n5.359834\n0.0003829\n0.0096301\nP63316\n\n\nP07195\n0.9985697\n0.1874549\n9.501868\n5.326987\n0.0003972\n0.0098767\nP07195\n\n\nP35625\n-2.1754244\n0.3893925\n8.562007\n-5.586713\n0.0004068\n0.0100014\nP35625\n\n\nP17174\n1.0116885\n0.1913267\n9.468860\n5.287755\n0.0004242\n0.0103116\nP17174\n\n\nO15230\n-0.8483405\n0.1605308\n9.335882\n-5.284596\n0.0004465\n0.0107248\nO15230\n\n\nQ6PI78\n1.4696344\n0.2848643\n9.822092\n5.159069\n0.0004510\n0.0107248\nQ6PI78\n\n\nQ9BXN1\n-1.6449225\n0.3195425\n9.779246\n-5.147743\n0.0004648\n0.0109342\nQ9BXN1\n\n\nQ9Y6X5\n-0.9114382\n0.1743822\n9.378833\n-5.226669\n0.0004760\n0.0110806\nQ9Y6X5\n\n\nQ16647\n-1.3098697\n0.2578596\n9.742336\n-5.079778\n0.0005184\n0.0119394\nQ16647\n\n\nP21399\n0.7733919\n0.1506412\n9.280176\n5.134001\n0.0005594\n0.0127385\nP21399\n\n\nP51970\n0.8453891\n0.1662355\n9.453305\n5.085491\n0.0005647\n0.0127385\nP51970\n\n\nQ96RP7\n-3.2449509\n0.4617082\n5.483644\n-7.028142\n0.0006117\n0.0136580\nQ96RP7\n\n\nQ9Y3B4\n-0.8676537\n0.1727639\n9.303225\n-5.022194\n0.0006482\n0.0143256\nQ9Y3B4\n\n\nP50453\n-0.7669119\n0.1527314\n9.251199\n-5.021311\n0.0006602\n0.0144443\nP50453\n\n\nQ6DKK2\n1.0463979\n0.2120923\n9.412715\n4.933692\n0.0007089\n0.0153565\nQ6DKK2\n\n\nP02748\n-0.9028985\n0.1827215\n9.328466\n-4.941392\n0.0007201\n0.0154467\nP02748\n\n\nQ8TBQ9\n-1.2020325\n0.2459524\n9.446801\n-4.887257\n0.0007494\n0.0159192\nQ8TBQ9\n\n\nQ9NZ01\n-1.2126719\n0.2534197\n9.896186\n-4.785231\n0.0007618\n0.0160279\nQ9NZ01\n\n\nP12110\n-0.9713556\n0.2007269\n9.536991\n-4.839189\n0.0007814\n0.0161672\nP12110\n\n\nP12814\n-1.3411812\n0.2670430\n8.741139\n-5.022341\n0.0007832\n0.0161672\nP12814\n\n\nP04003\n-1.0633338\n0.2197570\n9.469818\n-4.838681\n0.0007979\n0.0163158\nP04003\n\n\nQ53FA7\n1.5581378\n0.3239189\n9.564359\n4.810272\n0.0008082\n0.0163742\nQ53FA7\n\n\nP00748\n-1.1346342\n0.2388519\n9.766668\n-4.750367\n0.0008324\n0.0167096\nP00748\n\n\nP14550\n-0.7790248\n0.1630649\n9.485559\n-4.777390\n0.0008677\n0.0171682\nP14550\n\n\nQ9UBB5\n1.4018949\n0.2313680\n6.082236\n6.059156\n0.0008710\n0.0171682\nQ9UBB5\n\n\nP11766\n0.7921470\n0.1663652\n9.467043\n4.761494\n0.0008928\n0.0172923\nP11766\n\n\nP06732\n0.7828169\n0.1641535\n9.430106\n4.768811\n0.0008931\n0.0172923\nP06732\n\n\nQ12996\n-1.1900567\n0.2231950\n7.365790\n-5.331914\n0.0009195\n0.0176483\nQ12996\n\n\nQ8TDB4\n-1.8274152\n0.3415970\n7.269123\n-5.349622\n0.0009413\n0.0178003\nQ8TDB4\n\n\nP36021\n-1.7395850\n0.3577586\n8.828176\n-4.862455\n0.0009437\n0.0178003\nP36021\n\n\nQ92604\n-1.3127130\n0.2837564\n9.947381\n-4.626197\n0.0009548\n0.0178558\nQ92604\n\n\nQ9Y3D0\n1.6486483\n0.2959909\n6.670659\n5.569929\n0.0009933\n0.0184189\nQ9Y3D0\n\n\nQ6P1L8\n0.8425184\n0.1817397\n9.707064\n4.635853\n0.0010038\n0.0184563\nQ6P1L8\n\n\nQ6UWS5\n1.7220515\n0.3040600\n6.427167\n5.663526\n0.0010290\n0.0186969\nQ6UWS5\n\n\nQ6SZW1\n-1.4203348\n0.2792520\n7.758278\n-5.086212\n0.0010392\n0.0186969\nQ6SZW1\n\n\nP51151\n0.7775244\n0.1671543\n9.434716\n4.651537\n0.0010578\n0.0186969\nP51151\n\n\nQ53GQ0\n-1.1175142\n0.2430407\n9.718619\n-4.598054\n0.0010590\n0.0186969\nQ53GQ0\n\n\nP30405\n-1.0553674\n0.2310692\n9.892316\n-4.567322\n0.0010596\n0.0186969\nP30405\n\n\nP36955\n-1.0735843\n0.2345867\n9.772134\n-4.576493\n0.0010784\n0.0187156\nP36955\n\n\nP35754\n1.0604547\n0.2323092\n9.831307\n4.564842\n0.0010807\n0.0187156\nP35754\n\n\nQ14195-2\n-1.5280180\n0.3350901\n9.839393\n-4.560022\n0.0010863\n0.0187156\nQ14195-2\n\n\nQ5VUM1\n0.9061256\n0.1979080\n9.589831\n4.578519\n0.0011288\n0.0192961\nQ5VUM1\n\n\nP13667\n-0.7220582\n0.1596332\n9.557580\n-4.523233\n0.0012366\n0.0209741\nP13667\n\n\nQ9NQ50\n0.8058197\n0.1789252\n9.618824\n4.503668\n0.0012531\n0.0209972\nQ9NQ50\n\n\nQ00688\n0.8160471\n0.1814802\n9.643216\n4.496617\n0.0012584\n0.0209972\nQ00688\n\n\nO95182\n0.8368612\n0.1862421\n9.636518\n4.493405\n0.0012667\n0.0209972\nO95182\n\n\nQ8WZ42-6\n0.6975568\n0.1542241\n9.391830\n4.523007\n0.0012931\n0.0212722\nQ8WZ42-6\n\n\nQ9ULC3\n-0.8541539\n0.1918910\n9.768835\n-4.451245\n0.0013056\n0.0213180\nQ9ULC3\n\n\nO94919\n-0.6975347\n0.1543245\n9.271008\n-4.519921\n0.0013422\n0.0215226\nO94919\n\n\nQ9UKX3\n1.2122113\n0.2751758\n9.937136\n4.405225\n0.0013445\n0.0215226\nQ9UKX3\n\n\nP46060\n-1.2255778\n0.2663746\n8.847600\n-4.600957\n0.0013476\n0.0215226\nP46060\n\n\nQ86VP6\n-0.8480596\n0.1934764\n9.783783\n-4.383271\n0.0014437\n0.0228894\nQ86VP6\n\n\nP80723\n-1.1832701\n0.2565319\n8.478989\n-4.612565\n0.0014826\n0.0231809\nP80723\n\n\nP13073\n0.7406291\n0.1679121\n9.498815\n4.410813\n0.0014863\n0.0231809\nP13073\n\n\nQ63HM9\n0.8199517\n0.1857191\n9.454228\n4.415009\n0.0014938\n0.0231809\nQ63HM9\n\n\nQ5M9N0\n-1.6991316\n0.3824461\n9.175048\n-4.442800\n0.0015423\n0.0235916\nQ5M9N0\n\n\nP25940\n-0.9714255\n0.2245491\n9.837648\n-4.326117\n0.0015568\n0.0235916\nP25940\n\n\nO14949\n1.0203567\n0.2356108\n9.770618\n4.330688\n0.0015706\n0.0235916\nO14949\n\n\nQ5T481\n0.7543759\n0.1728985\n9.531949\n4.363114\n0.0015840\n0.0235916\nQ5T481\n\n\nQ5JUQ0\n2.3923426\n0.5129180\n8.057125\n4.664182\n0.0015843\n0.0235916\nQ5JUQ0\n\n\nQ12988\n-0.7197658\n0.1648005\n9.502808\n-4.367499\n0.0015850\n0.0235916\nQ12988\n\n\nP14543\n-0.8237268\n0.1917450\n9.883607\n-4.295950\n0.0016142\n0.0238635\nP14543\n\n\nP15848\n0.9610948\n0.2235365\n9.748276\n4.299497\n0.0016569\n0.0242835\nP15848\n\n\nP48047\n0.7986239\n0.1848261\n9.569504\n4.320948\n0.0016733\n0.0242835\nP48047\n\n\nP35052\n-0.9094996\n0.2011858\n8.489597\n-4.520695\n0.0016759\n0.0242835\nP35052\n\n\nP54296\n0.6696406\n0.1553053\n9.514121\n4.311768\n0.0017199\n0.0247578\nP54296\n\n\nQ15274\n-1.2921878\n0.2941256\n9.004136\n-4.393319\n0.0017352\n0.0247789\nQ15274\n\n\nO60503\n1.4353510\n0.2857061\n6.681999\n5.023872\n0.0017484\n0.0247789\nO60503\n\n\nP01034\n-0.9479850\n0.2241187\n9.971490\n-4.229835\n0.0017554\n0.0247789\nP01034\n\n\nQ96H79\n-1.4874612\n0.2966075\n6.634593\n-5.014914\n0.0018028\n0.0251508\nQ96H79\n\n\nO14980\n-0.6307124\n0.1452780\n9.144414\n-4.341416\n0.0018047\n0.0251508\nO14980\n\n\nQ9BUF5\n-1.0681765\n0.2531304\n9.885958\n-4.219867\n0.0018176\n0.0251700\nQ9BUF5\n\n\nP07585\n-1.3970312\n0.3326320\n9.953888\n-4.199930\n0.0018475\n0.0253056\nP07585\n\n\nP01042\n-1.8796814\n0.4047966\n7.668959\n-4.643520\n0.0018550\n0.0253056\nP01042\n\n\nP24752\n0.8147048\n0.1944004\n9.964493\n4.190859\n0.0018699\n0.0253056\nP24752\n\n\nQ8WY22\n-0.9915506\n0.2269833\n8.852505\n-4.368386\n0.0018736\n0.0253056\nQ8WY22\n\n\nQ86SX6\n0.7916631\n0.1879923\n9.736249\n4.211146\n0.0019058\n0.0255827\nQ86SX6\n\n\nQ86WV6\n-0.8075576\n0.1910670\n9.427466\n-4.226569\n0.0019992\n0.0264446\nQ86WV6\n\n\nQ9H479\n0.7577083\n0.1810834\n9.704367\n4.184305\n0.0020016\n0.0264446\nQ9H479\n\n\nQ53GG5\n1.1080565\n0.2648156\n9.694276\n4.184258\n0.0020063\n0.0264446\nQ53GG5\n\n\nQ9BTV4\n-0.9341181\n0.2278205\n10.185239\n-4.100238\n0.0020631\n0.0270307\nQ9BTV4\n\n\nQ9NNX1\n2.9099745\n0.6201504\n7.088545\n4.692369\n0.0021547\n0.0280621\nQ9NNX1\n\n\nP09619\n-0.6550082\n0.1570063\n9.413215\n-4.171860\n0.0021806\n0.0282314\nP09619\n\n\nQ8WWA0\n-2.7659862\n0.6806045\n10.156219\n-4.064014\n0.0022007\n0.0283248\nQ8WWA0\n\n\nP49770\n0.8269399\n0.2038694\n9.944656\n4.056224\n0.0023268\n0.0295944\nP49770\n\n\nQ02127\n1.2039706\n0.2657171\n7.401140\n4.531024\n0.0023416\n0.0295944\nQ02127\n\n\nI3L505\n1.1067201\n0.2753159\n10.197875\n4.019819\n0.0023451\n0.0295944\nI3L505\n\n\nQ9H3K6\n0.6971910\n0.1711668\n9.728454\n4.073168\n0.0023699\n0.0295944\nQ9H3K6\n\n\nP01024\n-0.6372280\n0.1551230\n9.468507\n-4.107887\n0.0023758\n0.0295944\nP01024\n\n\nO43920\n0.7719300\n0.1911945\n9.980424\n4.037406\n0.0023805\n0.0295944\nO43920\n\n\nP02461\n-1.9014625\n0.4756591\n10.174961\n-3.997532\n0.0024428\n0.0301970\nP02461\n\n\nP31930\n0.6341469\n0.1559075\n9.566010\n4.067457\n0.0024760\n0.0304356\nP31930\n\n\nQ13541\n1.0054699\n0.2514700\n10.012338\n3.998369\n0.0025188\n0.0305275\nQ13541\n\n\nQ9NQR4\n0.8497236\n0.2125583\n10.005294\n3.997603\n0.0025254\n0.0305275\nQ9NQR4\n\n\nQ9Y287\n-0.8805657\n0.2201911\n9.991693\n-3.999097\n0.0025262\n0.0305275\nQ9Y287\n\n\nP06727\n-0.7439890\n0.1815376\n9.225409\n-4.098264\n0.0025471\n0.0305275\nP06727\n\n\nP00352\n-0.6833984\n0.1679840\n9.400007\n-4.068236\n0.0025644\n0.0305275\nP00352\n\n\nP40939\n0.6064551\n0.1482708\n9.244856\n4.090186\n0.0025672\n0.0305275\nP40939\n\n\nP55039\n1.0233844\n0.2291242\n7.304575\n4.466505\n0.0026220\n0.0310109\nP55039\n\n\nQ04721\n1.0485452\n0.2622467\n9.688477\n3.998316\n0.0026896\n0.0315505\nQ04721\n\n\nP49458\n-1.1981452\n0.2798019\n7.977794\n-4.282120\n0.0026970\n0.0315505\nP49458\n\n\nP04209\n0.8634678\n0.2148474\n9.495921\n4.018982\n0.0027109\n0.0315505\nP04209\n\n\nQ15773\n0.7582360\n0.1916223\n9.910180\n3.956931\n0.0027477\n0.0316513\nQ15773\n\n\nP02790\n-0.7830751\n0.1991261\n10.113121\n-3.932558\n0.0027485\n0.0316513\nP02790\n\n\nP07451\n-0.7379038\n0.1847289\n9.585814\n-3.994523\n0.0027639\n0.0316617\nP07451\n\n\nQ53T59\n-1.1978861\n0.2885746\n8.466573\n-4.151045\n0.0028322\n0.0322757\nQ53T59\n\n\nP03928\n0.7362835\n0.1874644\n9.915745\n3.927591\n0.0028776\n0.0326230\nP03928\n\n\nQ9UBG0\n-1.0333426\n0.2624451\n9.768266\n-3.937366\n0.0029158\n0.0328547\nQ9UBG0\n\n\nQ96MM6\n1.3370336\n0.3311082\n9.013572\n4.038057\n0.0029281\n0.0328547\nQ96MM6\n\n\nQ9UMR3\n-1.2814546\n0.2782321\n6.538023\n-4.605703\n0.0029441\n0.0328657\nQ9UMR3\n\n\nQ92681\n-1.0478169\n0.2621030\n9.184710\n-3.997730\n0.0029961\n0.0331615\nQ92681\n\n\nQ02318\n-1.0543306\n0.2224723\n6.136433\n-4.739155\n0.0030083\n0.0331615\nQ02318\n\n\nQ9BX66-5\n1.0070024\n0.2303104\n7.236228\n4.372370\n0.0030161\n0.0331615\nQ9BX66-5\n\n\nO60760\n-1.4579900\n0.3648196\n9.077881\n-3.996469\n0.0030733\n0.0335841\nO60760\n\n\nQ14353\n0.9837112\n0.2560148\n10.277210\n3.842400\n0.0030937\n0.0335841\nQ14353\n\n\nO76031\n0.5944195\n0.1511239\n9.488222\n3.933326\n0.0031046\n0.0335841\nO76031\n\n\nP21953\n0.9232656\n0.2355721\n9.579770\n3.919248\n0.0031159\n0.0335841\nP21953\n\n\nP17050\n-0.6604019\n0.1688233\n9.576790\n-3.911793\n0.0031547\n0.0338359\nP17050\n\n\nO00264\n-0.7449556\n0.1928619\n9.921595\n-3.862637\n0.0031930\n0.0339604\nO00264\n\n\nP13671\n-0.8057348\n0.2080950\n9.834309\n-3.871957\n0.0031974\n0.0339604\nP13671\n\n\nP08574\n0.6109407\n0.1574461\n9.718140\n3.880317\n0.0032258\n0.0340964\nP08574\n\n\nQ8IUX7\n-1.7161917\n0.4188348\n8.138665\n-4.097538\n0.0033255\n0.0349822\nQ8IUX7\n\n\nQ96CS3\n-0.7036507\n0.1837872\n9.754773\n-3.828616\n0.0034805\n0.0364366\nQ96CS3\n\n\nQ9BZH6\n1.9481367\n0.5201485\n10.412295\n3.745347\n0.0035553\n0.0368470\nQ9BZH6\n\n\nP28070\n-0.6488737\n0.1693730\n9.617848\n-3.831034\n0.0035579\n0.0368470\nP28070\n\n\nQ3ZCW2\n-0.8754815\n0.2241369\n9.021266\n-3.906013\n0.0035702\n0.0368470\nQ3ZCW2\n\n\nP09874\n0.5848364\n0.1521501\n9.439573\n3.843813\n0.0036089\n0.0370716\nP09874\n\n\nQ9UBV8\n-0.7235789\n0.1896245\n9.594672\n-3.815851\n0.0036613\n0.0372603\nQ9UBV8\n\n\nQ8WZA9\n-0.6588659\n0.1724436\n9.553531\n-3.820763\n0.0036613\n0.0372603\nQ8WZA9\n\n\nP40261\n-0.9050994\n0.2361125\n9.424468\n-3.833340\n0.0036798\n0.0372752\nP40261\n\n\nQ16762\n0.6896826\n0.1829052\n9.857793\n3.770710\n0.0037509\n0.0376724\nQ16762\n\n\nO15195-2\n1.3363469\n0.3118800\n6.902306\n4.284811\n0.0037535\n0.0376724\nO15195-2\n\n\nQ9HAN9\n1.1414801\n0.2876745\n8.335372\n3.967958\n0.0038043\n0.0380082\nQ9HAN9\n\n\nQ8TBP6\n-0.8031089\n0.2158104\n10.178944\n-3.721363\n0.0038477\n0.0382674\nQ8TBP6\n\n\nQ07507\n-0.7241081\n0.1920710\n9.608284\n-3.770002\n0.0039297\n0.0389061\nQ07507\n\n\nP46940\n-0.6392674\n0.1713924\n9.877120\n-3.729847\n0.0039957\n0.0393808\nP46940\n\n\nO95202\n0.5779418\n0.1532531\n9.434554\n3.771159\n0.0040519\n0.0396103\nO95202\n\n\nP08603\n-0.6992781\n0.1878961\n9.869474\n-3.721621\n0.0040552\n0.0396103\nP08603\n\n\nQ8TAL6\n-1.8063108\n0.4072295\n6.166509\n-4.435608\n0.0041152\n0.0400182\nQ8TAL6\n\n\nQ9HB40\n-1.1127203\n0.2527625\n6.220567\n-4.402237\n0.0041808\n0.0404764\nQ9HB40\n\n\nO75190-3\n1.1109397\n0.3052132\n10.314084\n3.639881\n0.0043145\n0.0415862\nO75190-3\n\n\nQ9H511\n0.6668969\n0.1811347\n9.812109\n3.681773\n0.0043711\n0.0419470\nQ9H511\n\n\nQ07954\n-0.6207211\n0.1703226\n9.863946\n-3.644385\n0.0046065\n0.0440134\nQ07954\n\n\nQ9NQZ5\n1.1063978\n0.3078097\n10.264418\n3.594421\n0.0046943\n0.0446157\nQ9NQZ5\n\n\nQ16654\n0.8623740\n0.2320437\n9.094702\n3.716429\n0.0047103\n0.0446157\nQ16654\n\n\nQ2TAA5\n-0.6977539\n0.1932119\n10.009057\n-3.611340\n0.0047506\n0.0448030\nQ2TAA5\n\n\nQ5JVS0\n-1.3591318\n0.2824461\n5.020511\n-4.812004\n0.0047804\n0.0448910\nQ5JVS0\n\n\nQ0VAK6\n0.9271117\n0.2605769\n10.498467\n3.557919\n0.0048217\n0.0450849\nQ0VAK6\n\n\nP07686\n0.8405364\n0.2229746\n8.526947\n3.769651\n0.0048703\n0.0450865\nP07686\n\n\nQ13636\n-1.5458451\n0.3698208\n6.499442\n-4.179984\n0.0048744\n0.0450865\nQ13636\n\n\nP15374\n0.7806300\n0.2186997\n10.281794\n3.569416\n0.0048837\n0.0450865\nP15374\n\n\nP78406\n-1.1054909\n0.2599367\n6.222935\n-4.252923\n0.0049379\n0.0452520\nP78406\n\n\nP20774\n-1.0939518\n0.3086286\n10.484917\n-3.544558\n0.0049430\n0.0452520\nP20774\n\n\nQ08945\n-0.8371286\n0.2282277\n9.153856\n-3.667954\n0.0050247\n0.0458089\nQ08945\n\n\nQ99766\n0.5801784\n0.1601546\n9.531547\n3.622615\n0.0050489\n0.0458380\nQ99766\n\n\nP49207\n-0.5839141\n0.1637478\n10.075594\n-3.565936\n0.0050702\n0.0458413\nP49207\n\n\nP22695\n0.6160228\n0.1729941\n10.018999\n3.560947\n0.0051578\n0.0464413\nP22695\n\n\nQ9UI09\n0.6403409\n0.1794697\n9.918617\n3.567961\n0.0051791\n0.0464419\nQ9UI09\n\n\nP07357\n-0.6143868\n0.1718693\n9.780942\n-3.574733\n0.0052357\n0.0467581\nP07357\n\n\nQ16082\n-0.6322050\n0.1787586\n10.109135\n-3.536641\n0.0052977\n0.0469738\nQ16082\n\n\nQ8IXM3\n0.6461790\n0.1818011\n9.886801\n3.554318\n0.0053241\n0.0469738\nQ8IXM3\n\n\nQ92901\n0.7836579\n0.2227719\n10.288945\n3.517759\n0.0053243\n0.0469738\nQ92901\n\n\nQ13825\n1.1245424\n0.3221135\n10.534211\n3.491137\n0.0053793\n0.0472691\nQ13825\n\n\nQ9NQT8\n-1.1513781\n0.2915578\n7.066202\n-3.949056\n0.0054352\n0.0472891\nQ9NQT8\n\n\nP01604\n-1.2896968\n0.2795691\n5.116835\n-4.613159\n0.0054481\n0.0472891\nP01604\n\n\nQ6ZVF9\n-1.0955862\n0.2709835\n6.656492\n-4.042999\n0.0054588\n0.0472891\nQ6ZVF9\n\n\nP01699\n-1.6297466\n0.3943727\n6.325570\n-4.132503\n0.0054681\n0.0472891\nP01699\n\n\nQ16795\n0.6450332\n0.1840663\n10.157955\n3.504353\n0.0055524\n0.0478297\nQ16795\n\n\nQ9UI47\n0.5900888\n0.1676449\n9.800459\n3.519874\n0.0057127\n0.0490175\nQ9UI47\n\n\nO75947\n0.6002336\n0.1718265\n10.023771\n3.493253\n0.0057709\n0.0492302\nO75947\n\n\nP62760\n-0.9670022\n0.2804990\n10.519281\n-3.447436\n0.0058116\n0.0492302\nP62760\n\n\nQ04446\n0.8608184\n0.2481309\n10.234155\n3.469211\n0.0058272\n0.0492302\nQ04446\n\n\nQ9BSD7\n1.4315921\n0.3832730\n7.936523\n3.735176\n0.0058275\n0.0492302\nQ9BSD7\n\n\nQ9HC36\n0.9665091\n0.2423551\n6.638088\n3.987987\n0.0058727\n0.0494208\nQ9HC36\n\n\nP11182\n0.5859546\n0.1675892\n9.821787\n3.496374\n0.0059193\n0.0495347\nP11182\n\n\nO15118\n-1.3330724\n0.3463625\n7.225517\n-3.848778\n0.0059315\n0.0495347\nO15118\n\n\nQ9UHP9\n0.7222478\n0.2074836\n9.910771\n3.480988\n0.0059908\n0.0497354\nQ9UHP9\n\n\nQ96JM3\n-0.9006783\n0.2426905\n7.958417\n-3.711222\n0.0060010\n0.0497354\nQ96JM3\n\n\n\n\n\n\n\n\n6.7.8 Interaction\nLet us retrieve the result table from the rowData. The second column contains the results for the interaction contrast.\n\ninferenceInt &lt;- rowData(pe[[\"proteins\"]])[[colnames(L)[4]]]\ninferenceInt$Protein &lt;- rownames(inferenceInt)\nhead(inferenceInt)\n\n             logFC           se        df          t      pval adjPval Protein\nA0PJW6  0.00000000 7.792300e-10 14.003000  0.0000000 1.0000000       1  A0PJW6\nA0PJZ3          NA           NA        NA         NA        NA      NA  A0PJZ3\nA0PK00          NA           NA  5.826529         NA        NA      NA  A0PK00\nA1A4S6  0.01527264 1.258090e-01 13.324734  0.1213955 0.9051894       1  A1A4S6\nA1A5D9          NA           NA        NA         NA        NA      NA  A1A5D9\nA1IGU5 -0.28917988 2.871906e-01 10.934858 -1.0069267 0.3357322       1  A1IGU5\n\n\n\nVolcano plot\nVolcano plots are straightforward to generate from the inference table above. We also use ggrepel to annotate the 20 most significant proteins.\n\nggplot(inferenceInt) +\n  aes(x = logFC, y = -log10(pval), color = adjPval &lt; 0.05) +\n  geom_point() +\n  geom_text_repel(data = slice_min(inferenceInt, adjPval, n = 20),\n                  aes(label = Protein)) +\n  scale_color_manual(values = alpha(c(\"black\", \"red\"), 0.5)) + \n  ggtitle(\"log2 FC V-A Right\",\n          paste(\"Hypothesis test:\", colnames(L)[2], \"= 0\"))\n\n\n\n\n\n\n\n\nAs there are no significant features, we do not return a top table and do not make a heatmap for this contrast.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Heart use case: a MaxQuant LFQ DDA dataset with a more complex design</span>"
    ]
  },
  {
    "objectID": "06-heart.html#conclusion",
    "href": "06-heart.html#conclusion",
    "title": "6  Heart use case: a MaxQuant LFQ DDA dataset with a more complex design",
    "section": "6.8 Conclusion",
    "text": "6.8 Conclusion\nIn this chapter, we illustrated the analysis of a label-free proteomics data set with technical replication. We followed the workflow described in the previous chapters with minimal changes.\nThe experiment presented in this chapter presents a complex design and is an excellent illustration on how to model data with main effects, interactions and block effects. We could investigate:\n\nThe difference in protein abundance between the atrium and ventriculum in the left heart compartment.\nThe difference in protein abundance between the atrium and ventriculum in the right heart compartment.\nThe difference in protein abundance between the atrium and ventriculum, averaged over the right and left heart compartment.\nThe interaction, whether the difference between atrium and ventriculum is affected by whether we focus on the left heart or the right heart compartment.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Heart use case: a MaxQuant LFQ DDA dataset with a more complex design</span>"
    ]
  },
  {
    "objectID": "06-heart.html#footnotes",
    "href": "06-heart.html#footnotes",
    "title": "6  Heart use case: a MaxQuant LFQ DDA dataset with a more complex design",
    "section": "",
    "text": "Note that we use the same heatmap annotations so we don’t need to generate it again.↩︎",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Heart use case: a MaxQuant LFQ DDA dataset with a more complex design</span>"
    ]
  },
  {
    "objectID": "07-mouse_diet.html",
    "href": "07-mouse_diet.html",
    "title": "7  The mouse diet use case: a Skyline TMT DDA dataset",
    "section": "",
    "text": "7.1 Introduction\nIf you never used msqrob2, we suggest to familiarise yourself with the basic concepts chapter first. Note that TMT experiments imposes complex designs, hence we also suggest reading the advanced concepts chapter.\nWe will demonstrate the msqrob2TMT workflow, a data processing and modelling workflow dedicated to the analysis of TMT-based proteomics datasets. We will demonstrated the workflow using the study published by Plubell et al. (2017), illustrating the statistical concepts using a real-life use case.\nSince this chapter uses a real-life study, we cannot objectively assess the results. The advanced concepts chapter demonstrates an msqrob2TMT analysis with ground truth information.\nBefore delving further into the use case, let us prepare our computational environment.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The mouse diet use case: a Skyline TMT DDA dataset</span>"
    ]
  },
  {
    "objectID": "07-mouse_diet.html#load-packages",
    "href": "07-mouse_diet.html#load-packages",
    "title": "7  The mouse diet use case: a Skyline TMT DDA dataset",
    "section": "7.2 Load packages",
    "text": "7.2 Load packages\nFirst, we load the msqrob2 package and additional packages for data manipulation and visualisation.\n\nlibrary(\"msqrob2\")\nlibrary(\"ggplot2\")\nlibrary(\"patchwork\")\nlibrary(\"ggrepel\")\nlibrary(\"dplyr\")\n\nWe also configure the parallelisation framework.\n\nlibrary(\"BiocParallel\")\nregister(SerialParam())",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The mouse diet use case: a Skyline TMT DDA dataset</span>"
    ]
  },
  {
    "objectID": "07-mouse_diet.html#load-data",
    "href": "07-mouse_diet.html#load-data",
    "title": "7  The mouse diet use case: a Skyline TMT DDA dataset",
    "section": "7.3 Load data",
    "text": "7.3 Load data\n\n7.3.1 Experimental context\nThe data used in this vignette has been published by Plubell et al. (2017) (PXD005953). The objective of the experiment was to explore the impact of low-fat and high-fat diets on the proteomic content of adipose tissue in mice. It also assesses whether the duration of the diet may impact the results. The authors assigned twenty mice into four groups (5 mice per group) based on their diet, either low-fat (LF) or high-fat (HF), and the duration of the diet, which was classified as short (8 weeks) or long (18 weeks). Samples from the epididymal adipose tissue were extracted from each mice. The samples were then randomly distributed across three TMT 10-plex mixtures for analysis. In each mixture, two reference labels were used, each containing pooled samples that included a range of peptides from all the samples. Not all labels were used, leading to an unbalanced design. Each TMT 10-plex mixture was fractionated into nine parts, resulting in a total of 27 MS runs.\n\n\n\n\n\nOverview of the experimental design. Taken from Plubell et al. 2017.\n\n\n\n\n\n\n7.3.2 Getting the data\nThe data were reanalyzed by Huang et al. (2020) and have been deposited in the MSV000084264 MASSiVE repository, but we will retrieve the timestamped data from our Zenodo repository. We need 2 files: the Skyline identification and quantification table generated by the authors and the sample annotation files1.\n\nlibrary(\"BiocFileCache\")\nbfc &lt;- BiocFileCache()\npsmFile &lt;- bfcrpath(bfc, \"https://zenodo.org/records/14767905/files/mouse_psms.txt?download=1\")\nannotFile &lt;- bfcrpath(bfc, \"https://zenodo.org/records/14767905/files/mouse_annotations.csv?download=1\")\n\nThis analysis starts with the PSM table. Note that columns that start with \"Abundance.\" contain the quantitative values for each TMT label.\n\npsms &lt;- read.delim(psmFile)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChecked\nConfidence\nIdentifying.Node\nPSM.Ambiguity\nAnnotated.Sequence\nModifications\nX..Protein.Groups\nX..Proteins\nMaster.Protein.Accessions\nMaster.Protein.Descriptions\nProtein.Accessions\nProtein.Descriptions\nX..Missed.Cleavages\nCharge\nDeltaScore\nDeltaCn\nRank\nSearch.Engine.Rank\nm.z..Da.\nMH…Da.\nTheo..MH…Da.\nDeltaM..ppm.\nDeltam.z..Da.\nActivation.Type\nMS.Order\nIsolation.Interference….\nAverage.Reporter.S.N\nIon.Inject.Time..ms.\nRT..min.\nFirst.Scan\nSpectrum.File\nFile.ID\nAbundance..126\nAbundance..127N\nAbundance..127C\nAbundance..128N\nAbundance..128C\nAbundance..129N\nAbundance..129C\nAbundance..130N\nAbundance..130C\nAbundance..131\nQuan.Info\nIons.Score\nIdentity.Strict\nIdentity.Relaxed\nExpectation.Value\nPercolator.q.Value\nPercolator.PEP\n\n\n\n\nFalse\nHigh\nMascot (A2)\nUnambiguous\n[K].aIDILDR.[SM]\nN-Term(TMT6plex)\n1\n1\n\n\nQ61084\nMitogen-activated protein kinase kinase kinase 3 OS=Mus musculus GN=Map3k3 PE=1 SV=1\n0\n2\n0\n0\n1\n1\n522.8161\n1044.625\n1044.625\n-0.14\n-0.00008\nCID\nMS2\n2.279464\n10.5\n42.390\n63.4111\n16103\nPAMI-194_Mouse_U-Dd_TMT_40ug_28pctACN_25cm_120min_20160426_OT.raw\nF3.6\n2382.454\n2429.068\n2707.243\n3317.650\n5035.093\n3031.7993\n4808.5522\n2583.115\n3103.613\n2795.283\nNA\n40\n25\n18\n0.0003802\n0.0008956\n0.0111900\n\n\nFalse\nHigh\nMascot (C2)\nUnambiguous\n[K].aLEENNNFSk.[M]\nN-Term(TMT6plex); K10(TMT6plex)\n1\n1\n\n\nP55821\nStathmin-2 OS=Mus musculus GN=Stmn2 PE=1 SV=1\n0\n2\nNA\n0\n1\n2\n812.4410\n1623.875\n1623.874\n0.26\n0.00021\nCID\nMS2\n20.489330\n0.8\n116.000\n38.9028\n7622\nPAMI-176_Mouse_A-J_TMT_40ug_22pctACN_25cm_120min_20160223_OT.raw\nF1.3\n1112.530\nNA\nNA\nNA\nNA\n389.5883\n963.0698\nNA\nNA\nNA\nNA\n49\n29\n22\n0.0000932\n0.0000000\n0.0000510\n\n\nFalse\nHigh\nMascot (C2)\nRejected\n[K].eMISDIk.[F]\nN-Term(TMT6plex); K7(TMT6plex)\n0\n1\n\n\nQ5SQM0\nEchinoderm microtubule-associated protein-like 6 OS=Mus musculus GN=Eml6 PE=2 SV=1\n0\n2\n0\n0\n1\n1\n647.3786\n1293.750\n1293.749\n0.84\n0.00054\nCID\nMS2\n62.114720\n25.4\n50.658\n45.5494\n10094\nPAMI-176_Mouse_A-J_TMT_40ug_24pctACN_25cm_120min_20160223_OT.raw\nF1.4\n8606.559\n10042.301\n7976.240\n5196.599\n9381.061\n12227.7070\n6418.2720\n5791.740\n9665.493\n5747.680\nNA\n11\n28\n21\n0.5635688\n0.0016120\n0.0284500\n\n\nFalse\nHigh\nMascot (C2)\nUnambiguous\n[KR].iIDFGLAR.[HQRT]\nN-Term(TMT6plex)\n4\n3\n\n\nQ3UIZ8; Q5SUV5; Q8VCR8\nMyosin light chain kinase 3 OS=Mus musculus GN=Mylk3 PE=1 SV=1; Myosin light chain kinase family member 4 OS=Mus musculus GN=Mylk4 PE=1 SV=2; Myosin light chain kinase 2, skeletal/cardiac muscle OS=Mus musculus GN=Mylk2 PE=1 SV=2\n0\n2\n0\n0\n1\n1\n567.3476\n1133.688\n1133.688\n-0.09\n-0.00005\nCID\nMS2\n30.288610\n13.5\n41.830\n70.4334\n19108\nPAMI-176_Mouse_A-J_TMT_40ug_30pctACN_25cm_120min_20160223_OT.raw\nF1.7\n4964.429\n5950.643\n3133.549\n3321.042\n2914.397\n3274.3197\n3284.3334\n4714.300\n3846.105\n5461.438\nNA\n41\n24\n17\n0.0002663\n0.0000983\n0.0004159\n\n\nFalse\nHigh\nMascot (B2)\nUnambiguous\n[KR].iQLWDTAGQER.[FY]\nN-Term(TMT6plex)\n7\n1\n\n\nO35963\nRas-related protein Rab-33B OS=Mus musculus GN=Rab33b PE=1 SV=1\n0\n3\nNA\n0\n1\n2\n515.9459\n1545.823\n1545.822\n0.49\n0.00025\nCID\nMS2\n14.174430\n5.2\n116.000\n63.1792\n15687\nPAMI-176_Mouse_K-T_TMT_40ug_26pctACN_25cm_120min_20160223_OT.raw\nF2.5\n2202.812\n1313.995\n1942.837\n2381.060\n1443.969\n1701.8316\n968.0946\n1867.904\n910.823\n1371.243\nNA\n28\n28\n21\n0.0092083\n0.0000000\n0.0000261\n\n\nFalse\nHigh\nMascot (A2)\nUnambiguous\n[K].aIDILDR.[SM]\nN-Term(TMT6plex)\n1\n1\n\n\nQ61084\nMitogen-activated protein kinase kinase kinase 3 OS=Mus musculus GN=Map3k3 PE=1 SV=1\n0\n2\n0\n0\n1\n1\n522.8161\n1044.625\n1044.625\n-0.14\n-0.00008\nCID\nMS2\n21.614820\n19.0\n116.000\n62.4027\n15935\nPAMI-194_Mouse_U-Dd_TMT_40ug_26pctACN_25cm_120min_20160426_OT.raw\nF3.5\n6064.501\n3790.208\n4328.930\n6528.889\n6080.098\n7705.8087\n7836.0572\n4606.420\n5347.845\n5869.469\nNA\n42\n25\n18\n0.0002350\n0.0005618\n0.0067230\n\n\n\n\n\nWe also load the annotation table. Each row in the annotation table contains information for one sample (the table below shows the first 6 rows).\n\ncoldata &lt;- read.csv(annotFile)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChannel\nCondition\nRun\nBioReplicate\nMixture\nFraction\nTechRepMixture\n\n\n\n\n126\nLong_LF\nPAMI-176_Mouse_A-J_TMT_40ug_30pctACN_25cm_120min_20160223_OT.raw\nPAMI-176_Mouse_A-J.X126\nPAMI-176_Mouse_A-J\n40ug_30pctACN_25cm_120min_20160223\n1\n\n\n126\nLong_LF\nPAMI-176_Mouse_A-J_TMT_40ug_28pctACN_25cm_120min_20160223_OT.raw\nPAMI-176_Mouse_A-J.X126\nPAMI-176_Mouse_A-J\n40ug_28pctACN_25cm_120min_20160223\n1\n\n\n126\nLong_LF\nPAMI-176_Mouse_A-J_TMT_40ug_90pctACN_25cm_120min_20160223_OT.raw\nPAMI-176_Mouse_A-J.X126\nPAMI-176_Mouse_A-J\n40ug_90pctACN_25cm_120min_20160223\n1\n\n\n126\nLong_LF\nPAMI-176_Mouse_A-J_TMT_40ug_40pctACN_25cm_120min_20160223_OT.raw\nPAMI-176_Mouse_A-J.X126\nPAMI-176_Mouse_A-J\n40ug_40pctACN_25cm_120min_20160223\n1\n\n\n126\nLong_LF\nPAMI-176_Mouse_A-J_TMT_40ug_22pctACN_25cm_120min_20160223_OT.raw\nPAMI-176_Mouse_A-J.X126\nPAMI-176_Mouse_A-J\n40ug_22pctACN_25cm_120min_20160223\n1\n\n\n126\nLong_LF\nPAMI-176_Mouse_A-J_TMT_40ug_24pctACN_25cm_120min_20160223_OT.raw\nPAMI-176_Mouse_A-J.X126\nPAMI-176_Mouse_A-J\n40ug_24pctACN_25cm_120min_20160223\n1\n\n\n\n\n\nWe perform a little cleanup of the sample annotations to generate the information needed for later data modelling, namely\n\nWe extract the diet type from the condition variable.\nWe extract the diet duration from the condition variable.\nWe rename the Channel column to Label for more clarity with the main text.\n\n\ncoldata$Duration &lt;- gsub(\"_.*\", \"\", coldata$Condition) ## 1.\ncoldata$Diet &lt;- gsub(\".*_\", \"\", coldata$Condition) ## 2.\ncolnames(coldata)[1] &lt;- \"Label\" ## 3.\n\nWe will also subset the data set to reduce computational costs. If you want to run the vignette on the full data set, you can skip this chunk. We here randomly sample 500 proteins from the experiment.\n\nproteinIds &lt;- unique(psms$Protein.Accessions)\nset.seed(1234)\npsms &lt;- psms[psms$Protein.Accessions %in% sample(proteinIds, 500), ]\n\n\n\n7.3.3 The QFeatures data class\nWe combine the two tables into a QFeatures object. We need to point to the column containing the run information. For the annotation table, this is simply the Run column. For the Skyline table, this is the Spectrum.File column. We also add a quantCols column in the annotation table. We also simply the run names upon conversion for conciseness.\n\ncoldata$runCol &lt;- coldata$Run\ncoldata$quantCols &lt;- paste0(\"Abundance..\", coldata$Label)\nmouse &lt;- readQFeatures(psms, colData = coldata,\n                       quantCols = unique(coldata$quantCols),\n                       runCol = \"Spectrum.File\", name = \"psms\")\nnames(mouse) &lt;- sub(\"^.*(Mouse.*ACN).*raw\", \"\\\\1\", names(mouse))\nmouse\n\nAn instance of class QFeatures (type: bulk) with 27 sets:\n\n [1] Mouse_A-J_TMT_40ug_14pctACN: SummarizedExperiment with 198 rows and 10 columns \n [2] Mouse_A-J_TMT_40ug_20pctACN: SummarizedExperiment with 481 rows and 10 columns \n [3] Mouse_A-J_TMT_40ug_22pctACN: SummarizedExperiment with 514 rows and 10 columns \n ...\n [25] Mouse_U-Dd_TMT_40ug_30pctACN: SummarizedExperiment with 726 rows and 10 columns \n [26] Mouse_U-Dd_TMT_40ug_40pctACN: SummarizedExperiment with 566 rows and 10 columns \n [27] Mouse_U-Dd_TMT_40ug_90pctACN: SummarizedExperiment with 251 rows and 10 columns \n\n\nWe now have a QFeatures object with 27 sets, each containing data associated with an MS run.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The mouse diet use case: a Skyline TMT DDA dataset</span>"
    ]
  },
  {
    "objectID": "07-mouse_diet.html#data-preprocessing",
    "href": "07-mouse_diet.html#data-preprocessing",
    "title": "7  The mouse diet use case: a Skyline TMT DDA dataset",
    "section": "7.4 Data preprocessing",
    "text": "7.4 Data preprocessing\nmsqrob2 relies on the QFeatures data structure, meaning that we can directly make use of QFeatures’ data preprocessing functionality (see also the QFeatures documentation).\n\n7.4.1 Encoding missing values\nPeptides with zero intensities are missing peptides and should be represent with a NA value rather than 0 (see Encoding missing values).\n\nmouse &lt;- zeroIsNA(mouse, names(mouse))\n\n\n\n7.4.2 Sample filtering\nWe remove the reference samples that were used by the MSstatsTMT authors to obtain normalisation factors since msqrob2TMT workflows do not require normalisation from reference label. The information about which samples are normalisation samples is available from the colData, in the Condition column.\n\ntable(mouse$Condition)\n\n\n Long_HF  Long_LF   Long_M     Norm Short_HF Short_LF \n      45       45       36       54       45       45 \n\n\nWe remove any sample that is marked as Norm. We also remove sample that are annotated as Long_M since we could not find documentation for this group.\n\nmouse &lt;- subsetByColData(\n    mouse, mouse$Condition != \"Norm\" & mouse$Condition != \"Long_M\"\n)\n\n\n\n7.4.3 PSM filtering\nWe filter features for which more than 70% of the intensities are missing in a run. We keep the spectrum as soon as the reporter ions are observed in at least 3 out of 10 TMT labels of the run (same cut-off as applied in Huang et al. (2020)).\n\nmouse &lt;- filterNA(mouse, names(mouse), pNA = 0.7) ## 2.\n\nWe next remove PSMs that could not be mapped to a protein or that map to multiple proteins (the protein identifier contains multiple identifiers separated by a ;). We use filterFeatures() that will keep the row that fulfill the condition below. Note that Protein.Accessions is a column generated by Skyline that is available in the rowData.\n\nmouse &lt;- filterFeatures(\n    mouse, ~ Protein.Accessions != \"\" & ## Remove failed protein inference\n        !grepl(\";\", Protein.Accessions)) ## Remove protein groups\n\nPeptide ions that were identified with multiple PSMs in a run are collapsed to the PSM with the highest summed intensity over the labels, a strategy that is also used by MSstats. We will again use filterFeatures(), but the highest summed intensity for each PSM is not available in the rowData, so we need to create it manually.\nWe therefore loop over each set:\n\nMake a new variable for ionID in the rowData, which is defined as the peptide sequence and its charge.\nWe calculate the rowSums for each ion.\nMake a new variable psmRank that ranks the PSMs for each ion based on the summed intensity.\nWe store the new information back in the rowData.\nWe keep the PSM with the highest summed intensity, that is that ranks first (note that PSM unique to an ion will always rank first).\n\n\nfor (i in names(mouse)) {\n    rowdata &lt;- rowData(mouse[[i]])\n    rowdata$ionID &lt;- paste0(rowdata$Annotated.Sequence, rowdata$Charge) ## 1.\n    rowdata$rowSums &lt;- rowSums(assay(mouse[[i]]), na.rm = TRUE) ## 2.\n    rowdata &lt;- data.frame(rowdata) |&gt;\n        group_by(ionID) |&gt;\n        mutate(psmRank = rank(-rowSums)) ## 3.\n    rowData(mouse[[i]]) &lt;- DataFrame(rowdata) ## 4.\n}\nmouse &lt;- filterFeatures(mouse, ~ psmRank == 1) ## 5.\n\nSo, we implicitly collapsed the PSM-level data into peptide-ion data, where each row represents a PSM, but also a unique ion within a run. So we will refer to the data as “ion-level”.\n\n\n7.4.4 Standard preprocessing workflow\nWe can now prepare the data for modelling. The workflow ensures the data complies to msqrob2’s requirements:\n\nIntensities are log-transformed.\nSamples are normalised.\n(optionally) PSMs intensities are summarised into protein abundance values for protein-level workflows.\n\n\nsNames &lt;- names(mouse)\nmouse &lt;- logTransform( ## 1.\n    mouse, sNames, name = paste0(sNames, \"_log\"), base = 2\n)\nmouse &lt;- normalize( ## 2.\n    mouse, paste0(sNames, \"_log\"), name = paste0(sNames, \"_norm\"),\n    method = \"center.median\"\n)\nmouse &lt;- aggregateFeatures( ## 3.\n    mouse, i = paste0(sNames, \"_norm\"), name = paste0(sNames, \"_proteins\"),\n    fcol = \"Protein.Accessions\", fun = MsCoreUtils::medianPolish,\n    na.rm=TRUE\n)\n\nWe conclude the preprocessing by joining the assays of the different runs in a single ion set for ion-level models. In order to correctly match peptide ions across rus, we use ionID as a row identifier.\n\nmouse &lt;- joinAssays(mouse, paste0(sNames, \"_norm\"), fcol = \"ionID\", \"ions_norm\")\n\nWe also join the protein sets for protein-level models. We omit fcol and will merge rows based on their row name (protein identifier).\n\nmouse &lt;- joinAssays(mouse, paste0(sNames, \"_proteins\"), \"proteins\")",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The mouse diet use case: a Skyline TMT DDA dataset</span>"
    ]
  },
  {
    "objectID": "07-mouse_diet.html#data-exploration",
    "href": "07-mouse_diet.html#data-exploration",
    "title": "7  The mouse diet use case: a Skyline TMT DDA dataset",
    "section": "7.5 Data exploration",
    "text": "7.5 Data exploration\nAs described above, the samples originate from mice that were either subject to a low-fat (LF) or high-fat (HF) diet. Moreover, each diet was maintained for a short duration (Short) or a long duration (Long). Note that each group contains 5 mice but the peptides from each sample have been fractionated in 9 fractions, leading to 45 units per group.\nIn this case, we are interested in the effects of diet type and the effect of diet duration. The table below confirms we have a balanced design for each condition.\n\ntable(Diet = mouse$Diet, Duration = mouse$Duration)\n\n    Duration\nDiet Long Short\n  HF   45    45\n  LF   45    45\n\n\nFurthermore, there are potential unwanted sources of variation: the experimental unit (i.e. the mouse, BioReplicate), the fraction (Fraction), the run (Run), the TMT mixture (Mixture).\nWe will explore the main sources of variation in the data (see Data exploration). Unfortunately, the peptide ion data contains too many missing values and cannot be explored using standard dimension reduction approaches. omicsGMF (Segers et al. 2025) provides an interesting alternative, but is still in its early stage and will not be included here. We will therefore run a MDS analysis on the protein-level data instead, which contains less missing values.\n\nlibrary(\"scater\")\nse &lt;- getWithColData(mouse, \"proteins\") |&gt; \n  as(\"SingleCellExperiment\") |&gt; \n  runMDS(exprs_values = 1)\n\nWe can now plot the MDS and colour each sample based on different potential sources of variation.\n\nplotMDS(se, colour_by = \"Run\") + ggtitle(\"Coloured by Run\") +\n  scale_colour_manual(values = rainbow(27)) +\n  plotMDS(se, colour_by = \"Fraction\") + ggtitle(\"Coloured by Fraction\") +\n  plotMDS(se, colour_by = \"BioReplicate\") + ggtitle(\"Coloured by BioReplicate\") +\n  plotMDS(se, colour_by = \"Mixture\") + ggtitle(\"Coloured by Mixture\") +\n  plotMDS(se, colour_by = \"Diet\") + ggtitle(\"Coloured by Diet\") +\n  plotMDS(se, colour_by = \"Duration\") + ggtitle(\"Coloured by Duration\") &\n  theme(legend.position = \"none\") \n\n\n\n\n\n\n\n\nThe data exploration leads to several observations:\n\nThe strongest source of variation is associated with the MS acquisition run.\nPart of this run effect is influenced by which fraction it contains since samples from the same fraction tend to be closer than samples from different fractions. (TODO DISCUSS)\nIt is difficult to identify an effect of mouse (biological replicate) because every run contains distinct mice. However, this does not exclude an effect of mice which has been identified as a potential source of variation and hence should still be modelled. (TODO DISCUSS)\nThere is potentially also an effect of TMT mixture since samples from the same mixtures tend to cluster together (in the center of the plot). However, this effect are more subtle to detect and difficult to disentangle from the run and fraction effects.\nAlthough again very subtle, we can see within each run that samples from the mice with the same diet tends to group together. However, these effects are overwhelmed by the run effects. An effect of duration is to subtle to pinpoint from the current data exploration.\n\nData modelling disentangles the different sources of variation, given their are properly defined in the model, hence the next section.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The mouse diet use case: a Skyline TMT DDA dataset</span>"
    ]
  },
  {
    "objectID": "07-mouse_diet.html#data-modelling",
    "href": "07-mouse_diet.html#data-modelling",
    "title": "7  The mouse diet use case: a Skyline TMT DDA dataset",
    "section": "7.6 Data modelling",
    "text": "7.6 Data modelling\nThe preprocessed data can now be modelled to answer biologically relevant questions.\n\n7.6.1 Sources of variation\nProteomics data contain several sources of variation that need to be accounted for by the model:\n\nTreatment of interest: we model the source of variation induced by the experimental treatment of interest as a fixed effect. Fixed effects are effect that are considered non-random, i.e. the treatment effect is assumed to be the same and reproducible across repeated experiments, but it is unknown and has to be estimated. We will include Diet as a fixed effect that models the fact that a change in diet type can induce changes in protein abundance. Similarly, we also include Duration as a fixed effect to model the change in protein abundance induces by the diet duration. Finally, we will also include an interaction between the two variables allowing that the changes in protein abundance induced by diet type can be different whether the mice were fed for a short or long duration.\nPseudo-replication: the experiment involves biological replication as the adipose tissue extracts were sampled from 20 mice (5 mice per Diet x Duration combination). The tissue from each mouse was prepared in a single TMT mixture, but each mixture was acquired in 9 fractions, so we have 9 measures for each mice. While the treatment is applied at the mice level (experimental unit), we actually measure 9 fractions as an outcome (observational unit). We refer to pseudo-replication when the observational unit is different from the experimental unit. We therefore need to account for the potential correlation among pseudo-replicates from the same mouse compared to between different mice. These effects are typically modelled as random effects, and are assumed to be i.i.d normally distributed with mean 0 and constant variance, \\(u_{mouse} \\sim\nN(0,\\sigma^{2,\\text{mouse}})\\). This random effect models the correlation of the log2-intensities of pseudo replicates, explicitly.\n\n\nlength(unique(mouse$BioReplicate))\n\n[1] 20\n\n\n\nLabelling effects: the 20 mouse adipose tissue samples have been labelled using 18-plex TMT. We can expect that samples measured within the same TMT label may be more similar than samples measured within different TMT labels. Since these effects may not be reproducible from one experiment to another, for instance because each TMT kit may potentially contain different impurity ratios, we can account for this source of variation using a random effect for TMT label.\n\n\nlength(unique(mouse$Label))\n\n[1] 10\n\n\n\nMixture effects: the 20 mouse samples were assigned to one out of 3 mixtures. Again, we expect that protein intensities from the same mixture will be more alike than those of different mixtures. Hence, we will add a random effect for mixture.\n\n\ntable(mouse$Mixture)\n\n\n PAMI-176_Mouse_A-J  PAMI-176_Mouse_K-T PAMI-194_Mouse_U-Dd \n                 54                  63                  63 \n\n\n\nRun effects: log2-intensities that are measured within the same run will be more similar than log2-intensities between runs. We will use a random effect for run to explicitly model this correlation in the data. Note that each sample has been acquired in 9 fractions, each fraction being measured in a separate run. Accounting for the effects of run will also absorb the effects of fraction.\n\n\nlength(unique(mouse$Run))\n\n[1] 27\n\n\n\nSpectrum effects: we will directly estimate the treatment effect at the protein-level from ion-level data. This will again induce additional levels of correlation. The intensities for the different TMT labels in the same spectrum (PSM) within a run will be more similar than the intensities between spectra. We therefore need to add a random effect term to account for the within spectrum correlation structure. Note that a spectrum here contains the data from one peptide ion within a run. Hence, modelling a random effect for spectrum boils down to modelling a random effect for peptide ion nested within run.\nLabelling effects nested in run: modelling the data at the ion-level also implies that a label in a run contains multiple ion intensities for each protein. Hence, intensities from different peptide ions for a protein with the same label within a run will be more alike than intensities of different PSMs for the same protein with different labels and/or runs, and we will address this correlation with a random effect for label nested in run.\n\nmsqrob2 workflows rely on linear mixed models, which are models that can estimate and predict fixed and random effects, respectively.\nNow we have identified the sources of variation, we can define a model. We will model the main effects for Diet and Duration, and a Diet:Duration interaction, to account for proteins for which the Diet effect changes according to Duration, and vice versa, which can be written as Diet + Duration + Diet:Duration, shortened into Diet * Duration. Adding the technical sources of variation, the model becomes.\n\nmodel &lt;- ~ Diet * Duration + ## (1) fixed effect for Diet and Duration with interaction\n  (1 | BioReplicate) +  ## (2) random effect for biological replicate (mouse)      \n  (1 | Label) + ## (3) random effect for label\n  (1 | Mixture) + ## (4) random effect for mixture\n  (1 | Run) + ## (5) random effect for MS run\n  (1 | Run:ionID) + ## (6) random effect for spectrum, i.e. ionID nested in run\n  (1 | Run:Label)  ## (7) random effect for label nested in MS run\n\nWe can run the msqrob2 statistical workflow.\n\n\n7.6.2 Model estimation\nWe estimate the peptide-ion-level model with msqrobAggregate() (see the modelling section). Recall that variables defined in model are automatically retrieved from the colData (\"Diet\", \"Duration\", \"Label\", \"Mixture\") and from the rowData (\"ionID\"). We also enable M-estimation (robust = TRUE) for improved robustness against outliers and ridge penalisation (ridge = TRUE) to stabilise the parameter estimation.\n\nmouse &lt;- msqrobAggregate(\n    mouse, i = \"ions_norm\",\n    formula = model,\n    fcol = \"Protein.Accessions\",\n    modelColumnName = \"msqrob_ion\",\n    name = \"proteins_msqrob\",\n    ridge = TRUE, robust = TRUE\n)\n\nOnce the model is estimated, we can start answering biological questions.\n\n\n7.6.3 Hypothesis testing\nIn this section, you will learn how to convert a biological question into a statistical hypothesis.\n\nDifference between low fat and high fat diet after short duration\nA first question one can ask is: how are protein abundance affected by diet when only considering a short diet duration? We need to convert this question in a combination of the model parameters, also referred to as a contrast. To aid defining contrasts, we will visualise the experimental design using the ExploreModelMatrix package. Note that with ExploreModelMatrix we can only visualise fixed effects part of the model. This is fine as the mean protein abundances can only systematically differ from each other according to the main effects for Diet and Duration and the Diet:Duration interaction.\n\nlibrary(\"ExploreModelMatrix\")\nvd &lt;- VisualizeDesign(\n    sampleData =  colData(mouse),\n    designFormula = ~ Diet * Duration,\n    textSizeFitted = 4\n)\nvd$plotlist[[1]]\n\n\n\n\n\n\n\n\nAssessing the difference between low-fat and high-fat diets for short duration boils down to assessing the difference between the Short_LF and Short_HF. The mean for the short low-fat diet group is defined by (Intercept) + DietLF + DurationShort + DietLF:DurationShort. The mean for the short high-fat diet group is defined by (Intercept) + DurationShort. The difference between the two results in the contrast below:\n\ncontrast &lt;- \"ridgeDietLF + ridgeDietLF:DurationShort\"\n\nNote that because we used ridge regression for modelling, we need to prefix the parameter names with ridge. We can further specify the null hypothesis, that is we are interest whether the differences between the two groups is different from zero.\n\n(hypothesis1 &lt;- paste(contrast, \"= 0\"))\n\n[1] \"ridgeDietLF + ridgeDietLF:DurationShort = 0\"\n\n\nWe next use makeContrast() to build a contrast matrix.\n\n(L &lt;- makeContrast(\n    hypothesis1,\n    parameterNames = c(\"ridgeDietLF\",\"ridgeDurationShort\",\"ridgeDietLF:DurationShort\")\n))\n\n                          ridgeDietLF + ridgeDietLF:DurationShort\nridgeDietLF                                                     1\nridgeDurationShort                                              0\nridgeDietLF:DurationShort                                       1\n\n\nWe can now test our null hypothesis.\n\nmouse &lt;- hypothesisTest(\n    mouse, i = \"proteins_msqrob\", L, modelColumn = \"msqrob_ion\"\n)\n\nLet us retrieve the result table from the rowData. Note that the model column is named after the column names of the contrast matrix L.\n\ninference &lt;- rowData(mouse[[\"proteins_msqrob\"]])[[colnames(L)]]\ninference$Protein &lt;- rownames(inference)\nhead(inference, 10)\n\n               logFC           se       df             t      pval adjPval\nA2AJB7  3.491872e-09 9.284189e-05 67.35093  3.761096e-05 0.9999701       1\nA2AJK6            NA           NA       NA            NA        NA      NA\nA2AQP0            NA           NA       NA            NA        NA      NA\nA2AWP8            NA           NA       NA            NA        NA      NA\nA6H8H2            NA           NA       NA            NA        NA      NA\nB1AVY7            NA           NA       NA            NA        NA      NA\nB2RSH2  2.296647e-09 8.045105e-05 52.17788  2.854713e-05 0.9999773       1\nC0HKD8            NA           NA       NA            NA        NA      NA\nD3Z5L6            NA           NA       NA            NA        NA      NA\nE9Q5C9 -1.798058e-09 6.822108e-05 29.11140 -2.635634e-05 0.9999792       1\n       Protein\nA2AJB7  A2AJB7\nA2AJK6  A2AJK6\nA2AQP0  A2AQP0\nA2AWP8  A2AWP8\nA6H8H2  A6H8H2\nB1AVY7  B1AVY7\nB2RSH2  B2RSH2\nC0HKD8  C0HKD8\nD3Z5L6  D3Z5L6\nE9Q5C9  E9Q5C9\n\n\nThe table contains the hypothesis testing results for every protein. Notice that several rows contain missing values. This is because data modelling resulted in a fitError. The model cannot be estimated for some proteins either because of patterns in missing values, or because a protein was measured from a single peptide ion alleviating the estimation of spectrum effects (see how to deal with fitErrors).\nWe can use the table above directly to build a volcano plot using ggplot2 functionality.\n\nggplot(inference) +\n    aes(x = logFC, y = -log10(pval), color = adjPval &lt; 0.05) +\n    geom_text_repel(data = filter(inference, adjPval &lt; 0.05),\n                    aes(label = Protein)) +\n    geom_point() +\n    ggtitle(\"Statistical inference on differences between LF and HF (short duration)\",\n            paste(\"Hypothesis test:\", gsub(\"ridgeCondition\", \"\", colnames(L)), \"= 0\"))\n\n\n\n\n\n\n\n\nIn this example (remember this is a subset of the complete data set), only a few proteins pass the significance threshold of 5%. Let us visualise the protein with the largest fold change.\n\n(targetProtein &lt;- rownames(inference)[which.max(inference$logFC)])\n\n[1] \"Q5SWU9\"\n\n\nTo obtain the required data, we perform a little data manipulation pipeline:\n\nWe use the QFeatures subsetting functionality to retrieve all data related to Q5SWU9 and focusing on the ions_norm set that contains the preprocessed peptide ion data used for modelling.\nWe use longForm() to convert the object into a table suitable for plotting.\nWe remove missing values for plotting and focus only on the data with short diet duration.\nWe reorder the sample identifiers to improve visualisation.\n\n\nionData &lt;- mouse[targetProtein, , \"ions_norm\"] |&gt; #1\n    longForm(colvars = colnames(colData(mouse)), #2\n               rowvars = c(\"Protein.Accessions\", \"ionID\")) |&gt;\n    data.frame() |&gt;\n    filter(!is.na(value) & Duration == \"Short\") |&gt; #3\n    mutate(colname = factor(colname, levels = unique(colname[order(Condition)]))) #4\n\nWe can now plot the log normalised intensities. Since the protein is modelled at the peptide ion level, multiple ion intensities are recorded in each sample. Each ion is linked across samples using a grey line. Samples are coloured according to the diet type. Finally, we split the plot in facets, one for each mixture, to visualise the heterogeneity induced by different pools of mice.\n\nggplot(ionData) +\n    aes(x = colname,\n        y = value) +\n    geom_line(aes(group = ionID), linewidth = 0.1) +\n    geom_point(aes(colour = Condition)) +\n    facet_grid(~ Mixture, scales = \"free\") +\n    labs(x = \"Sample\", y = \"log2 intensity\") +\n    ggtitle(targetProtein) +\n    theme_minimal() +\n    theme(axis.text.x = element_blank())\n\n\n\n\n\n\n\n\nThe statistical analysis revealed a significant increase (positive log fold change) of the abundance for Q5SWU9 in the group fed with a low-fat diet compared to the high-fat diet fed group (upon early diet duration). This finding can be visually validated as there is a systematic increase in peptide ion intensities between the low-fat diet group (blue) compared to the high-fat diet group (red).\n\n\nDifference between low fat and high fat diet after long duration\nThe second question one can ask is what proteins are affected by diet when only considering, this time, a long diet duration. Following the same approach as above, the contrast becomes.\n\nhypothesis2 &lt;- \"ridgeDietLF = 0\"\n\nWe run the same statistical analysis pipeline as above.\n\nL &lt;- makeContrast(\n    hypothesis2,\n    parameterNames = c(\"ridgeDietLF\",\"ridgeDurationShort\",\"ridgeDietLF:DurationShort\")\n)\nmouse &lt;- hypothesisTest(\n    mouse, i = \"proteins_msqrob\", L, modelColumn = \"msqrob_ion\"\n)\ninference &lt;- rowData(mouse[[\"proteins_msqrob\"]])[[colnames(L)]]\ninference$Protein &lt;- rownames(inference)\n\nAnd we plot the results.\n\nggplot(inference) +\n    aes(x = logFC, y = -log10(pval), color = adjPval &lt; 0.05) +\n    geom_text_repel(data = filter(inference, adjPval &lt; 0.05),\n                    aes(label = Protein)) +\n    geom_point() +\n    ggtitle(\"Statistical inference on differences between LF and HF (long duration)\",\n            paste(\"Hypothesis test:\", gsub(\"ridgeCondition\", \"\", colnames(L)), \"= 0\"))\n\n\n\n\n\n\n\n\nAgain, only a few proteins come out differentially abundant between the two diets, but after a long diet duration. Surprisingly, there is only a small overlap between differential protein after short duration and after long duration. One hypothesis is that there is not sufficient data to detect a reliable difference. A solution would be to combine both short and long diet duration to retrieve an averaged systematic effect between diets that combine all available data. Another hypothesis is that diet duration may influence the effect of diet on the protein abundances. We will explore the two hypothesis in the following two sub-sections.\n\n\nAverage difference between low fat and high fat diet\nOne may want to identify the set of proteins that are systematically differentially abundant between diets, irrespective of the duration. To answer this question, we want to infer on the average difference between group LF and group HF. The average low-fat diet is defined by ((Intercept) + DietLF + DurationShort + DietLF:DurationShort + (Intercept) + DietLF)/2. The average high-fat diet group is defined by ((Intercept) + DurationShort + (Intercept))/2. The difference between the two results in the hypothesis below:\n\nhypothesis3 &lt;- \"ridgeDietLF + (ridgeDietLF:DurationShort)/2 = 0\"\n\nWe next run again the same statistical analysis pipeline as above.\n\nL &lt;- makeContrast(\n    hypothesis3,\n    parameterNames = c(\"ridgeDietLF\",\"ridgeDurationShort\",\"ridgeDietLF:DurationShort\")\n)\nmouse &lt;- hypothesisTest(\n    mouse, i = \"proteins_msqrob\", L, modelColumn = \"msqrob_ion\"\n)\ninference &lt;- rowData(mouse[[\"proteins_msqrob\"]])[[colnames(L)]]\ninference$Protein &lt;- rownames(inference)\n\nAnd we plot the results.\n\nggplot(inference) +\n    aes(x = logFC, y = -log10(pval), color = adjPval &lt; 0.05) +\n    geom_text_repel(data = filter(inference, adjPval &lt; 0.05),\n                    aes(label = Protein)) +\n    geom_point() +\n    ggtitle(\"Statistical inference on average difference between LF and HF\",\n            paste(\"Hypothesis test:\", gsub(\"ridgeCondition\", \"\", colnames(L)), \"= 0\"))\n\n\n\n\n\n\n\n\nWe find much more significant proteins when combining all available data to infer the differences between low-fat and high-fat diets, irrespective of duration. We also retrieve a good overlap between this set of significant proteins and the two previous sets, indicating that more data helped improving the statistical power.\n\n\nInteraction: does the diet effect change according to duration?\nWe will now explore whether the effect of diet on protein abundance may be affected by duration, i.e. we want to infer on the difference of differences. The difference between hypothesis 1 and 2 is (DietLF + DietLF:DurationShort) - (DietLF) and results in the hypothesis below:\n\nhypothesis4 &lt;- \"ridgeDietLF:DurationShort = 0\"\n\nWe can proceed with the same statistical pipeline.\n\nL &lt;- makeContrast(\n    hypothesis4,\n    parameterNames = c(\"ridgeDietLF\",\"ridgeDurationShort\",\"ridgeDietLF:DurationShort\")\n)\nmouse &lt;- hypothesisTest(\n    mouse, i = \"proteins_msqrob\", L, modelColumn = \"msqrob_ion\"\n)\ninference &lt;- rowData(mouse[[\"proteins_msqrob\"]])[[colnames(L)]]\ninference$Protein &lt;- rownames(inference)\n\nAnd we plot the results.\n\nggplot(inference) +\n    aes(x = logFC, y = -log10(pval), color = adjPval &lt; 0.05) +\n    geom_text_repel(data = filter(inference, adjPval &lt; 0.05),\n                    aes(label = Protein)) +\n    geom_point() +\n    ggtitle(\"Statistical inference on the effect of duration on the differences between diets\",\n            paste(\"Hypothesis test:\", gsub(\"ridgeCondition\", \"\", colnames(L)), \"= 0\"))\n\n\n\n\n\n\n\n\nThere are only 3 proteins for which the effect of diet changes according to the duration. Let us visually explore this changes for the most significant protein.\n\n(targetProtein &lt;- rownames(inference)[which.min(inference$adjPval)])\n\n[1] \"Q924P3\"\n\n\nWe use again Qfeatures’s data manipulation pipeline.\n\nionData &lt;- mouse[targetProtein, , \"ions_norm\"] |&gt; #1\n    longForm(colvars = colnames(colData(mouse)), #2\n               rowvars = c(\"Protein.Accessions\", \"ionID\")) |&gt;\n    data.frame() |&gt;\n    filter(!is.na(value)) |&gt; #3\n    mutate(colname = factor(colname, levels = unique(colname[order(Condition)]))) #4\n\nAnd we explore the peptide ion data by visualising the differences between LF and HF separately for each mixture and diet duration in order to highlight changes in direction between these differences according to duration. We link data points belonging to the same peptide ion using a grey line.\n\nggplot(ionData) +\n    aes(x = colname,\n        y = value) +\n    geom_line(aes(group = ionID), linewidth = 0.1) +\n    geom_point(aes(colour = Diet)) +\n    facet_grid(Mixture ~ Duration, scales = \"free\") +\n    labs(x = \"Sample\", y = \"log2 intensity\") +\n    ggtitle(targetProtein) +\n    theme_minimal() +\n    theme(axis.text.x = element_blank())\n\n\n\n\n\n\n\n\nThe graph hints towards a slight increase in protein abundance in the low-fat diet group compared to the high-fat diet group during a short diet duration, but this increase disappears after a long diet duration. However, the visual inspection of the results also shows that the result rely on sparse and highly unbalanced data. The results may hence require further experimental validation.\nNote that we performed the statistical analysis for each hypothesis separately. However, msqrob2 can assess multiple hypotheses at once.\n\nL &lt;- makeContrast(\n    c(hypothesis1, hypothesis2, hypothesis3, hypothesis4),\n    parameterNames = c(\"ridgeDietLF\",\"ridgeDurationShort\",\"ridgeDietLF:DurationShort\")\n)\nmouse &lt;- hypothesisTest(\n    mouse, i = \"proteins_msqrob\", L,\n    modelColumn = \"msqrob_ion\", overwrite = TRUE\n)\n\nNote that since we already generated results for the contrast, we overwrite the results with the argument overwrite = TRUE.\nWe retrieve the inference tables from the rowData to generate the volcano plot.\n\ninferenceTables &lt;- rowData(mouse[[\"proteins_msqrob\"]])[, colnames(L)]\n\nWe here use a lapply() loop to generate the plots. The code chunk is elaborate, but follows the same structure as in the previous section. This generates a list of volcano plots, one for each hypothesis.\n\nvolcanoPlots &lt;- lapply(colnames(inferenceTables), function(i) {\n    inference &lt;- inferenceTables[[i]]\n    inference$Protein &lt;- rownames(inference)\n    ggplot(inference) +\n        aes(x = logFC, y = -log10(pval), color = adjPval &lt; 0.05) +\n        geom_text_repel(data = filter(inference, adjPval &lt; 0.05),\n                        aes(label = Protein)) +\n        geom_point() +\n        ggtitle(\"Hypothesis test:\",\n                paste(gsub(\"ridge\", \"\", i), \"= 0\"))\n})\n\nWe combine all the plots in a single figure using the patchwork packages.\n\nwrap_plots(volcanoPlots)\n\n\n\n\n\n\n\n\n\n\n\n7.6.4 Protein-level model\nThis section illustrates data modelling starting from protein data instead of ion data.\nHere, the workflow will use the summarised peptide ion intensities, as performed during the preprocessing. Note, that we no longer have multiple quantitative values for a protein in the same label of a run. Hence, we can omit the nested effects for label and ionID in run.\n\nmodelSum &lt;- ~ Diet * Duration + ## fixed effect for Diet and Duration with interaction\n        (1 | Label) + ## (1) random effect for label\n        (1 | Mixture) + ## (2) random effect for mixture\n        (1 | Run) + ## (3) random effect for MS run\n        (1 | BioReplicate)  ## (6) random effect for biorepeat (mouse)\n\nFor protein-level modelling, we use msqrob() instead of msqrobAggregate(), but their function arguments closely overlap.\n\nmouse &lt;- msqrob(\n    mouse, i = \"proteins\",\n    formula = modelSum,\n    modelColumnName = \"msqrob_rrilmm\",\n    ridge = TRUE, robust = TRUE\n)\n\nWe perform hypothesis tests for the early, late, average and interaction effects. Note that the contrasts remain unchanged.\n\nmouse &lt;- hypothesisTest(\n    mouse, i = \"proteins\", L, modelColumn = \"msqrob_rrilmm\"\n)\n\nThe inference tables were all stored in the rowData as separate columns, like previously.\n\ninferenceTablesSum &lt;- rowData(mouse[[\"proteins\"]])[, colnames(L)]\n\nWe here use again the lapply() loop that generates the list of volcano plots, one for each hypothesis.\n\nvolcanoPlotsSum &lt;- lapply(names(inferenceTablesSum), function(i) {\n    inference &lt;- inferenceTablesSum[[i]]\n    inference$Protein &lt;- rownames(inference)\n    ggplot(inference) +\n        aes(x = logFC, y = -log10(pval), color = adjPval &lt; 0.05) +\n        geom_text_repel(data = filter(inference, adjPval &lt; 0.05),\n                        aes(label = Protein)) +\n        geom_point() +\n        ggtitle(\"Hypothesis test:\",\n                paste(gsub(\"tests_|ridge\", \"\", i), \"= 0\"))\n})\n\n\nwrap_plots(volcanoPlotsSum)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The mouse diet use case: a Skyline TMT DDA dataset</span>"
    ]
  },
  {
    "objectID": "07-mouse_diet.html#conclusion",
    "href": "07-mouse_diet.html#conclusion",
    "title": "7  The mouse diet use case: a Skyline TMT DDA dataset",
    "section": "7.7 Conclusion",
    "text": "7.7 Conclusion\nIn this chapter, we have demonstrated the application of msqrob2TMT workflows on a real-life case study.\nThe preprocessing workflow relies on the the QFeatures package. The package provides functionality to carry out many steps like data filtering, missing values management, normalisation, log-transformation, imputation, summarisation, etc. The functions also provide different methods for each step, meaning that the preprocessing pipeline can be easily adapted to the researcher’s needs based on their experiment and data set.\nOnce preprocessed, we used the msqrob2 package to model all sources of variability as identified from the experimental design (and in part validated by data exploration): effect of diet and duration, effect of the MS acquisition run, effect of TMT mixture, effect of spectrum, and effect of sample. Modelling these different sources of variability allows to correctly infer changes in protein abundances between groups of interest while using ion-level data, although we also illustrate how to model the data at the protein level.\nThe experiment aims to understand the proteomic changes in mouse adipose tissue that occur upon feeding the mice with low-fat or high-fat diets, during a short or a long duration. We showed how to model the effect of these two factors using main effects and an interaction, which allows that the effect of diet can change according to the duration, and vice versa. We also showed how to translate biological questions into statistical hypothesis and corresponding contrast matrices using our msqrob2TMT workflow.\nA unique feature of msqrob2 is that its flexible approach can include more than 2 variables (with multiple interaction terms) as well as including numerical variables, which may be essential in other experimental contexts.\nModelling TMT-based data with biological replication leads to one of the most complex designs. These have to be further complexified with upcoming single-cell proteomics design where a new source of variability arises as cells belonging to the same experimental unit (subject or cell culture) are more similar than cells belonging to different experimental units. However, the model simplifies for other use cases. For instance, we saw how a protein-level model upon aggregation simplifies the model. However, spectrum effects can no longer be accounted for. This means that an appropriate summarisation approach is needed to correctly account for these spectrum effects when computing the protein-level summaries. Median polish (exemplified here) or robust summary do account for this, at least partially depending on the experimental design.\nLabel-free experiments, which do not perform chemical labelling of the samples, do not contain labelling effects which therefore are omitted. Moreover, every sample is acquired as part of a single run hence no run effect can be modelled. This simplified model is easier to understand but bear in mind that these sources of variation (eg. spectrum effects or run effect) end up in the residual variance, which might reduce statistical power.\nHence, we here demonstrated the power and flexibility of msqrob2 and the msqrob2TMT workflows to help researchers answer biologically-relevant questions from their MS proteomics data.\n\n\n\n\nHuang, Ting, Meena Choi, Manuel Tzouros, Sabrina Golling, Nikhil Janak Pandya, Balazs Banfai, Tom Dunkley, and Olga Vitek. 2020. “MSstatsTMT: Statistical Detection of Differentially Abundant Proteins in Experiments with Isobaric Labeling and Multiple Mixtures.” Mol. Cell. Proteomics 19 (10): 1706–23.\n\n\nPlubell, Deanna L, Phillip A Wilmarth, Yuqi Zhao, Alexandra M Fenton, Jessica Minnier, Ashok P Reddy, John Klimek, Xia Yang, Larry L David, and Nathalie Pamir. 2017. “Extended Multiplexing of Tandem Mass Tags (TMT) Labeling Reveals Age and High Fat Diet Specific Proteome Changes in Mouse Epididymal Adipose Tissue.” Mol. Cell. Proteomics 16 (5): 873–90.\n\n\nSegers, Alexandre, Cristian Castiglione, Christophe Vanderaa, Elfride De Baere, Lennart Martens, Davide Risso, and Lieven Clement. 2025. “omicsGMF: A Multi-Tool for Dimensionality Reduction, Batch Correction and Imputation Applied to Bulk- and Single Cell Proteomics Data.” bioRxiv, March, 2025.03.24.644996.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The mouse diet use case: a Skyline TMT DDA dataset</span>"
    ]
  },
  {
    "objectID": "07-mouse_diet.html#footnotes",
    "href": "07-mouse_diet.html#footnotes",
    "title": "7  The mouse diet use case: a Skyline TMT DDA dataset",
    "section": "",
    "text": "note that these files are locally cached↩︎",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The mouse diet use case: a Skyline TMT DDA dataset</span>"
    ]
  },
  {
    "objectID": "99-end.html",
    "href": "99-end.html",
    "title": "8  Additional information",
    "section": "",
    "text": "8.1 Citation\nPlease cite this book as:\nTODO: add citation once published\nPlease cite the msqrob2 package as:\nIf you opt for a summarisation-based workflow, you can also cite:\nIf you use TMT-based workflows, please cite",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Additional information</span>"
    ]
  },
  {
    "objectID": "99-end.html#citation",
    "href": "99-end.html#citation",
    "title": "8  Additional information",
    "section": "",
    "text": "Goeminne L, Gevaert K, Clement L (2016). “Peptide-level Robust Ridge Regression Improves Estimation, Sensitivity, and Specificity in Data-dependent Quantitative Label-free Shotgun Proteomics.” Molecular & Cellular Proteomics, 15(2), 657-668. doi:10.1074/mcp.m115.055897.\n\n\n\nSticker A, Goeminne L, Martens L, Clement L (2020). “Robust Summarization and Inference in Proteome-wide Label-free Quantification.” Molecular & Cellular Proteomics, 19(7), 1209-1219. doi:10.1074/mcp.ra119.001624.\n\n\n\nVandenbulcke S, Vanderaa C, Crook O, Martens L, Clement L. msqrob2TMT: robust linear mixed models for inferring differential abundant proteins in labelled experiments with arbitrarily complex design. bioRxiv. Published online March 29, 2024:2024.03.29.587218. doi:10.1101/2024.03.29.587218",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Additional information</span>"
    ]
  },
  {
    "objectID": "99-end.html#references",
    "href": "99-end.html#references",
    "title": "8  Additional information",
    "section": "References",
    "text": "References\n\n\nGatto, Laurent, Ruedi Aebersold, Juergen Cox, Vadim Demichev, Jason\nDerks, Edward Emmott, Alexander M Franks, et al. 2023. “Initial\nRecommendations for Performing, Benchmarking and Reporting Single-Cell\nProteomics Experiments.” Nat. Methods 20 (3): 375–86.\n\n\nGoeminne, Ludger J E, Kris Gevaert, and Lieven Clement. 2016.\n“Peptide-Level Robust Ridge Regression Improves Estimation,\nSensitivity, and Specificity in Data-Dependent Quantitative Label-Free\nShotgun Proteomics.” Mol. Cell. Proteomics 15 (2):\n657–68.\n\n\nHuang, Ting, Meena Choi, Manuel Tzouros, Sabrina Golling, Nikhil Janak\nPandya, Balazs Banfai, Tom Dunkley, and Olga Vitek. 2020.\n“MSstatsTMT: Statistical Detection of Differentially\nAbundant Proteins in Experiments with Isobaric Labeling and Multiple\nMixtures.” Mol. Cell. Proteomics 19 (10): 1706–23.\n\n\nO’Brien, Jonathon J, Anil Raj, Aleksandr Gaun, Adam Waite, Wenzhou Li,\nDavid G Hendrickson, Niclas Olsson, and Fiona E McAllister. 2024.\n“A Data Analysis Framework for Combining Multiple Batches\nIncreases the Power of Isobaric Proteomics Experiments.” Nat.\nMethods 21 (2): 290–300.\n\n\nPlubell, Deanna L, Phillip A Wilmarth, Yuqi Zhao, Alexandra M Fenton,\nJessica Minnier, Ashok P Reddy, John Klimek, Xia Yang, Larry L David,\nand Nathalie Pamir. 2017. “Extended Multiplexing of Tandem Mass\nTags (TMT) Labeling Reveals Age and High Fat Diet Specific\nProteome Changes in Mouse Epididymal Adipose Tissue.” Mol.\nCell. Proteomics 16 (5): 873–90.\n\n\nRamond, Elodie, Gael Gesbert, Ida Chiara Guerrera, Cerina Chhuon, Marion\nDupuis, Mélanie Rigard, Thomas Henry, Monique Barel, and Alain Charbit.\n2015. “Importance of Host Cell Arginine Uptake in Francisella\nPhagosomal Escape and Ribosomal Protein Amounts.” Mol. Cell.\nProteomics 14 (4): 870–81.\n\n\nSavitski, Mikhail M, Gavain Sweetman, Manor Askenazi, Jarrod A Marto,\nManja Lang, Nico Zinn, and Marcus Bantscheff. 2011. “Delayed\nFragmentation and Optimized Isolation Width Settings for Improvement of\nProtein Identification and Accuracy of Isobaric Mass Tag Quantification\non Orbitrap-Type Mass Spectrometers.” Anal. Chem. 83\n(23): 8959–67.\n\n\nSegers, Alexandre, Cristian Castiglione, Christophe Vanderaa, Elfride De\nBaere, Lennart Martens, Davide Risso, and Lieven Clement. 2025.\n“omicsGMF: A Multi-Tool for\nDimensionality Reduction, Batch Correction and Imputation Applied to\nBulk- and Single Cell Proteomics Data.” bioRxiv, March,\n2025.03.24.644996.\n\n\nShen, Xiaomeng, Shichen Shen, Jun Li, Qiang Hu, Lei Nie, Chengjian Tu,\nXue Wang, et al. 2018. “IonStar Enables\nHigh-Precision, Low-Missing-Data Proteomics Quantification in Large\nBiological Cohorts.” Proc. Natl. Acad. Sci. U. S. A. 115\n(21): E4767–76.\n\n\nSticker, Adriaan, Ludger Goeminne, Lennart Martens, and Lieven Clement.\n2020. “Robust Summarization and Inference in Proteome-Wide\nLabel-Free Quantification.” Mol. Cell. Proteomics 19\n(7): 1209–19.\n\n\nVandenbulcke, Stijn, Christophe Vanderaa, Oliver Crook, Lennart Martens,\nand Lieven Clement. 2025. “Msqrob2TMT: Robust Linear\nMixed Models for Inferring Differential Abundant Proteins in Labeled\nExperiments with Arbitrarily Complex Design.” Mol. Cell.\nProteomics 24 (7): 101002.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Additional information</span>"
    ]
  },
  {
    "objectID": "99-end.html#data-sets",
    "href": "99-end.html#data-sets",
    "title": "8  Additional information",
    "section": "8.2 Data sets",
    "text": "8.2 Data sets\nWe refer here the data sources used in the book:\n\n8.2.1 E. Coli LFQ spike-in data set\nOriginal study: Shen X, Shen S, Li J, Hu Q, Nie L, Tu C, et al. (2018) Ionstar enables high-precision, low-missing-data proteomics quantification in large bio- logical cohorts. Proc. Natl. Acad. Sci. U.S.A. 115, E4767–E4776\nReanalysis study: Sticker A, Goeminne L, Martens L, Clement L. Robust Summarization and Inference in Proteome-wide Label-free Quantification. Mol Cell Proteomics. 2020;19(7):1209-1219.\nLink to data: https://github.com/statOmics/MSqRobSumPaper/raw/refs/heads/master/spikein/data/maxquant/peptides.zip\nLink to data in archive: TODO add link to Zenodo\nUsed in Chapter 1 and Chapter 3.\n\n\n8.2.2 TMT spike-in data set\nOriginal study: Huang T, Choi M, Tzouros M, Golling S, Pandya NJ, Banfai B, et al. MSstatsTMT: Statistical Detection of Differentially Abundant Proteins in Experiments with Isobaric Labeling and Multiple Mixtures. Mol Cell Proteomics. 2020;19(10):1706-1723.\nReanalysis study: Vandenbulcke S, Vanderaa C, Crook O, Martens L, Clement L. Msqrob2TMT: Robust linear mixed models for inferring differential abundant proteins in labeled experiments with arbitrarily complex design. Mol Cell Proteomics. 2025;24(7):101002.\nData source: MassIVE repository (RMSV000000265)\nLink to data from archive: https://zenodo.org/records/14767905\nUsed in Chapter 2.\n\n\n8.2.3 Francisella data set\nTODO\n\n\n8.2.4 Heart data set\nTODO\n\n\n8.2.5 Mouse diet data set\nTODO",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Additional information</span>"
    ]
  },
  {
    "objectID": "99-end.html#license",
    "href": "99-end.html#license",
    "title": "8  Additional information",
    "section": "8.3 License",
    "text": "8.3 License\nThis material is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. You are free to share (copy and redistribute the material in any medium or format) and adapt (remix, transform, and build upon the material) for any purpose, even commercially, as long as you give appropriate credit and distribute your contributions under the same license as the original.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Additional information</span>"
    ]
  },
  {
    "objectID": "99-end.html#session-info",
    "href": "99-end.html#session-info",
    "title": "8  Additional information",
    "section": "8.4 Session Info",
    "text": "8.4 Session Info\nThe following packages have been used to generate this document.\n\nsessionInfo()\n\nR version 4.5.2 (2025-10-31)\nPlatform: x86_64-pc-linux-gnu\nRunning under: Ubuntu 24.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.12.0 \nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.12.0  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Europe/Brussels\ntzcode source: system (glibc)\n\nattached base packages:\n[1] grid      stats4    stats     graphics  grDevices utils     datasets \n[8] methods   base     \n\nother attached packages:\n [1] bookdown_0.45               tidyr_1.3.1                \n [3] scater_1.38.0               scuttle_1.20.0             \n [5] SingleCellExperiment_1.32.0 patchwork_1.3.2            \n [7] MsDataHub_1.10.0            impute_1.84.0              \n [9] ggrepel_0.9.6               ggplot2_4.0.1              \n[11] ExploreModelMatrix_1.22.0   dplyr_1.1.4                \n[13] ComplexHeatmap_2.26.0       BiocFileCache_3.0.0        \n[15] dbplyr_2.5.1                BiocParallel_1.44.0        \n[17] msqrob2book_0.0.99          msqrob2_1.18.0             \n[19] QFeatures_1.20.0            MultiAssayExperiment_1.36.1\n[21] SummarizedExperiment_1.40.0 Biobase_2.70.0             \n[23] GenomicRanges_1.62.0        Seqinfo_1.0.0              \n[25] IRanges_2.44.0              S4Vectors_0.48.0           \n[27] BiocGenerics_0.56.0         generics_0.1.4             \n[29] MatrixGenerics_1.22.0       matrixStats_1.5.0          \n\nloaded via a namespace (and not attached):\n  [1] splines_4.5.2           later_1.4.4             filelock_1.0.3         \n  [4] tibble_3.3.0            lifecycle_1.0.4         httr2_1.2.1            \n  [7] Rdpack_2.6.4            doParallel_1.0.17       rprojroot_2.1.1        \n [10] lattice_0.22-7          MASS_7.3-65             magrittr_2.0.4         \n [13] limma_3.66.0            rmarkdown_2.30          yaml_2.3.11            \n [16] remotes_2.5.0           httpuv_1.6.16           otel_0.2.0             \n [19] sessioninfo_1.2.3       pkgbuild_1.4.8          cowplot_1.2.0          \n [22] MsCoreUtils_1.22.1      DBI_1.2.3               minqa_1.2.8            \n [25] RColorBrewer_1.1-3      abind_1.4-8             pkgload_1.4.1          \n [28] purrr_1.2.0             AnnotationFilter_1.34.0 rappdirs_0.3.3         \n [31] circlize_0.4.16         irlba_2.3.5.1           codetools_0.2-20       \n [34] DelayedArray_0.36.0     DT_0.34.0               tidyselect_1.2.1       \n [37] shape_1.4.6.1           farver_2.1.2            lme4_1.1-37            \n [40] ScaledMatrix_1.18.0     viridis_0.6.5           jsonlite_2.0.0         \n [43] GetoptLong_1.1.0        BiocNeighbors_2.4.0     ellipsis_0.3.2         \n [46] iterators_1.0.14        foreach_1.5.2           tools_4.5.2            \n [49] Rcpp_1.1.0              glue_1.8.0              gridExtra_2.3          \n [52] SparseArray_1.10.3      BiocBaseUtils_1.12.0    xfun_0.54              \n [55] usethis_3.2.1           shinydashboard_0.7.3    withr_3.0.2            \n [58] BiocManager_1.30.27     fastmap_1.2.0           boot_1.3-31            \n [61] shinyjs_2.1.0           digest_0.6.39           rsvd_1.0.5             \n [64] R6_2.6.1                mime_0.13               colorspace_2.1-2       \n [67] RSQLite_2.4.5           httr_1.4.7              htmlwidgets_1.6.4      \n [70] S4Arrays_1.10.0         pkgconfig_2.0.3         gtable_0.3.6           \n [73] blob_1.2.4              S7_0.2.1                XVector_0.50.0         \n [76] htmltools_0.5.8.1       ProtGenerics_1.42.0     rintrojs_0.3.4         \n [79] clue_0.3-66             scales_1.4.0            png_0.1-8              \n [82] reformulas_0.4.2        knitr_1.50              rstudioapi_0.17.1      \n [85] reshape2_1.4.5          rjson_0.2.23            nlme_3.1-168           \n [88] curl_7.0.0              nloptr_2.2.1            cachem_1.1.0           \n [91] GlobalOptions_0.1.3     stringr_1.6.0           BiocVersion_3.22.0     \n [94] parallel_4.5.2          vipor_0.4.7             AnnotationDbi_1.72.0   \n [97] desc_1.4.3              pillar_1.11.1           vctrs_0.6.5            \n[100] promises_1.5.0          BiocSingular_1.26.1     beachmat_2.26.0        \n[103] xtable_1.8-4            cluster_2.1.8.1         beeswarm_0.4.0         \n[106] evaluate_1.0.5          cli_3.6.5               compiler_4.5.2         \n[109] rlang_1.1.6             crayon_1.5.3            plyr_1.8.9             \n[112] fs_1.6.6                ggbeeswarm_0.7.3        stringi_1.8.7          \n[115] viridisLite_0.4.2       Biostrings_2.78.0       lazyeval_0.2.2         \n[118] devtools_2.4.6          Matrix_1.7-4            ExperimentHub_3.0.0    \n[121] bit64_4.6.0-1           KEGGREST_1.50.0         statmod_1.5.1          \n[124] shiny_1.11.1            AnnotationHub_4.0.0     rbibutils_2.4          \n[127] igraph_2.2.1            memoise_2.0.1           bit_4.6.0",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Additional information</span>"
    ]
  }
]